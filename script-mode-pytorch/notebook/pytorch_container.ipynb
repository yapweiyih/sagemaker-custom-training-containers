{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create custom container using SageMaker PyTorch Deep Learning Framework\n",
    "\n",
    "Update `role` with your SageMaker role arn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 20.1 from /Users/yihyap/anaconda3/envs/sandbox36/lib/python3.6/site-packages/pip (python 3.6)\r\n"
     ]
    }
   ],
   "source": [
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account: 342474125894\n",
      "Region: ap-southeast-1\n",
      "Role: arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\n",
      "S3 Bucket: sagemaker-ap-southeast-1-342474125894\n",
      "Repo: sagemaker-training-containers/pytorch-training\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ecr_namespace = 'sagemaker-training-containers/'\n",
    "prefix = 'pytorch-training'\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = \"arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\"\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print('Account: {}'.format(account_id))\n",
    "print('Region: {}'.format(region))\n",
    "print('Role: {}'.format(role))\n",
    "print('S3 Bucket: {}'.format(bucket))\n",
    "print('Repo: {}'.format(ecr_repository_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build training container\n",
    "\n",
    "Next we will create a script that will build and upload the custom container image into ECR. It has to be in the same region where the job is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  18.43kB\n",
      "Step 1/16 : FROM ubuntu:16.04\n",
      " ---> 13c9f1285025\n",
      "Step 2/16 : LABEL maintainer=\"Giuseppe A. Porcelli\"\n",
      " ---> Using cache\n",
      " ---> 6bbf3d07c68d\n",
      "Step 3/16 : ARG PYTHON=python3\n",
      " ---> Using cache\n",
      " ---> 8e254b9ef0a0\n",
      "Step 4/16 : ARG PYTHON_PIP=python3-pip\n",
      " ---> Using cache\n",
      " ---> 84c928b11bb3\n",
      "Step 5/16 : ARG PIP=pip3\n",
      " ---> Using cache\n",
      " ---> 65e780b1f9d7\n",
      "Step 6/16 : ARG PYTHON_VERSION=3.6.6\n",
      " ---> Using cache\n",
      " ---> 03bab72f170e\n",
      "Step 7/16 : RUN apt-get update && apt-get install -y --no-install-recommends software-properties-common &&     add-apt-repository ppa:deadsnakes/ppa -y &&     apt-get update && apt-get install -y --no-install-recommends         build-essential         ca-certificates         curl         wget         git         libopencv-dev         openssh-client         openssh-server         vim         zlib1g-dev &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 0b3f66ca4c73\n",
      "Step 8/16 : RUN wget https://www.python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tgz &&         tar -xvf Python-$PYTHON_VERSION.tgz && cd Python-$PYTHON_VERSION &&         ./configure && make && make install &&         apt-get update && apt-get install -y --no-install-recommends libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev &&         make && make install && rm -rf ../Python-$PYTHON_VERSION* &&         ln -s /usr/local/bin/pip3 /usr/bin/pip\n",
      " ---> Using cache\n",
      " ---> da24d9684dbd\n",
      "Step 9/16 : RUN ${PIP} --no-cache-dir install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> a7e0f5c77b12\n",
      "Step 10/16 : RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
      " ---> Using cache\n",
      " ---> 9970f3a50688\n",
      "Step 11/16 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 7185a26a84ec\n",
      "Step 12/16 : RUN ${PIP} install --no-cache --upgrade         numpy==1.14.5         pandas==0.24.1         scikit-learn==0.20.3         requests==2.21.0         scipy==1.2.1         torch         torchaudio\n",
      " ---> Using cache\n",
      " ---> b994da0ad189\n",
      "Step 13/16 : ENV PYTHONDONTWRITEBYTECODE=1     PYTHONUNBUFFERED=1     LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\"     PYTHONIOENCODING=UTF-8     LANG=C.UTF-8     LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 534c9458df19\n",
      "Step 14/16 : RUN ${PIP} install --no-cache --upgrade     sagemaker-containers\n",
      " ---> Using cache\n",
      " ---> 8a9b3ea0d6eb\n",
      "Step 15/16 : COPY code/* /opt/ml/code/\n",
      " ---> 10e5debf641c\n",
      "Step 16/16 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in f1a6782ce27a\n",
      "Removing intermediate container f1a6782ce27a\n",
      " ---> c44d320e9f29\n",
      "Successfully built c44d320e9f29\n",
      "Successfully tagged sagemaker-training-containers/pytorch-training:latest\n",
      "Login Succeeded\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryUri\": \"342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/pytorch-training\", \n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            }, \n",
      "            \"registryId\": \"342474125894\", \n",
      "            \"imageTagMutability\": \"MUTABLE\", \n",
      "            \"repositoryArn\": \"arn:aws:ecr:ap-southeast-1:342474125894:repository/sagemaker-training-containers/pytorch-training\", \n",
      "            \"repositoryName\": \"sagemaker-training-containers/pytorch-training\", \n",
      "            \"createdAt\": 1597146062.0\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "The push refers to repository [342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/pytorch-training]\n",
      "\n",
      "\u001b[1Ba16a6cfd: Preparing \n",
      "\u001b[1B98b4e3f3: Preparing \n",
      "\u001b[1Bc7c70141: Preparing \n",
      "\u001b[1B4a5b1e5b: Preparing \n",
      "\u001b[1B087edcda: Preparing \n",
      "\u001b[1B0ce8b97f: Preparing \n",
      "\u001b[1Bef1fd00d: Preparing \n",
      "\u001b[1Bf22d44f3: Preparing \n",
      "\u001b[1B6f329a25: Preparing \n",
      "\u001b[1B7de5faec: Preparing \n",
      "\u001b[11B16a6cfd: Pushed lready exists 4kB\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[2A\u001b[2K\u001b[11A\u001b[2Klatest: digest: sha256:430dec278f96f9871372b4416b3bb107deb5ab77972bafa106d9c5a7960fa3a4 size: 2626\n"
     ]
    }
   ],
   "source": [
    "# ./build_and_push.sh 342474125894 ap-southeast-1 sagemaker-training-containers/pytorch-training\n",
    "! ../scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECR training container ARN: 342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/pytorch-training:latest\n"
     ]
    }
   ],
   "source": [
    "train_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, ecr_repository_name)\n",
    "print('ECR training container ARN: {}'.format(train_image_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The docker image is now pushed to ECR. In the next section, we will show how to train an acoustic classification model using the custom container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Training on SageMaker PyTorch custom container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-11 14:16:09 Starting - Starting the training job...\n",
      "2020-08-11 14:16:11 Starting - Launching requested ML instances......\n",
      "2020-08-11 14:17:23 Starting - Preparing the instances for training...\n",
      "2020-08-11 14:18:05 Downloading - Downloading input data\n",
      "2020-08-11 14:18:05 Training - Downloading the training image......\n",
      "2020-08-11 14:19:09 Uploading - Uploading generated training model.\u001b[34m2020-08-11 14:19:04,441 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-11 14:19:04,459 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-11 14:19:04,472 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-11 14:19:04,482 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"seed\": 1,\n",
      "        \"epochs\": 50\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-08-11-14-16-28-241\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":50,\"seed\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":50,\"seed\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-08-11-14-16-28-241\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"50\",\"--seed\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_SEED=1\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=50\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 train.py --epochs 50 --seed 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNamespace(batch_size=64, epochs=50, log_interval=10, lr=0.1, model_dir='/opt/ml/model', save_model=False, seed=1, train=None, validation=None)\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in train channel: \u001b[0m\n",
      "\u001b[34mSM_CHANNEL is not set\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in validation channel: \u001b[0m\n",
      "\u001b[34mSM_CHANNEL is not set\u001b[0m\n",
      "\u001b[34mDevice: cpu\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [0/700 (0%)]#011Loss: 1.397044\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [600/700 (91%)]#011Loss: 0.554748\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [0/700 (0%)]#011Loss: 0.427614\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [600/700 (91%)]#011Loss: 0.278386\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [0/700 (0%)]#011Loss: 0.250472\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [600/700 (91%)]#011Loss: 0.168894\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [0/700 (0%)]#011Loss: 0.254978\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [600/700 (91%)]#011Loss: 0.117975\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [0/700 (0%)]#011Loss: 0.202066\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [600/700 (91%)]#011Loss: 0.190511\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [0/700 (0%)]#011Loss: 0.153269\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [600/700 (91%)]#011Loss: 0.121626\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [0/700 (0%)]#011Loss: 0.296067\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [600/700 (91%)]#011Loss: 0.060579\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [0/700 (0%)]#011Loss: 0.210702\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [600/700 (91%)]#011Loss: 0.098814\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [0/700 (0%)]#011Loss: 0.080478\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [600/700 (91%)]#011Loss: 0.043554\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [0/700 (0%)]#011Loss: 0.141391\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [600/700 (91%)]#011Loss: 0.130171\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [0/700 (0%)]#011Loss: 0.107489\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [600/700 (91%)]#011Loss: 0.084962\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [0/700 (0%)]#011Loss: 0.123311\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [600/700 (91%)]#011Loss: 0.076903\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [0/700 (0%)]#011Loss: 0.161478\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [600/700 (91%)]#011Loss: 0.072555\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [0/700 (0%)]#011Loss: 0.273229\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [600/700 (91%)]#011Loss: 0.140882\u001b[0m\n",
      "\u001b[34mTrain Epoch: 15 [0/700 (0%)]#011Loss: 0.103442\u001b[0m\n",
      "\u001b[34mTrain Epoch: 15 [600/700 (91%)]#011Loss: 0.125399\u001b[0m\n",
      "\u001b[34mTrain Epoch: 16 [0/700 (0%)]#011Loss: 0.062349\u001b[0m\n",
      "\u001b[34mTrain Epoch: 16 [600/700 (91%)]#011Loss: 0.133088\u001b[0m\n",
      "\u001b[34mTrain Epoch: 17 [0/700 (0%)]#011Loss: 0.106978\u001b[0m\n",
      "\u001b[34mTrain Epoch: 17 [600/700 (91%)]#011Loss: 0.171333\u001b[0m\n",
      "\u001b[34mTrain Epoch: 18 [0/700 (0%)]#011Loss: 0.106133\u001b[0m\n",
      "\u001b[34mTrain Epoch: 18 [600/700 (91%)]#011Loss: 0.039655\u001b[0m\n",
      "\u001b[34mTrain Epoch: 19 [0/700 (0%)]#011Loss: 0.150448\u001b[0m\n",
      "\u001b[34mTrain Epoch: 19 [600/700 (91%)]#011Loss: 0.067831\u001b[0m\n",
      "\u001b[34mTrain Epoch: 20 [0/700 (0%)]#011Loss: 0.057838\u001b[0m\n",
      "\u001b[34mTrain Epoch: 20 [600/700 (91%)]#011Loss: 0.072466\u001b[0m\n",
      "\u001b[34mTrain Epoch: 21 [0/700 (0%)]#011Loss: 0.045784\u001b[0m\n",
      "\u001b[34mTrain Epoch: 21 [600/700 (91%)]#011Loss: 0.071888\u001b[0m\n",
      "\u001b[34mTrain Epoch: 22 [0/700 (0%)]#011Loss: 0.056103\u001b[0m\n",
      "\u001b[34mTrain Epoch: 22 [600/700 (91%)]#011Loss: 0.060492\u001b[0m\n",
      "\u001b[34mTrain Epoch: 23 [0/700 (0%)]#011Loss: 0.137211\u001b[0m\n",
      "\u001b[34mTrain Epoch: 23 [600/700 (91%)]#011Loss: 0.071937\u001b[0m\n",
      "\u001b[34mTrain Epoch: 24 [0/700 (0%)]#011Loss: 0.072909\u001b[0m\n",
      "\u001b[34mTrain Epoch: 24 [600/700 (91%)]#011Loss: 0.042278\u001b[0m\n",
      "\u001b[34mTrain Epoch: 25 [0/700 (0%)]#011Loss: 0.107233\u001b[0m\n",
      "\u001b[34mTrain Epoch: 25 [600/700 (91%)]#011Loss: 0.133018\u001b[0m\n",
      "\u001b[34mTrain Epoch: 26 [0/700 (0%)]#011Loss: 0.054438\u001b[0m\n",
      "\u001b[34mTrain Epoch: 26 [600/700 (91%)]#011Loss: 0.076478\u001b[0m\n",
      "\u001b[34mTrain Epoch: 27 [0/700 (0%)]#011Loss: 0.039363\u001b[0m\n",
      "\u001b[34mTrain Epoch: 27 [600/700 (91%)]#011Loss: 0.193148\u001b[0m\n",
      "\u001b[34mTrain Epoch: 28 [0/700 (0%)]#011Loss: 0.140906\u001b[0m\n",
      "\u001b[34mTrain Epoch: 28 [600/700 (91%)]#011Loss: 0.026257\u001b[0m\n",
      "\u001b[34mTrain Epoch: 29 [0/700 (0%)]#011Loss: 0.026260\u001b[0m\n",
      "\u001b[34mTrain Epoch: 29 [600/700 (91%)]#011Loss: 0.118374\u001b[0m\n",
      "\u001b[34mTrain Epoch: 30 [0/700 (0%)]#011Loss: 0.039989\u001b[0m\n",
      "\u001b[34mTrain Epoch: 30 [600/700 (91%)]#011Loss: 0.027762\u001b[0m\n",
      "\u001b[34mTrain Epoch: 31 [0/700 (0%)]#011Loss: 0.295625\u001b[0m\n",
      "\u001b[34mTrain Epoch: 31 [600/700 (91%)]#011Loss: 0.284550\u001b[0m\n",
      "\u001b[34mTrain Epoch: 32 [0/700 (0%)]#011Loss: 0.053689\u001b[0m\n",
      "\u001b[34mTrain Epoch: 32 [600/700 (91%)]#011Loss: 0.039031\u001b[0m\n",
      "\u001b[34mTrain Epoch: 33 [0/700 (0%)]#011Loss: 0.093207\u001b[0m\n",
      "\u001b[34mTrain Epoch: 33 [600/700 (91%)]#011Loss: 0.074951\u001b[0m\n",
      "\u001b[34mTrain Epoch: 34 [0/700 (0%)]#011Loss: 0.168241\u001b[0m\n",
      "\u001b[34mTrain Epoch: 34 [600/700 (91%)]#011Loss: 0.036480\u001b[0m\n",
      "\u001b[34mTrain Epoch: 35 [0/700 (0%)]#011Loss: 0.247766\u001b[0m\n",
      "\u001b[34mTrain Epoch: 35 [600/700 (91%)]#011Loss: 0.102818\u001b[0m\n",
      "\u001b[34mTrain Epoch: 36 [0/700 (0%)]#011Loss: 0.225871\u001b[0m\n",
      "\u001b[34mTrain Epoch: 36 [600/700 (91%)]#011Loss: 0.041332\u001b[0m\n",
      "\u001b[34mTrain Epoch: 37 [0/700 (0%)]#011Loss: 0.291039\u001b[0m\n",
      "\u001b[34mTrain Epoch: 37 [600/700 (91%)]#011Loss: 0.038301\u001b[0m\n",
      "\u001b[34mTrain Epoch: 38 [0/700 (0%)]#011Loss: 0.098736\u001b[0m\n",
      "\u001b[34mTrain Epoch: 38 [600/700 (91%)]#011Loss: 0.040286\u001b[0m\n",
      "\u001b[34mTrain Epoch: 39 [0/700 (0%)]#011Loss: 0.098627\u001b[0m\n",
      "\u001b[34mTrain Epoch: 39 [600/700 (91%)]#011Loss: 0.168440\u001b[0m\n",
      "\u001b[34mTrain Epoch: 40 [0/700 (0%)]#011Loss: 0.025710\u001b[0m\n",
      "\u001b[34mTrain Epoch: 40 [600/700 (91%)]#011Loss: 0.044079\u001b[0m\n",
      "\u001b[34mTrain Epoch: 41 [0/700 (0%)]#011Loss: 0.022323\u001b[0m\n",
      "\u001b[34mTrain Epoch: 41 [600/700 (91%)]#011Loss: 0.143349\u001b[0m\n",
      "\u001b[34mTrain Epoch: 42 [0/700 (0%)]#011Loss: 0.051734\u001b[0m\n",
      "\u001b[34mTrain Epoch: 42 [600/700 (91%)]#011Loss: 0.296605\u001b[0m\n",
      "\u001b[34mTrain Epoch: 43 [0/700 (0%)]#011Loss: 0.033206\u001b[0m\n",
      "\u001b[34mTrain Epoch: 43 [600/700 (91%)]#011Loss: 0.244053\u001b[0m\n",
      "\u001b[34mTrain Epoch: 44 [0/700 (0%)]#011Loss: 0.149287\u001b[0m\n",
      "\u001b[34mTrain Epoch: 44 [600/700 (91%)]#011Loss: 0.096720\u001b[0m\n",
      "\u001b[34mTrain Epoch: 45 [0/700 (0%)]#011Loss: 0.216382\u001b[0m\n",
      "\u001b[34mTrain Epoch: 45 [600/700 (91%)]#011Loss: 0.148102\u001b[0m\n",
      "\u001b[34mTrain Epoch: 46 [0/700 (0%)]#011Loss: 0.096489\u001b[0m\n",
      "\u001b[34mTrain Epoch: 46 [600/700 (91%)]#011Loss: 0.036839\u001b[0m\n",
      "\u001b[34mTrain Epoch: 47 [0/700 (0%)]#011Loss: 0.269076\u001b[0m\n",
      "\u001b[34mTrain Epoch: 47 [600/700 (91%)]#011Loss: 0.040452\u001b[0m\n",
      "\u001b[34mTrain Epoch: 48 [0/700 (0%)]#011Loss: 0.290529\u001b[0m\n",
      "\u001b[34mTrain Epoch: 48 [600/700 (91%)]#011Loss: 0.050985\u001b[0m\n",
      "\u001b[34mTrain Epoch: 49 [0/700 (0%)]#011Loss: 0.073460\u001b[0m\n",
      "\u001b[34mTrain Epoch: 49 [600/700 (91%)]#011Loss: 0.072288\u001b[0m\n",
      "\u001b[34mTrain Epoch: 50 [0/700 (0%)]#011Loss: 0.026967\u001b[0m\n",
      "\u001b[34mTrain Epoch: 50 [600/700 (91%)]#011Loss: 0.024244\n",
      "\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.1402, Accuracy: 292/300 (97%)\n",
      "\u001b[0m\n",
      "\u001b[34m2020-08-11 14:19:07,123 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-08-11 14:19:15 Completed - Training job completed\n",
      "Training seconds: 79\n",
      "Billable seconds: 79\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "\n",
    "hyperparameters = {\n",
    "    \"seed\": \"1\",\n",
    "    \"epochs\": 50,\n",
    "}\n",
    "\n",
    "est = sagemaker.estimator.Estimator(train_image_uri,\n",
    "                                    role,\n",
    "                                    train_instance_count=1, \n",
    "                                    #instance_type='local', # we use local mode\n",
    "                                    train_instance_type='ml.m5.xlarge',\n",
    "                                    base_job_name=prefix,\n",
    "                                    hyperparameters=hyperparameters)\n",
    "\n",
    "\n",
    "est.fit()\n",
    "\n",
    "#train_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "#val_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "#est.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve model location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-342474125894/pytorch-training-2020-08-11-14-16-28-241/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_location = est.model_data\n",
    "print(model_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Inference\n",
    "\n",
    "For inference, we will use default inference image. Mandatory `model_fn` is implemented in `inference.py`. PyTorchModel is used to deploy custom model that we trained previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sagemaker\r\n",
      "Version: 1.51.3\r\n",
      "Summary: Open source library for training and deploying models on Amazon SageMaker.\r\n",
      "Home-page: https://github.com/aws/sagemaker-python-sdk/\r\n",
      "Author: Amazon Web Services\r\n",
      "Author-email: None\r\n",
      "License: Apache License 2.0\r\n",
      "Location: /Users/yihyap/anaconda3/envs/sandbox36/lib/python3.6/site-packages\r\n",
      "Requires: boto3, packaging, protobuf, importlib-metadata, protobuf3-to-dict, smdebug-rulesconfig, numpy, scipy\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip show sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data=\"s3://sagemaker-ap-southeast-1-342474125894/pytorch-training-2020-08-11-14-16-28-241/output/model.tar.gz\", \n",
    "                             role=role, \n",
    "                             entry_point='inference.py',\n",
    "                             source_dir='../docker/code',\n",
    "                             py_version='py3',\n",
    "                             framework_version='1.5.1',\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (404) when calling the HeadObject operation: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-65058fd7e10c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytorch_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ml.m5.xlarge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, update_endpoint, tags, kms_key, wait, data_capture_config)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled_model_suffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_sagemaker_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         production_variant = sagemaker.production_variant(\n\u001b[1;32m    444\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_instance_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccelerator_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36m_create_sagemaker_model\u001b[0;34m(self, instance_type, accelerator_type, tags)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;34m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mservices\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;31m#SageMaker.Client.add_tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \"\"\"\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mcontainer_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_container_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccelerator_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_from_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer_def\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0menable_network_isolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_network_isolation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/sagemaker/pytorch/model.py\u001b[0m in \u001b[0;36mprepare_container_def\u001b[0;34m(self, instance_type, accelerator_type)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mdeploy_key_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_code_key_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upload_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeploy_key_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_mms_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mdeploy_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mdeploy_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_framework_env_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36m_upload_code\u001b[0;34m(self, key_prefix, repack)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mrepacked_model_uri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepacked_model_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0msagemaker_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_kms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m             )\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/sagemaker/utils.py\u001b[0m in \u001b[0;36mrepack_model\u001b[0;34m(inference_script, source_directory, dependencies, model_uri, repacked_model_uri, sagemaker_session, kms_key)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_tmpdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         _create_or_update_code_dir(\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/sagemaker/utils.py\u001b[0m in \u001b[0;36m_extract_model\u001b[0;34m(model_uri, sagemaker_session, tmp)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mlocal_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tar_file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mdownload_file_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0mlocal_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file://\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/sagemaker/utils.py\u001b[0m in \u001b[0;36mdownload_file_from_url\u001b[0;34m(url, dst, sagemaker_session)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m     \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/sagemaker/utils.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(bucket_name, path, target, sagemaker_session)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0ms3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m     \u001b[0mbucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/boto3/s3/inject.py\u001b[0m in \u001b[0;36mbucket_download_file\u001b[0;34m(self, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    244\u001b[0m     return self.meta.client.download_file(\n\u001b[1;32m    245\u001b[0m         \u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         ExtraArgs=ExtraArgs, Callback=Callback, Config=Config)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/boto3/s3/inject.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    170\u001b[0m         return transfer.download_file(\n\u001b[1;32m    171\u001b[0m             \u001b[0mbucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             extra_args=ExtraArgs, callback=Callback)\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/boto3/s3/transfer.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[1;32m    305\u001b[0m             bucket, key, filename, extra_args, subscribers)\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;31m# This is for backwards compatibility where when retries are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# exceeded we need to throw the same error from boto3 instead of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/s3transfer/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# however if a KeyboardInterrupt is raised we want want to exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# out of this and propogate the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/s3transfer/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# final result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/s3transfer/tasks.py\u001b[0m in \u001b[0;36m_main\u001b[0;34m(self, transfer_future, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# Call the submit method to start submitting tasks to execute the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;31m# transfer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# If there was an exception raised during the submission of task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/s3transfer/download.py\u001b[0m in \u001b[0;36m_submit\u001b[0;34m(self, client, config, osutil, request_executor, io_executor, transfer_future, bandwidth_limiter)\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m             )\n\u001b[1;32m    345\u001b[0m             transfer_future.meta.provide_transfer_size(\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (404) when calling the HeadObject operation: Not Found"
     ]
    }
   ],
   "source": [
    "predictor = pytorch_model.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge', wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install python package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install python packages to load sample test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q librosa==0.7.2 numba==0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference on sample test data\n",
    "\n",
    "Create dataloader to perform inference by batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "class UrbanSoundDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, csv_path: Path, file_path: Path, folderList: Iterable[int], new_sr=8000, audio_len=20, sampling_ratio=5\n",
    "    ):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            csv_path (Path): Path to dataset metadata csv\n",
    "            file_path (Path): Path to data folders\n",
    "            folderList (Iterable[int]): Data folders to be included in dataset\n",
    "            new_sr (int, optional): New sampling rate. Defaults to 8000.\n",
    "            audio_len (int, optional): Audio length based on new sampling rate (sec). Defaults to 20.\n",
    "            sampling_ratio (int, optional): Additional downsampling ratio. Defaults to 5.\n",
    "        \"\"\"\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.file_names = []\n",
    "        self.labels = []\n",
    "        self.folders = []\n",
    "        for i in range(0, len(df)):\n",
    "            if df.iloc[i, 5] in list(folderList):\n",
    "                self.labels.append(df.iloc[i, 6])\n",
    "                self.folders.append(df.iloc[i, 5])\n",
    "                temp = \"fold\" + str(df.iloc[i, 5]) + \"/\" + str(df.iloc[i, 0])\n",
    "                temp = file_path / temp\n",
    "                self.file_names.append(temp)\n",
    "\n",
    "        self.file_path = Path(file_path)\n",
    "        self.folderList = folderList\n",
    "        self.new_sr = new_sr\n",
    "        self.audio_len = audio_len\n",
    "        self.sampling_ratio = sampling_ratio\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # format the file path and load the file\n",
    "        path = self.file_names[index]\n",
    "        sound, sr = librosa.core.load(str(path), mono=False, sr=None)\n",
    "        if sound.ndim < 2:\n",
    "            sound = np.expand_dims(sound, axis=0)\n",
    "        # Convert into single channel format\n",
    "        sound = sound.mean(axis=0, keepdims=True)\n",
    "        # Downsampling\n",
    "        sound = librosa.core.resample(sound, orig_sr=sr, target_sr=self.new_sr)\n",
    "\n",
    "        # Zero padding to keep desired audio length in seconds\n",
    "        const_len = self.new_sr * self.audio_len\n",
    "        tempData = np.zeros([1, const_len])\n",
    "        if sound.shape[1] < const_len:\n",
    "            tempData[0, : sound.shape[1]] = sound[:]\n",
    "        else:\n",
    "            tempData[0, :] = sound[0, :const_len]\n",
    "        sound = tempData\n",
    "        # Resampling\n",
    "        new_const_len = const_len // self.sampling_ratio\n",
    "        soundFormatted = torch.zeros([1, new_const_len])\n",
    "        soundFormatted[0, :] = torch.tensor(sound[0, ::5], dtype=float)\n",
    "\n",
    "        return soundFormatted, self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the class labels.\n",
    "\n",
    "```\n",
    "0 = airconditioner \n",
    "1 = carhorn\n",
    "2 = childrenplaying \n",
    "3 = dogbark\n",
    "4 = drilling\n",
    "5 = engineidling \n",
    "6 = gunshot\n",
    "7 = jackhammer\n",
    "8 = siren\n",
    "9 = street_music\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = [10]\n",
    "datapath = Path(\"../data/UrbanSound8K\")\n",
    "csvpath = datapath / \"UrbanSound8K.csv\"\n",
    "\n",
    "test_set = UrbanSoundDataset(csvpath, datapath, test_folder)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32000]) tensor([4, 8, 0, 8, 7])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(test_loader))\n",
    "print(X.shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 0 7 7]\n"
     ]
    }
   ],
   "source": [
    "response = predictor.predict(X.numpy())\n",
    "response = np.transpose(response, (1, 0, 2))\n",
    "prediction = response[0].argmax(axis=1)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Optional Cleanup\n",
    "\n",
    "When you're done with the endpoint, you should clean it up.\n",
    "\n",
    "All of the training jobs, models and endpoints we created can be viewed through the SageMaker console of your AWS account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox36",
   "language": "python",
   "name": "sandbox36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
