{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create custom container using SageMaker PyTorch Deep Learning Framework\n",
    "\n",
    "Update `role` with your SageMaker role arn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 20.2.1 from /Users/yihyap/anaconda3/envs/smv2/lib/python3.8/site-packages/pip (python 3.8)\n"
     ]
    }
   ],
   "source": [
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account: 342474125894\n",
      "Region: ap-southeast-1\n",
      "Role: arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\n",
      "S3 Bucket: sagemaker-ap-southeast-1-342474125894\n",
      "Repo: sagemaker-training-containers/pytorch-training\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ecr_namespace = 'sagemaker-training-containers/'\n",
    "prefix = 'pytorch-training'\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = \"arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\"\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print('Account: {}'.format(account_id))\n",
    "print('Region: {}'.format(region))\n",
    "print('Role: {}'.format(role))\n",
    "print('S3 Bucket: {}'.format(bucket))\n",
    "print('Repo: {}'.format(ecr_repository_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build training container\n",
    "\n",
    "Next we will create a script that will build and upload the custom container image into ECR. It has to be in the same region where the job is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid argument \"../docker\" for \"-t, --tag\" flag: invalid reference format\n",
      "See 'docker build --help'.\n",
      "\"docker tag\" requires exactly 2 arguments.\n",
      "See 'docker tag --help'.\n",
      "\n",
      "Usage:  docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]\n",
      "\n",
      "Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE\n",
      "usage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]\n",
      "To see help text, you can run:\n",
      "\n",
      "  aws help\n",
      "  aws <command> help\n",
      "  aws <command> <subcommand> help\n",
      "aws: error: argument --region: expected one argument\n",
      "Error: Cannot perform an interactive login from a non TTY device\n",
      "\n",
      "Parameter validation failed:\n",
      "Invalid length for parameter repositoryNames, value: 0, valid range: 1-inf\n",
      "usage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]\n",
      "To see help text, you can run:\n",
      "\n",
      "  aws help\n",
      "  aws <command> help\n",
      "  aws <command> <subcommand> help\n",
      "aws: error: argument --repository-name: expected one argument\n",
      "invalid reference format\n"
     ]
    }
   ],
   "source": [
    "# ./build_and_push.sh 342474125894 ap-southeast-1 sagemaker-training-containers/pytorch-training\n",
    "! ../scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECR training container ARN: 342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/pytorch-training:latest\n"
     ]
    }
   ],
   "source": [
    "train_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, ecr_repository_name)\n",
    "print('ECR training container ARN: {}'.format(train_image_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The docker image is now pushed to ECR. In the next section, we will show how to train an acoustic classification model using the custom container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Training on SageMaker PyTorch custom container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-11 12:33:43 Starting - Starting the training job...\n",
      "2020-08-11 12:33:45 Starting - Launching requested ML instances......\n",
      "2020-08-11 12:35:13 Starting - Preparing the instances for training......\n",
      "2020-08-11 12:35:58 Downloading - Downloading input data\n",
      "2020-08-11 12:35:58 Training - Downloading the training image......\n",
      "2020-08-11 12:37:08 Uploading - Uploading generated training model\n",
      "2020-08-11 12:37:08 Completed - Training job completed\n",
      "\u001b[34m2020-08-11 12:36:57,534 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-11 12:37:03,777 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-11 12:37:03,790 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-11 12:37:03,801 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"seed\": 1,\n",
      "        \"epochs\": 50\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-08-11-12-33-56-086\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":50,\"seed\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":50,\"seed\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-08-11-12-33-56-086\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"50\",\"--seed\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_SEED=1\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=50\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 train.py --epochs 50 --seed 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNamespace(batch_size=64, epochs=50, log_interval=10, lr=0.1, model_dir='/opt/ml/model', save_model=False, seed=1, train=None, validation=None)\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in train channel: \u001b[0m\n",
      "\u001b[34mSM_CHANNEL is not set\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in validation channel: \u001b[0m\n",
      "\u001b[34mSM_CHANNEL is not set\u001b[0m\n",
      "\u001b[34mDevice: cpu\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [0/700 (0%)]#011Loss: 1.246465\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [600/700 (91%)]#011Loss: 0.402991\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [0/700 (0%)]#011Loss: 0.363496\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [600/700 (91%)]#011Loss: 0.274379\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [0/700 (0%)]#011Loss: 0.247654\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [600/700 (91%)]#011Loss: 0.190433\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [0/700 (0%)]#011Loss: 0.136744\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [600/700 (91%)]#011Loss: 0.134895\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [0/700 (0%)]#011Loss: 0.219409\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [600/700 (91%)]#011Loss: 0.115372\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [0/700 (0%)]#011Loss: 0.200042\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [600/700 (91%)]#011Loss: 0.167996\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [0/700 (0%)]#011Loss: 0.283195\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [600/700 (91%)]#011Loss: 0.199422\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [0/700 (0%)]#011Loss: 0.109881\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [600/700 (91%)]#011Loss: 0.146233\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [0/700 (0%)]#011Loss: 0.243325\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [600/700 (91%)]#011Loss: 0.074036\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [0/700 (0%)]#011Loss: 0.219839\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [600/700 (91%)]#011Loss: 0.113918\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [0/700 (0%)]#011Loss: 0.066527\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [600/700 (91%)]#011Loss: 0.174719\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [0/700 (0%)]#011Loss: 0.072640\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [600/700 (91%)]#011Loss: 0.133258\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [0/700 (0%)]#011Loss: 0.243909\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [600/700 (91%)]#011Loss: 0.128473\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [0/700 (0%)]#011Loss: 0.235559\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [600/700 (91%)]#011Loss: 0.223389\u001b[0m\n",
      "\u001b[34mTrain Epoch: 15 [0/700 (0%)]#011Loss: 0.121445\u001b[0m\n",
      "\u001b[34mTrain Epoch: 15 [600/700 (91%)]#011Loss: 0.193082\u001b[0m\n",
      "\u001b[34mTrain Epoch: 16 [0/700 (0%)]#011Loss: 0.063812\u001b[0m\n",
      "\u001b[34mTrain Epoch: 16 [600/700 (91%)]#011Loss: 0.085707\u001b[0m\n",
      "\u001b[34mTrain Epoch: 17 [0/700 (0%)]#011Loss: 0.178552\u001b[0m\n",
      "\u001b[34mTrain Epoch: 17 [600/700 (91%)]#011Loss: 0.164557\u001b[0m\n",
      "\u001b[34mTrain Epoch: 18 [0/700 (0%)]#011Loss: 0.220178\u001b[0m\n",
      "\u001b[34mTrain Epoch: 18 [600/700 (91%)]#011Loss: 0.209136\u001b[0m\n",
      "\u001b[34mTrain Epoch: 19 [0/700 (0%)]#011Loss: 0.057292\u001b[0m\n",
      "\u001b[34mTrain Epoch: 19 [600/700 (91%)]#011Loss: 0.211054\u001b[0m\n",
      "\u001b[34mTrain Epoch: 20 [0/700 (0%)]#011Loss: 0.255197\u001b[0m\n",
      "\u001b[34mTrain Epoch: 20 [600/700 (91%)]#011Loss: 0.290681\u001b[0m\n",
      "\u001b[34mTrain Epoch: 21 [0/700 (0%)]#011Loss: 0.169475\u001b[0m\n",
      "\u001b[34mTrain Epoch: 21 [600/700 (91%)]#011Loss: 0.056139\u001b[0m\n",
      "\u001b[34mTrain Epoch: 22 [0/700 (0%)]#011Loss: 0.042849\u001b[0m\n",
      "\u001b[34mTrain Epoch: 22 [600/700 (91%)]#011Loss: 0.182004\u001b[0m\n",
      "\u001b[34mTrain Epoch: 23 [0/700 (0%)]#011Loss: 0.224415\u001b[0m\n",
      "\u001b[34mTrain Epoch: 23 [600/700 (91%)]#011Loss: 0.158556\u001b[0m\n",
      "\u001b[34mTrain Epoch: 24 [0/700 (0%)]#011Loss: 0.056994\u001b[0m\n",
      "\u001b[34mTrain Epoch: 24 [600/700 (91%)]#011Loss: 0.199269\u001b[0m\n",
      "\u001b[34mTrain Epoch: 25 [0/700 (0%)]#011Loss: 0.155457\u001b[0m\n",
      "\u001b[34mTrain Epoch: 25 [600/700 (91%)]#011Loss: 0.237527\u001b[0m\n",
      "\u001b[34mTrain Epoch: 26 [0/700 (0%)]#011Loss: 0.200539\u001b[0m\n",
      "\u001b[34mTrain Epoch: 26 [600/700 (91%)]#011Loss: 0.046677\u001b[0m\n",
      "\u001b[34mTrain Epoch: 27 [0/700 (0%)]#011Loss: 0.050108\u001b[0m\n",
      "\u001b[34mTrain Epoch: 27 [600/700 (91%)]#011Loss: 0.048362\u001b[0m\n",
      "\u001b[34mTrain Epoch: 28 [0/700 (0%)]#011Loss: 0.060574\u001b[0m\n",
      "\u001b[34mTrain Epoch: 28 [600/700 (91%)]#011Loss: 0.194338\u001b[0m\n",
      "\u001b[34mTrain Epoch: 29 [0/700 (0%)]#011Loss: 0.098406\u001b[0m\n",
      "\u001b[34mTrain Epoch: 29 [600/700 (91%)]#011Loss: 0.154718\u001b[0m\n",
      "\u001b[34mTrain Epoch: 30 [0/700 (0%)]#011Loss: 0.169508\u001b[0m\n",
      "\u001b[34mTrain Epoch: 30 [600/700 (91%)]#011Loss: 0.256905\u001b[0m\n",
      "\u001b[34mTrain Epoch: 31 [0/700 (0%)]#011Loss: 0.198465\u001b[0m\n",
      "\u001b[34mTrain Epoch: 31 [600/700 (91%)]#011Loss: 0.085757\u001b[0m\n",
      "\u001b[34mTrain Epoch: 32 [0/700 (0%)]#011Loss: 0.078371\u001b[0m\n",
      "\u001b[34mTrain Epoch: 32 [600/700 (91%)]#011Loss: 0.076397\u001b[0m\n",
      "\u001b[34mTrain Epoch: 33 [0/700 (0%)]#011Loss: 0.068212\u001b[0m\n",
      "\u001b[34mTrain Epoch: 33 [600/700 (91%)]#011Loss: 0.139404\u001b[0m\n",
      "\u001b[34mTrain Epoch: 34 [0/700 (0%)]#011Loss: 0.059278\u001b[0m\n",
      "\u001b[34mTrain Epoch: 34 [600/700 (91%)]#011Loss: 0.261709\u001b[0m\n",
      "\u001b[34mTrain Epoch: 35 [0/700 (0%)]#011Loss: 0.039707\u001b[0m\n",
      "\u001b[34mTrain Epoch: 35 [600/700 (91%)]#011Loss: 0.404582\u001b[0m\n",
      "\u001b[34mTrain Epoch: 36 [0/700 (0%)]#011Loss: 0.100960\u001b[0m\n",
      "\u001b[34mTrain Epoch: 36 [600/700 (91%)]#011Loss: 0.160217\u001b[0m\n",
      "\u001b[34mTrain Epoch: 37 [0/700 (0%)]#011Loss: 0.269739\u001b[0m\n",
      "\u001b[34mTrain Epoch: 37 [600/700 (91%)]#011Loss: 0.113497\u001b[0m\n",
      "\u001b[34mTrain Epoch: 38 [0/700 (0%)]#011Loss: 0.065836\u001b[0m\n",
      "\u001b[34mTrain Epoch: 38 [600/700 (91%)]#011Loss: 0.050971\u001b[0m\n",
      "\u001b[34mTrain Epoch: 39 [0/700 (0%)]#011Loss: 0.153710\u001b[0m\n",
      "\u001b[34mTrain Epoch: 39 [600/700 (91%)]#011Loss: 0.093884\u001b[0m\n",
      "\u001b[34mTrain Epoch: 40 [0/700 (0%)]#011Loss: 0.160933\u001b[0m\n",
      "\u001b[34mTrain Epoch: 40 [600/700 (91%)]#011Loss: 0.157435\u001b[0m\n",
      "\u001b[34mTrain Epoch: 41 [0/700 (0%)]#011Loss: 0.194713\u001b[0m\n",
      "\u001b[34mTrain Epoch: 41 [600/700 (91%)]#011Loss: 0.196359\u001b[0m\n",
      "\u001b[34mTrain Epoch: 42 [0/700 (0%)]#011Loss: 0.122460\u001b[0m\n",
      "\u001b[34mTrain Epoch: 42 [600/700 (91%)]#011Loss: 0.073653\u001b[0m\n",
      "\u001b[34mTrain Epoch: 43 [0/700 (0%)]#011Loss: 0.042496\u001b[0m\n",
      "\u001b[34mTrain Epoch: 43 [600/700 (91%)]#011Loss: 0.079883\u001b[0m\n",
      "\u001b[34mTrain Epoch: 44 [0/700 (0%)]#011Loss: 0.264662\u001b[0m\n",
      "\u001b[34mTrain Epoch: 44 [600/700 (91%)]#011Loss: 0.250606\u001b[0m\n",
      "\u001b[34mTrain Epoch: 45 [0/700 (0%)]#011Loss: 0.108772\u001b[0m\n",
      "\u001b[34mTrain Epoch: 45 [600/700 (91%)]#011Loss: 0.346386\u001b[0m\n",
      "\u001b[34mTrain Epoch: 46 [0/700 (0%)]#011Loss: 0.072548\u001b[0m\n",
      "\u001b[34mTrain Epoch: 46 [600/700 (91%)]#011Loss: 0.228464\u001b[0m\n",
      "\u001b[34mTrain Epoch: 47 [0/700 (0%)]#011Loss: 0.167562\u001b[0m\n",
      "\u001b[34mTrain Epoch: 47 [600/700 (91%)]#011Loss: 0.220678\u001b[0m\n",
      "\u001b[34mTrain Epoch: 48 [0/700 (0%)]#011Loss: 0.135641\u001b[0m\n",
      "\u001b[34mTrain Epoch: 48 [600/700 (91%)]#011Loss: 0.067597\u001b[0m\n",
      "\u001b[34mTrain Epoch: 49 [0/700 (0%)]#011Loss: 0.042293\u001b[0m\n",
      "\u001b[34mTrain Epoch: 49 [600/700 (91%)]#011Loss: 0.100951\u001b[0m\n",
      "\u001b[34mTrain Epoch: 50 [0/700 (0%)]#011Loss: 0.073045\u001b[0m\n",
      "\u001b[34mTrain Epoch: 50 [600/700 (91%)]#011Loss: 0.109161\n",
      "\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0923, Accuracy: 294/300 (98%)\n",
      "\u001b[0m\n",
      "\u001b[34m2020-08-11 12:37:06,383 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 78\n",
      "Billable seconds: 78\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "\n",
    "hyperparameters = {\n",
    "    \"seed\": \"1\",\n",
    "    \"epochs\": 50,\n",
    "}\n",
    "\n",
    "est = sagemaker.estimator.Estimator(train_image_uri,\n",
    "                                    role,\n",
    "                                    instance_count=1, \n",
    "                                    #instance_type='local', # we use local mode\n",
    "                                    instance_type='ml.m5.xlarge',\n",
    "                                    base_job_name=prefix,\n",
    "                                    hyperparameters=hyperparameters)\n",
    "\n",
    "\n",
    "est.fit()\n",
    "\n",
    "#train_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "#val_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "#est.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve model location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-342474125894/pytorch-training-2020-08-11-12-33-56-086/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_location = est.model_data\n",
    "print(model_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Inference\n",
    "\n",
    "For inference, we will use default inference image. Mandatory `model_fn` is implemented in `inference.py`. PyTorchModel is used to deploy custom model that we trained previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data=\"s3://sagemaker-ap-southeast-1-342474125894/pytorch-training-2020-08-11-15-05-07-606/output/model.tar.gz\", \n",
    "                             role=role, \n",
    "                             entry_point='inference.py',\n",
    "                             source_dir='../docker/code',\n",
    "                             py_version='py3',\n",
    "                             framework_version='1.5',\n",
    "                            )\n",
    "predictor = pytorch_model.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge', wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchPredictor\n",
    "\n",
    "endpoint_name = \"pytorch-inference-2020-08-12-08-52-57-488\"\n",
    "\n",
    "# The PyTorch model uses a npy serializer and deserializer by default\n",
    "predictor = PyTorchPredictor(endpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.78976059e+00 -8.42716694e+00 -2.74858845e-04]\n",
      " [-1.21343966e+01 -1.20159941e+01 -1.14440263e-05]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "payload = torch.tensor(np.array([[1,2,3,4,5],[2,3,4,5,6]]), dtype=torch.float)\n",
    "response = predictor.predict(payload)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Optional Cleanup\n",
    "\n",
    "When you're done with the endpoint, you should clean it up.\n",
    "\n",
    "All of the training jobs, models and endpoints we created can be viewed through the SageMaker console of your AWS account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_features, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        #x = x.reshape(-1,3)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.4697e+00, -6.5448e+00, -2.9917e-03],\n",
       "        [-7.9158e+00, -8.4261e+00, -5.8419e-04]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = torch.tensor(np.array([[1,2,3,4,5],[2,3,4,5,6]]), dtype=torch.float)\n",
    "model(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "X, Y = make_classification(\n",
    "    n_samples=100,\n",
    "    n_features=5,\n",
    "    n_redundant=0,\n",
    "    n_informative=2,\n",
    "    n_clusters_per_class=1,\n",
    "    n_classes=3,\n",
    ")\n",
    "\n",
    "features = torch.FloatTensor(X[0])\n",
    "labels = torch.LongTensor(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.60699847, -0.25228405, -0.76545418,  1.23142814,  0.68585389])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6070, -0.2523, -0.7655,  1.2314,  0.6859])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3977854284320629293])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4503928797958963200,                   8])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(Y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(Y[0], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 0, 0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (virtualenv_p38smv2)",
   "language": "python",
   "name": "virtualenv_p38smv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
