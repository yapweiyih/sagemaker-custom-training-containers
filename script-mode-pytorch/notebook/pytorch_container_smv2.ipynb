{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create custom container using SageMaker PyTorch Deep Learning Framework\n",
    "\n",
    "Update `role` with your SageMaker role arn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 20.1 from /Users/yihyap/anaconda3/envs/sandbox36/lib/python3.6/site-packages/pip (python 3.6)\r\n"
     ]
    }
   ],
   "source": [
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account: 342474125894\n",
      "Region: ap-southeast-1\n",
      "Role: arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\n",
      "S3 Bucket: sagemaker-ap-southeast-1-342474125894\n",
      "Repo: sagemaker-training-containers/pytorch-training\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ecr_namespace = 'sagemaker-training-containers/'\n",
    "prefix = 'pytorch-training'\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = \"arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\"\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print('Account: {}'.format(account_id))\n",
    "print('Region: {}'.format(region))\n",
    "print('Role: {}'.format(role))\n",
    "print('S3 Bucket: {}'.format(bucket))\n",
    "print('Repo: {}'.format(ecr_repository_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build training container\n",
    "\n",
    "Next we will create a script that will build and upload the custom container image into ECR. It has to be in the same region where the job is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  19.46kB\n",
      "Step 1/16 : FROM ubuntu:16.04\n",
      " ---> 13c9f1285025\n",
      "Step 2/16 : LABEL maintainer=\"Giuseppe A. Porcelli\"\n",
      " ---> Using cache\n",
      " ---> 6bbf3d07c68d\n",
      "Step 3/16 : ARG PYTHON=python3\n",
      " ---> Using cache\n",
      " ---> 8e254b9ef0a0\n",
      "Step 4/16 : ARG PYTHON_PIP=python3-pip\n",
      " ---> Using cache\n",
      " ---> 84c928b11bb3\n",
      "Step 5/16 : ARG PIP=pip3\n",
      " ---> Using cache\n",
      " ---> 65e780b1f9d7\n",
      "Step 6/16 : ARG PYTHON_VERSION=3.6.6\n",
      " ---> Using cache\n",
      " ---> 03bab72f170e\n",
      "Step 7/16 : RUN apt-get update && apt-get install -y --no-install-recommends software-properties-common &&     add-apt-repository ppa:deadsnakes/ppa -y &&     apt-get update && apt-get install -y --no-install-recommends         build-essential         ca-certificates         curl         wget         git         libopencv-dev         openssh-client         openssh-server         vim         zlib1g-dev &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 0b3f66ca4c73\n",
      "Step 8/16 : RUN wget https://www.python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tgz &&         tar -xvf Python-$PYTHON_VERSION.tgz && cd Python-$PYTHON_VERSION &&         ./configure && make && make install &&         apt-get update && apt-get install -y --no-install-recommends libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev &&         make && make install && rm -rf ../Python-$PYTHON_VERSION* &&         ln -s /usr/local/bin/pip3 /usr/bin/pip\n",
      " ---> Using cache\n",
      " ---> da24d9684dbd\n",
      "Step 9/16 : RUN ${PIP} --no-cache-dir install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> a7e0f5c77b12\n",
      "Step 10/16 : RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
      " ---> Using cache\n",
      " ---> 9970f3a50688\n",
      "Step 11/16 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 7185a26a84ec\n",
      "Step 12/16 : RUN ${PIP} install --no-cache --upgrade         numpy==1.14.5         pandas==0.24.1         scikit-learn==0.20.3         requests==2.21.0         scipy==1.2.1         torch         torchaudio\n",
      " ---> Using cache\n",
      " ---> b994da0ad189\n",
      "Step 13/16 : ENV PYTHONDONTWRITEBYTECODE=1     PYTHONUNBUFFERED=1     LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\"     PYTHONIOENCODING=UTF-8     LANG=C.UTF-8     LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 534c9458df19\n",
      "Step 14/16 : RUN ${PIP} install --no-cache --upgrade     sagemaker-containers\n",
      " ---> Using cache\n",
      " ---> 8a9b3ea0d6eb\n",
      "Step 15/16 : COPY code/* /opt/ml/code/\n",
      " ---> Using cache\n",
      " ---> 6c0c233832e7\n",
      "Step 16/16 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Using cache\n",
      " ---> ec805fbf5f9c\n",
      "Successfully built ec805fbf5f9c\n",
      "Successfully tagged sagemaker-training-containers/pytorch-training:latest\n",
      "Login Succeeded\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryUri\": \"342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/pytorch-training\", \n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            }, \n",
      "            \"registryId\": \"342474125894\", \n",
      "            \"imageTagMutability\": \"MUTABLE\", \n",
      "            \"repositoryArn\": \"arn:aws:ecr:ap-southeast-1:342474125894:repository/sagemaker-training-containers/pytorch-training\", \n",
      "            \"repositoryName\": \"sagemaker-training-containers/pytorch-training\", \n",
      "            \"createdAt\": 1597146062.0\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "The push refers to repository [342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/pytorch-training]\n",
      "\n",
      "\u001b[1B165bff5c: Preparing \n",
      "\u001b[1B98b4e3f3: Preparing \n",
      "\u001b[1Bc7c70141: Preparing \n",
      "\u001b[1B4a5b1e5b: Preparing \n",
      "\u001b[1B087edcda: Preparing \n",
      "\u001b[1B0ce8b97f: Preparing \n",
      "\u001b[1Bef1fd00d: Preparing \n",
      "\u001b[1Bf22d44f3: Preparing \n",
      "\u001b[1B6f329a25: Preparing \n",
      "\u001b[1B7de5faec: Preparing \n",
      "\u001b[1Ba27b0484: Layer already exists \u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2Klatest: digest: sha256:342ead59edb22c6315f2ebd5858515cebb8765089003b0871fa76480e92da90e size: 2626\n"
     ]
    }
   ],
   "source": [
    "# ./build_and_push.sh 342474125894 ap-southeast-1 sagemaker-training-containers/pytorch-training\n",
    "! ../scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECR training container ARN: 342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/pytorch-training:latest\n"
     ]
    }
   ],
   "source": [
    "train_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, ecr_repository_name)\n",
    "print('ECR training container ARN: {}'.format(train_image_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The docker image is now pushed to ECR. In the next section, we will show how to train an acoustic classification model using the custom container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Training on SageMaker PyTorch custom container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-11 12:33:43 Starting - Starting the training job...\n",
      "2020-08-11 12:33:45 Starting - Launching requested ML instances......\n",
      "2020-08-11 12:35:13 Starting - Preparing the instances for training......\n",
      "2020-08-11 12:35:58 Downloading - Downloading input data\n",
      "2020-08-11 12:35:58 Training - Downloading the training image......\n",
      "2020-08-11 12:37:08 Uploading - Uploading generated training model\n",
      "2020-08-11 12:37:08 Completed - Training job completed\n",
      "\u001b[34m2020-08-11 12:36:57,534 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-11 12:37:03,777 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-11 12:37:03,790 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-11 12:37:03,801 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"seed\": 1,\n",
      "        \"epochs\": 50\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-08-11-12-33-56-086\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":50,\"seed\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":50,\"seed\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-08-11-12-33-56-086\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"50\",\"--seed\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_SEED=1\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=50\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 train.py --epochs 50 --seed 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNamespace(batch_size=64, epochs=50, log_interval=10, lr=0.1, model_dir='/opt/ml/model', save_model=False, seed=1, train=None, validation=None)\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in train channel: \u001b[0m\n",
      "\u001b[34mSM_CHANNEL is not set\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in validation channel: \u001b[0m\n",
      "\u001b[34mSM_CHANNEL is not set\u001b[0m\n",
      "\u001b[34mDevice: cpu\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [0/700 (0%)]#011Loss: 1.246465\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [600/700 (91%)]#011Loss: 0.402991\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [0/700 (0%)]#011Loss: 0.363496\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [600/700 (91%)]#011Loss: 0.274379\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [0/700 (0%)]#011Loss: 0.247654\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [600/700 (91%)]#011Loss: 0.190433\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [0/700 (0%)]#011Loss: 0.136744\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [600/700 (91%)]#011Loss: 0.134895\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [0/700 (0%)]#011Loss: 0.219409\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [600/700 (91%)]#011Loss: 0.115372\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [0/700 (0%)]#011Loss: 0.200042\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [600/700 (91%)]#011Loss: 0.167996\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [0/700 (0%)]#011Loss: 0.283195\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [600/700 (91%)]#011Loss: 0.199422\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [0/700 (0%)]#011Loss: 0.109881\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [600/700 (91%)]#011Loss: 0.146233\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [0/700 (0%)]#011Loss: 0.243325\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [600/700 (91%)]#011Loss: 0.074036\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [0/700 (0%)]#011Loss: 0.219839\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [600/700 (91%)]#011Loss: 0.113918\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [0/700 (0%)]#011Loss: 0.066527\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [600/700 (91%)]#011Loss: 0.174719\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [0/700 (0%)]#011Loss: 0.072640\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [600/700 (91%)]#011Loss: 0.133258\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [0/700 (0%)]#011Loss: 0.243909\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [600/700 (91%)]#011Loss: 0.128473\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [0/700 (0%)]#011Loss: 0.235559\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [600/700 (91%)]#011Loss: 0.223389\u001b[0m\n",
      "\u001b[34mTrain Epoch: 15 [0/700 (0%)]#011Loss: 0.121445\u001b[0m\n",
      "\u001b[34mTrain Epoch: 15 [600/700 (91%)]#011Loss: 0.193082\u001b[0m\n",
      "\u001b[34mTrain Epoch: 16 [0/700 (0%)]#011Loss: 0.063812\u001b[0m\n",
      "\u001b[34mTrain Epoch: 16 [600/700 (91%)]#011Loss: 0.085707\u001b[0m\n",
      "\u001b[34mTrain Epoch: 17 [0/700 (0%)]#011Loss: 0.178552\u001b[0m\n",
      "\u001b[34mTrain Epoch: 17 [600/700 (91%)]#011Loss: 0.164557\u001b[0m\n",
      "\u001b[34mTrain Epoch: 18 [0/700 (0%)]#011Loss: 0.220178\u001b[0m\n",
      "\u001b[34mTrain Epoch: 18 [600/700 (91%)]#011Loss: 0.209136\u001b[0m\n",
      "\u001b[34mTrain Epoch: 19 [0/700 (0%)]#011Loss: 0.057292\u001b[0m\n",
      "\u001b[34mTrain Epoch: 19 [600/700 (91%)]#011Loss: 0.211054\u001b[0m\n",
      "\u001b[34mTrain Epoch: 20 [0/700 (0%)]#011Loss: 0.255197\u001b[0m\n",
      "\u001b[34mTrain Epoch: 20 [600/700 (91%)]#011Loss: 0.290681\u001b[0m\n",
      "\u001b[34mTrain Epoch: 21 [0/700 (0%)]#011Loss: 0.169475\u001b[0m\n",
      "\u001b[34mTrain Epoch: 21 [600/700 (91%)]#011Loss: 0.056139\u001b[0m\n",
      "\u001b[34mTrain Epoch: 22 [0/700 (0%)]#011Loss: 0.042849\u001b[0m\n",
      "\u001b[34mTrain Epoch: 22 [600/700 (91%)]#011Loss: 0.182004\u001b[0m\n",
      "\u001b[34mTrain Epoch: 23 [0/700 (0%)]#011Loss: 0.224415\u001b[0m\n",
      "\u001b[34mTrain Epoch: 23 [600/700 (91%)]#011Loss: 0.158556\u001b[0m\n",
      "\u001b[34mTrain Epoch: 24 [0/700 (0%)]#011Loss: 0.056994\u001b[0m\n",
      "\u001b[34mTrain Epoch: 24 [600/700 (91%)]#011Loss: 0.199269\u001b[0m\n",
      "\u001b[34mTrain Epoch: 25 [0/700 (0%)]#011Loss: 0.155457\u001b[0m\n",
      "\u001b[34mTrain Epoch: 25 [600/700 (91%)]#011Loss: 0.237527\u001b[0m\n",
      "\u001b[34mTrain Epoch: 26 [0/700 (0%)]#011Loss: 0.200539\u001b[0m\n",
      "\u001b[34mTrain Epoch: 26 [600/700 (91%)]#011Loss: 0.046677\u001b[0m\n",
      "\u001b[34mTrain Epoch: 27 [0/700 (0%)]#011Loss: 0.050108\u001b[0m\n",
      "\u001b[34mTrain Epoch: 27 [600/700 (91%)]#011Loss: 0.048362\u001b[0m\n",
      "\u001b[34mTrain Epoch: 28 [0/700 (0%)]#011Loss: 0.060574\u001b[0m\n",
      "\u001b[34mTrain Epoch: 28 [600/700 (91%)]#011Loss: 0.194338\u001b[0m\n",
      "\u001b[34mTrain Epoch: 29 [0/700 (0%)]#011Loss: 0.098406\u001b[0m\n",
      "\u001b[34mTrain Epoch: 29 [600/700 (91%)]#011Loss: 0.154718\u001b[0m\n",
      "\u001b[34mTrain Epoch: 30 [0/700 (0%)]#011Loss: 0.169508\u001b[0m\n",
      "\u001b[34mTrain Epoch: 30 [600/700 (91%)]#011Loss: 0.256905\u001b[0m\n",
      "\u001b[34mTrain Epoch: 31 [0/700 (0%)]#011Loss: 0.198465\u001b[0m\n",
      "\u001b[34mTrain Epoch: 31 [600/700 (91%)]#011Loss: 0.085757\u001b[0m\n",
      "\u001b[34mTrain Epoch: 32 [0/700 (0%)]#011Loss: 0.078371\u001b[0m\n",
      "\u001b[34mTrain Epoch: 32 [600/700 (91%)]#011Loss: 0.076397\u001b[0m\n",
      "\u001b[34mTrain Epoch: 33 [0/700 (0%)]#011Loss: 0.068212\u001b[0m\n",
      "\u001b[34mTrain Epoch: 33 [600/700 (91%)]#011Loss: 0.139404\u001b[0m\n",
      "\u001b[34mTrain Epoch: 34 [0/700 (0%)]#011Loss: 0.059278\u001b[0m\n",
      "\u001b[34mTrain Epoch: 34 [600/700 (91%)]#011Loss: 0.261709\u001b[0m\n",
      "\u001b[34mTrain Epoch: 35 [0/700 (0%)]#011Loss: 0.039707\u001b[0m\n",
      "\u001b[34mTrain Epoch: 35 [600/700 (91%)]#011Loss: 0.404582\u001b[0m\n",
      "\u001b[34mTrain Epoch: 36 [0/700 (0%)]#011Loss: 0.100960\u001b[0m\n",
      "\u001b[34mTrain Epoch: 36 [600/700 (91%)]#011Loss: 0.160217\u001b[0m\n",
      "\u001b[34mTrain Epoch: 37 [0/700 (0%)]#011Loss: 0.269739\u001b[0m\n",
      "\u001b[34mTrain Epoch: 37 [600/700 (91%)]#011Loss: 0.113497\u001b[0m\n",
      "\u001b[34mTrain Epoch: 38 [0/700 (0%)]#011Loss: 0.065836\u001b[0m\n",
      "\u001b[34mTrain Epoch: 38 [600/700 (91%)]#011Loss: 0.050971\u001b[0m\n",
      "\u001b[34mTrain Epoch: 39 [0/700 (0%)]#011Loss: 0.153710\u001b[0m\n",
      "\u001b[34mTrain Epoch: 39 [600/700 (91%)]#011Loss: 0.093884\u001b[0m\n",
      "\u001b[34mTrain Epoch: 40 [0/700 (0%)]#011Loss: 0.160933\u001b[0m\n",
      "\u001b[34mTrain Epoch: 40 [600/700 (91%)]#011Loss: 0.157435\u001b[0m\n",
      "\u001b[34mTrain Epoch: 41 [0/700 (0%)]#011Loss: 0.194713\u001b[0m\n",
      "\u001b[34mTrain Epoch: 41 [600/700 (91%)]#011Loss: 0.196359\u001b[0m\n",
      "\u001b[34mTrain Epoch: 42 [0/700 (0%)]#011Loss: 0.122460\u001b[0m\n",
      "\u001b[34mTrain Epoch: 42 [600/700 (91%)]#011Loss: 0.073653\u001b[0m\n",
      "\u001b[34mTrain Epoch: 43 [0/700 (0%)]#011Loss: 0.042496\u001b[0m\n",
      "\u001b[34mTrain Epoch: 43 [600/700 (91%)]#011Loss: 0.079883\u001b[0m\n",
      "\u001b[34mTrain Epoch: 44 [0/700 (0%)]#011Loss: 0.264662\u001b[0m\n",
      "\u001b[34mTrain Epoch: 44 [600/700 (91%)]#011Loss: 0.250606\u001b[0m\n",
      "\u001b[34mTrain Epoch: 45 [0/700 (0%)]#011Loss: 0.108772\u001b[0m\n",
      "\u001b[34mTrain Epoch: 45 [600/700 (91%)]#011Loss: 0.346386\u001b[0m\n",
      "\u001b[34mTrain Epoch: 46 [0/700 (0%)]#011Loss: 0.072548\u001b[0m\n",
      "\u001b[34mTrain Epoch: 46 [600/700 (91%)]#011Loss: 0.228464\u001b[0m\n",
      "\u001b[34mTrain Epoch: 47 [0/700 (0%)]#011Loss: 0.167562\u001b[0m\n",
      "\u001b[34mTrain Epoch: 47 [600/700 (91%)]#011Loss: 0.220678\u001b[0m\n",
      "\u001b[34mTrain Epoch: 48 [0/700 (0%)]#011Loss: 0.135641\u001b[0m\n",
      "\u001b[34mTrain Epoch: 48 [600/700 (91%)]#011Loss: 0.067597\u001b[0m\n",
      "\u001b[34mTrain Epoch: 49 [0/700 (0%)]#011Loss: 0.042293\u001b[0m\n",
      "\u001b[34mTrain Epoch: 49 [600/700 (91%)]#011Loss: 0.100951\u001b[0m\n",
      "\u001b[34mTrain Epoch: 50 [0/700 (0%)]#011Loss: 0.073045\u001b[0m\n",
      "\u001b[34mTrain Epoch: 50 [600/700 (91%)]#011Loss: 0.109161\n",
      "\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0923, Accuracy: 294/300 (98%)\n",
      "\u001b[0m\n",
      "\u001b[34m2020-08-11 12:37:06,383 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 78\n",
      "Billable seconds: 78\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "\n",
    "hyperparameters = {\n",
    "    \"seed\": \"1\",\n",
    "    \"epochs\": 50,\n",
    "}\n",
    "\n",
    "est = sagemaker.estimator.Estimator(train_image_uri,\n",
    "                                    role,\n",
    "                                    instance_count=1, \n",
    "                                    #instance_type='local', # we use local mode\n",
    "                                    instance_type='ml.m5.xlarge',\n",
    "                                    base_job_name=prefix,\n",
    "                                    hyperparameters=hyperparameters)\n",
    "\n",
    "\n",
    "est.fit()\n",
    "\n",
    "#train_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "#val_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "#est.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve model location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-342474125894/pytorch-training-2020-08-11-12-33-56-086/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_location = est.model_data\n",
    "print(model_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Inference\n",
    "\n",
    "For inference, we will use default inference image. Mandatory `model_fn` is implemented in `inference.py`. PyTorchModel is used to deploy custom model that we trained previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (404) when calling the HeadObject operation: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1c321faba5c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                              \u001b[0mframework_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1.5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                             )\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytorch_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ml.m5.xlarge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled_model_suffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_sagemaker_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         production_variant = sagemaker.production_variant(\n\u001b[1;32m    490\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_instance_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccelerator_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36m_create_sagemaker_model\u001b[0;34m(self, instance_type, accelerator_type, tags)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;34m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mservices\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;31m#SageMaker.Client.add_tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mcontainer_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_container_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccelerator_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_base_name_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer_def\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/sagemaker/pytorch/model.py\u001b[0m in \u001b[0;36mprepare_container_def\u001b[0;34m(self, instance_type, accelerator_type)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mdeploy_key_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_code_key_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upload_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeploy_key_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_mms_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mdeploy_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mdeploy_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_framework_env_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36m_upload_code\u001b[0;34m(self, key_prefix, repack)\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0mrepacked_model_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"s3://\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.tar.gz\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m             utils.repack_model(\n\u001b[0m\u001b[1;32m    859\u001b[0m                 \u001b[0minference_script\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                 \u001b[0msource_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/sagemaker/utils.py\u001b[0m in \u001b[0;36mrepack_model\u001b[0;34m(inference_script, source_directory, dependencies, model_uri, repacked_model_uri, sagemaker_session, kms_key)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_tmpdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         _create_or_update_code_dir(\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/sagemaker/utils.py\u001b[0m in \u001b[0;36m_extract_model\u001b[0;34m(model_uri, sagemaker_session, tmp)\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mlocal_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tar_file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mdownload_file_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mlocal_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file://\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/sagemaker/utils.py\u001b[0m in \u001b[0;36mdownload_file_from_url\u001b[0;34m(url, dst, sagemaker_session)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m     \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/sagemaker/utils.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(bucket_name, path, target, sagemaker_session)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0ms3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboto_region_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m     \u001b[0mbucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/boto3/s3/inject.py\u001b[0m in \u001b[0;36mbucket_download_file\u001b[0;34m(self, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mtransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \"\"\"\n\u001b[0;32m--> 244\u001b[0;31m     return self.meta.client.download_file(\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         ExtraArgs=ExtraArgs, Callback=Callback, Config=Config)\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/boto3/s3/inject.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \"\"\"\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mS3Transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransfer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         return transfer.download_file(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mbucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             extra_args=ExtraArgs, callback=Callback)\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/boto3/s3/transfer.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[1;32m    305\u001b[0m             bucket, key, filename, extra_args, subscribers)\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;31m# This is for backwards compatibility where when retries are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# exceeded we need to throw the same error from boto3 instead of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/s3transfer/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# however if a KeyboardInterrupt is raised we want want to exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# out of this and propogate the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/s3transfer/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# final result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/s3transfer/tasks.py\u001b[0m in \u001b[0;36m_main\u001b[0;34m(self, transfer_future, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# Call the submit method to start submitting tasks to execute the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;31m# transfer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# If there was an exception raised during the submission of task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/s3transfer/download.py\u001b[0m in \u001b[0;36m_submit\u001b[0;34m(self, client, config, osutil, request_executor, io_executor, transfer_future, bandwidth_limiter)\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;31m# If a size was not provided figure out the size for the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;31m# user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             response = client.head_object(\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/smv2/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (404) when calling the HeadObject operation: Not Found"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data=model_location, \n",
    "                             role=role, \n",
    "                             entry_point='inference.py',\n",
    "                             source_dir='../docker/code',\n",
    "                             py_version='py3',\n",
    "                             framework_version='1.5',\n",
    "                            )\n",
    "predictor = pytorch_model.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge', wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pytorch-inference-2020-07-24-07-58-57-213'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install python package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install python packages to load sample test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q librosa==0.7.2 numba==0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference on sample test data\n",
    "\n",
    "Create dataloader to perform inference by batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "class UrbanSoundDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, csv_path: Path, file_path: Path, folderList: Iterable[int], new_sr=8000, audio_len=20, sampling_ratio=5\n",
    "    ):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            csv_path (Path): Path to dataset metadata csv\n",
    "            file_path (Path): Path to data folders\n",
    "            folderList (Iterable[int]): Data folders to be included in dataset\n",
    "            new_sr (int, optional): New sampling rate. Defaults to 8000.\n",
    "            audio_len (int, optional): Audio length based on new sampling rate (sec). Defaults to 20.\n",
    "            sampling_ratio (int, optional): Additional downsampling ratio. Defaults to 5.\n",
    "        \"\"\"\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.file_names = []\n",
    "        self.labels = []\n",
    "        self.folders = []\n",
    "        for i in range(0, len(df)):\n",
    "            if df.iloc[i, 5] in list(folderList):\n",
    "                self.labels.append(df.iloc[i, 6])\n",
    "                self.folders.append(df.iloc[i, 5])\n",
    "                temp = \"fold\" + str(df.iloc[i, 5]) + \"/\" + str(df.iloc[i, 0])\n",
    "                temp = file_path / temp\n",
    "                self.file_names.append(temp)\n",
    "\n",
    "        self.file_path = Path(file_path)\n",
    "        self.folderList = folderList\n",
    "        self.new_sr = new_sr\n",
    "        self.audio_len = audio_len\n",
    "        self.sampling_ratio = sampling_ratio\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # format the file path and load the file\n",
    "        path = self.file_names[index]\n",
    "        sound, sr = librosa.core.load(str(path), mono=False, sr=None)\n",
    "        if sound.ndim < 2:\n",
    "            sound = np.expand_dims(sound, axis=0)\n",
    "        # Convert into single channel format\n",
    "        sound = sound.mean(axis=0, keepdims=True)\n",
    "        # Downsampling\n",
    "        sound = librosa.core.resample(sound, orig_sr=sr, target_sr=self.new_sr)\n",
    "\n",
    "        # Zero padding to keep desired audio length in seconds\n",
    "        const_len = self.new_sr * self.audio_len\n",
    "        tempData = np.zeros([1, const_len])\n",
    "        if sound.shape[1] < const_len:\n",
    "            tempData[0, : sound.shape[1]] = sound[:]\n",
    "        else:\n",
    "            tempData[0, :] = sound[0, :const_len]\n",
    "        sound = tempData\n",
    "        # Resampling\n",
    "        new_const_len = const_len // self.sampling_ratio\n",
    "        soundFormatted = torch.zeros([1, new_const_len])\n",
    "        soundFormatted[0, :] = torch.tensor(sound[0, ::5], dtype=float)\n",
    "\n",
    "        return soundFormatted, self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the class labels.\n",
    "\n",
    "```\n",
    "0 = airconditioner \n",
    "1 = carhorn\n",
    "2 = childrenplaying \n",
    "3 = dogbark\n",
    "4 = drilling\n",
    "5 = engineidling \n",
    "6 = gunshot\n",
    "7 = jackhammer\n",
    "8 = siren\n",
    "9 = street_music\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = [10]\n",
    "datapath = Path(\"../data/UrbanSound8K\")\n",
    "csvpath = datapath / \"UrbanSound8K.csv\"\n",
    "\n",
    "test_set = UrbanSoundDataset(csvpath, datapath, test_folder)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32000]) tensor([4, 8, 0, 8, 7])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(test_loader))\n",
    "print(X.shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 0 7 7]\n"
     ]
    }
   ],
   "source": [
    "response = predictor.predict(X.numpy())\n",
    "response = np.transpose(response, (1, 0, 2))\n",
    "prediction = response[0].argmax(axis=1)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Optional Cleanup\n",
    "\n",
    "When you're done with the endpoint, you should clean it up.\n",
    "\n",
    "All of the training jobs, models and endpoints we created can be viewed through the SageMaker console of your AWS account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smv2",
   "language": "python",
   "name": "smv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
