{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameter_ranges = {'lr': ContinuousParameter(0.001, 0.01),\n",
    "                         'n-epochs': IntegerParameter(100, 200)}<h1> Method 1: Train with custom XGB Container </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to build and use a custom Docker container for training with Amazon SageMaker that leverages on the <strong>Script Mode</strong> execution that is implemented by the sagemaker-containers library. Reference documentation is available at https://github.com/aws/sagemaker-containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining some variables like the current execution role, the ECR repository that we are going to use for pushing the custom Docker container and a default Amazon S3 bucket to be used by Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342474125894\n",
      "ap-southeast-1\n",
      "arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\n",
      "sagemaker-ap-southeast-1-342474125894\n",
      "sagemaker-training-containers/script-mode-container-xgb\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "ecr_namespace = 'sagemaker-training-containers/'\n",
    "prefix = 'script-mode-container-xgb'\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = \"arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\"\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)\n",
    "print(ecr_repository_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Build and push the container</h3>\n",
    "We are now ready to build this container and push it to Amazon ECR. This task is executed using a shell script stored in the ../script/ folder. Let's take a look at this script and then execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  24.58kB\n",
      "Step 1/16 : FROM ubuntu:16.04\n",
      " ---> 13c9f1285025\n",
      "Step 2/16 : LABEL maintainer=\"Giuseppe A. Porcelli\"\n",
      " ---> Using cache\n",
      " ---> 6bbf3d07c68d\n",
      "Step 3/16 : ARG PYTHON=python3\n",
      " ---> Using cache\n",
      " ---> 8e254b9ef0a0\n",
      "Step 4/16 : ARG PYTHON_PIP=python3-pip\n",
      " ---> Using cache\n",
      " ---> 84c928b11bb3\n",
      "Step 5/16 : ARG PIP=pip3\n",
      " ---> Using cache\n",
      " ---> 65e780b1f9d7\n",
      "Step 6/16 : ARG PYTHON_VERSION=3.6.6\n",
      " ---> Using cache\n",
      " ---> 03bab72f170e\n",
      "Step 7/16 : RUN apt-get update && apt-get install -y --no-install-recommends software-properties-common &&     add-apt-repository ppa:deadsnakes/ppa -y &&     apt-get update && apt-get install -y --no-install-recommends     build-essential     ca-certificates     curl     wget     git     libopencv-dev     openssh-client     openssh-server     vim     zlib1g-dev &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> e29c159657d9\n",
      "Step 8/16 : RUN wget https://www.python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tgz &&     tar -xvf Python-$PYTHON_VERSION.tgz && cd Python-$PYTHON_VERSION &&     ./configure && make && make install &&     apt-get update && apt-get install -y --no-install-recommends libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev &&     make && make install && rm -rf ../Python-$PYTHON_VERSION* &&     ln -s /usr/local/bin/pip3 /usr/bin/pip\n",
      " ---> Using cache\n",
      " ---> 5f344151a182\n",
      "Step 9/16 : RUN ${PIP} --no-cache-dir install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> eda3fb14df62\n",
      "Step 10/16 : RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
      " ---> Using cache\n",
      " ---> 36e695fcdc04\n",
      "Step 11/16 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 47c0eeca0f80\n",
      "Step 12/16 : RUN ${PIP} install --no-cache --upgrade     numpy==1.14.5     pandas==0.24.1     scikit-learn==0.20.3     requests==2.21.0     scipy==1.2.1     xgboost==1.1.1\n",
      " ---> Using cache\n",
      " ---> 8005d64e71ff\n",
      "Step 13/16 : ENV PYTHONDONTWRITEBYTECODE=1     PYTHONUNBUFFERED=1     LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\"     PYTHONIOENCODING=UTF-8     LANG=C.UTF-8     LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> d49a18978498\n",
      "Step 14/16 : RUN ${PIP} install --no-cache --upgrade     sagemaker-containers\n",
      " ---> Using cache\n",
      " ---> 1d33f1130683\n",
      "Step 15/16 : COPY code/* /opt/ml/code/\n",
      " ---> e616102c6518\n",
      "Step 16/16 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in 56aac28563de\n",
      "Removing intermediate container 56aac28563de\n",
      " ---> 69c7041cf251\n",
      "Successfully built 69c7041cf251\n",
      "Successfully tagged sagemaker-training-containers/script-mode-container-xgb:latest\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "Login Succeeded\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryArn\": \"arn:aws:ecr:ap-southeast-1:342474125894:repository/sagemaker-training-containers/script-mode-container-xgb\",\n",
      "            \"registryId\": \"342474125894\",\n",
      "            \"repositoryName\": \"sagemaker-training-containers/script-mode-container-xgb\",\n",
      "            \"repositoryUri\": \"342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/script-mode-container-xgb\",\n",
      "            \"createdAt\": 1597065421.0,\n",
      "            \"imageTagMutability\": \"MUTABLE\",\n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            },\n",
      "            \"encryptionConfiguration\": {\n",
      "                \"encryptionType\": \"AES256\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "The push refers to repository [342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/script-mode-container-xgb]\n",
      "\n",
      "\u001b[1Bdabfcd40: Preparing \n",
      "\u001b[1B707974b2: Preparing \n",
      "\u001b[1B2b5574ba: Preparing \n",
      "\u001b[1Bfc276494: Preparing \n",
      "\u001b[1Bb7f4d226: Preparing \n",
      "\u001b[1B136c651b: Preparing \n",
      "\u001b[1Bb57b75a1: Preparing \n",
      "\u001b[1Bf22d44f3: Preparing \n",
      "\u001b[1B6f329a25: Preparing \n",
      "\u001b[1B7de5faec: Preparing \n",
      "\u001b[11Babfcd40: Pushed lready exists \u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[11A\u001b[2Klatest: digest: sha256:1af8a5980f36b1255eac474ce6740522f50b916af192e899551bf855cc095548 size: 2626\n"
     ]
    }
   ],
   "source": [
    "! ../scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training with Amazon SageMaker</h3>\n",
    "\n",
    "Once we have correctly pushed our container to Amazon ECR, we are ready to start training with Amazon SageMaker, which requires the ECR path to the Docker container used for training as parameter for starting a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/script-mode-container-xgb:latest\n"
     ]
    }
   ],
   "source": [
    "container_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, ecr_repository_name)\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can realize that the training code has been implemented as a standard Python script, that will be invoked by the sagemaker-containers library passing hyperparameters as arguments. This way of invoking training script is indeed called <strong>Script Mode</strong> for Amazon SageMaker containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare Data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we upload some dummy data to Amazon S3, in order to define our S3-based training channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (100, 5), y:(100,)\n",
      "train_df: (70, 6), test_df:(30, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=100, n_features=5, n_redundant=0, n_informative=2, n_clusters_per_class=1, n_classes=3\n",
    ")\n",
    "print(f\"X: {X.shape}, y:{y.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "train_df = pd.concat([y_train, X_train], axis=1)\n",
    "train_df.columns = range(train_df.shape[1])\n",
    "test_df = pd.concat([y_test, X_test], axis=1)\n",
    "test_df.columns = range(test_df.shape[1])\n",
    "\n",
    "print(f\"train_df: {train_df.shape}, test_df:{test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-342474125894/script-mode-container-xgb/train/train.csv\n",
      "s3://sagemaker-ap-southeast-1-342474125894/script-mode-container-xgb/val/test.csv\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"../test_data/train/train.csv\"\n",
    "test_filename = \"../test_data/val/test.csv\"\n",
    "train_df.to_csv(train_filename, header=True, index=False)\n",
    "test_df.to_csv(test_filename, header=True, index=False)\n",
    "\n",
    "train_uri = sagemaker_session.upload_data(train_filename, bucket, prefix + '/train')\n",
    "test_uri = sagemaker_session.upload_data(test_filename, bucket, prefix + '/val')\n",
    "print(train_uri)\n",
    "print(test_uri)\n",
    "#! rm $train_filename $test_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can execute the training job by calling the fit() method of the generic Estimator object defined in the Amazon SageMaker Python SDK (https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/estimator.py). This corresponds to calling the CreateTrainingJob() API (https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTrainingJob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-20 08:01:33 Starting - Starting the training job...\n",
      "2020-08-20 08:01:35 Starting - Launching requested ML instances......\n",
      "2020-08-20 08:02:45 Starting - Preparing the instances for training...\n",
      "2020-08-20 08:03:25 Downloading - Downloading input data\n",
      "2020-08-20 08:03:25 Training - Downloading the training image.....\u001b[34m2020-08-20 08:04:13,482 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-20 08:04:13,483 sagemaker-containers INFO     Failed to parse hyperparameter hp1 value value1 to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\n",
      "2020-08-20 08:04:29 Uploading - Uploading generated training model\n",
      "2020-08-20 08:04:29 Completed - Training job completed\n",
      "\u001b[34m2020-08-20 08:04:19,714 sagemaker-containers INFO     Failed to parse hyperparameter hp1 value value1 to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-08-20 08:04:19,716 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-20 08:04:19,727 sagemaker-containers INFO     Failed to parse hyperparameter hp1 value value1 to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-08-20 08:04:19,730 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-20 08:04:19,740 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hp1\": \"value1\",\n",
      "        \"hp3\": 0.001,\n",
      "        \"hp2\": 300\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"script-mode-container-xgb-2020-08-20-08-01-39-396\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"script-mode-container-xgb-2020-08-20-08-01-39-396\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--hp1\",\"value1\",\"--hp2\",\"300\",\"--hp3\",\"0.001\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HP1=value1\u001b[0m\n",
      "\u001b[34mSM_HP_HP3=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_HP2=300\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 train.py --hp1 value1 --hp2 300 --hp3 0.001\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNamespace(epochs=50, hp1='value1', hp2=300, hp3=0.001, model_dir='/opt/ml/model', train='/opt/ml/input/data/train', validation='/opt/ml/input/data/validation')\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in train channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/train/train.csv\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in validation channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/validation/test.csv\u001b[0m\n",
      "\u001b[34mX_train: (70, 5), y_train:(70,)\u001b[0m\n",
      "\u001b[34mX_test: (30, 5), y_test:(30,)\u001b[0m\n",
      "\u001b[34mXGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=None,\n",
      "       importance_type='gain', interaction_constraints=None,\n",
      "       learning_rate=0.0001, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=5, missing=None, monotone_constraints=None,\n",
      "       n_estimators=50, n_jobs=3, nthread=None, num_parallel_tree=None,\n",
      "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=None, subsample=1, tree_method=None,\n",
      "       validate_parameters=None, verbosity=1)\u001b[0m\n",
      "\u001b[34m[0]#011validation_0-mlogloss:1.09854#011validation_1-mlogloss:1.09855\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation_1-mlogloss hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[1]#011validation_0-mlogloss:1.09846#011validation_1-mlogloss:1.09848\u001b[0m\n",
      "\u001b[34m[2]#011validation_0-mlogloss:1.09839#011validation_1-mlogloss:1.09842\u001b[0m\n",
      "\u001b[34m[3]#011validation_0-mlogloss:1.09831#011validation_1-mlogloss:1.09835\u001b[0m\n",
      "\u001b[34m[4]#011validation_0-mlogloss:1.09824#011validation_1-mlogloss:1.09829\u001b[0m\n",
      "\u001b[34m[5]#011validation_0-mlogloss:1.09816#011validation_1-mlogloss:1.09823\u001b[0m\n",
      "\u001b[34m[6]#011validation_0-mlogloss:1.09809#011validation_1-mlogloss:1.09816\u001b[0m\n",
      "\u001b[34m[7]#011validation_0-mlogloss:1.09801#011validation_1-mlogloss:1.09810\u001b[0m\n",
      "\u001b[34m[8]#011validation_0-mlogloss:1.09794#011validation_1-mlogloss:1.09803\u001b[0m\n",
      "\u001b[34m[9]#011validation_0-mlogloss:1.09786#011validation_1-mlogloss:1.09797\u001b[0m\n",
      "\u001b[34m[10]#011validation_0-mlogloss:1.09779#011validation_1-mlogloss:1.09790\u001b[0m\n",
      "\u001b[34m[11]#011validation_0-mlogloss:1.09771#011validation_1-mlogloss:1.09784\u001b[0m\n",
      "\u001b[34m[12]#011validation_0-mlogloss:1.09764#011validation_1-mlogloss:1.09777\u001b[0m\n",
      "\u001b[34m[13]#011validation_0-mlogloss:1.09756#011validation_1-mlogloss:1.09771\u001b[0m\n",
      "\u001b[34m[14]#011validation_0-mlogloss:1.09749#011validation_1-mlogloss:1.09765\u001b[0m\n",
      "\u001b[34m[15]#011validation_0-mlogloss:1.09741#011validation_1-mlogloss:1.09758\u001b[0m\n",
      "\u001b[34m[16]#011validation_0-mlogloss:1.09734#011validation_1-mlogloss:1.09752\u001b[0m\n",
      "\u001b[34m[17]#011validation_0-mlogloss:1.09726#011validation_1-mlogloss:1.09745\u001b[0m\n",
      "\u001b[34m[18]#011validation_0-mlogloss:1.09719#011validation_1-mlogloss:1.09739\u001b[0m\n",
      "\u001b[34m[19]#011validation_0-mlogloss:1.09712#011validation_1-mlogloss:1.09732\u001b[0m\n",
      "\u001b[34m[20]#011validation_0-mlogloss:1.09704#011validation_1-mlogloss:1.09726\u001b[0m\n",
      "\u001b[34m[21]#011validation_0-mlogloss:1.09697#011validation_1-mlogloss:1.09719\u001b[0m\n",
      "\u001b[34m[22]#011validation_0-mlogloss:1.09689#011validation_1-mlogloss:1.09713\u001b[0m\n",
      "\u001b[34m[23]#011validation_0-mlogloss:1.09682#011validation_1-mlogloss:1.09707\u001b[0m\n",
      "\u001b[34m[24]#011validation_0-mlogloss:1.09674#011validation_1-mlogloss:1.09700\u001b[0m\n",
      "\u001b[34m[25]#011validation_0-mlogloss:1.09667#011validation_1-mlogloss:1.09694\u001b[0m\n",
      "\u001b[34m[26]#011validation_0-mlogloss:1.09659#011validation_1-mlogloss:1.09687\u001b[0m\n",
      "\u001b[34m[27]#011validation_0-mlogloss:1.09652#011validation_1-mlogloss:1.09681\u001b[0m\n",
      "\u001b[34m[28]#011validation_0-mlogloss:1.09644#011validation_1-mlogloss:1.09675\u001b[0m\n",
      "\u001b[34m[29]#011validation_0-mlogloss:1.09637#011validation_1-mlogloss:1.09668\u001b[0m\n",
      "\u001b[34m[30]#011validation_0-mlogloss:1.09629#011validation_1-mlogloss:1.09662\u001b[0m\n",
      "\u001b[34m[31]#011validation_0-mlogloss:1.09622#011validation_1-mlogloss:1.09655\u001b[0m\n",
      "\u001b[34m[32]#011validation_0-mlogloss:1.09614#011validation_1-mlogloss:1.09649\u001b[0m\n",
      "\u001b[34m[33]#011validation_0-mlogloss:1.09607#011validation_1-mlogloss:1.09642\u001b[0m\n",
      "\u001b[34m[34]#011validation_0-mlogloss:1.09600#011validation_1-mlogloss:1.09636\u001b[0m\n",
      "\u001b[34m[35]#011validation_0-mlogloss:1.09592#011validation_1-mlogloss:1.09630\u001b[0m\n",
      "\u001b[34m[36]#011validation_0-mlogloss:1.09585#011validation_1-mlogloss:1.09623\u001b[0m\n",
      "\u001b[34m[37]#011validation_0-mlogloss:1.09577#011validation_1-mlogloss:1.09617\u001b[0m\n",
      "\u001b[34m[38]#011validation_0-mlogloss:1.09570#011validation_1-mlogloss:1.09610\u001b[0m\n",
      "\u001b[34m[39]#011validation_0-mlogloss:1.09562#011validation_1-mlogloss:1.09604\u001b[0m\n",
      "\u001b[34m[40]#011validation_0-mlogloss:1.09555#011validation_1-mlogloss:1.09598\u001b[0m\n",
      "\u001b[34m[41]#011validation_0-mlogloss:1.09547#011validation_1-mlogloss:1.09591\u001b[0m\n",
      "\u001b[34m[42]#011validation_0-mlogloss:1.09540#011validation_1-mlogloss:1.09585\u001b[0m\n",
      "\u001b[34m[43]#011validation_0-mlogloss:1.09533#011validation_1-mlogloss:1.09578\u001b[0m\n",
      "\u001b[34m[44]#011validation_0-mlogloss:1.09525#011validation_1-mlogloss:1.09572\u001b[0m\n",
      "\u001b[34m[45]#011validation_0-mlogloss:1.09518#011validation_1-mlogloss:1.09566\u001b[0m\n",
      "\u001b[34m[46]#011validation_0-mlogloss:1.09510#011validation_1-mlogloss:1.09559\u001b[0m\n",
      "\u001b[34m[47]#011validation_0-mlogloss:1.09503#011validation_1-mlogloss:1.09553\u001b[0m\n",
      "\u001b[34m[48]#011validation_0-mlogloss:1.09495#011validation_1-mlogloss:1.09546\u001b[0m\n",
      "\u001b[34m[49]#011validation_0-mlogloss:1.09488#011validation_1-mlogloss:1.09540\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        11\n",
      "           1       0.64      0.88      0.74         8\n",
      "           2       1.00      0.45      0.62        11\n",
      "\n",
      "   micro avg       0.77      0.77      0.77        30\n",
      "   macro avg       0.81      0.78      0.75        30\u001b[0m\n",
      "\u001b[34mweighted avg       0.82      0.77      0.75        30\n",
      "\u001b[0m\n",
      "\u001b[34m[[11  0  0]\n",
      " [ 1  7  0]\n",
      " [ 2  4  5]]\u001b[0m\n",
      "\u001b[34m0.8244588744588744\u001b[0m\n",
      "\u001b[34msave booster\u001b[0m\n",
      "\u001b[34m2020-08-20 08:04:20,916 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 70\n",
      "Billable seconds: 70\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "\n",
    "# Must align with training script argparser\n",
    "hyperparameters = {\n",
    "    \"hp1\": \"value1\",\n",
    "    \"hp2\": 300,\n",
    "    \"hp3\": 0.001}\n",
    "\n",
    "# Custom container can support metric definition\n",
    "est = sagemaker.estimator.Estimator(container_image_uri,\n",
    "                                    role,\n",
    "                                    instance_count=1, \n",
    "                                    #instance_type='local', # we use local mode\n",
    "                                    instance_type='ml.m5.xlarge',\n",
    "                                    base_job_name=prefix,\n",
    "                                    hyperparameters=hyperparameters)\n",
    "\n",
    "train_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "est.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "# Must align with training script argparser\n",
    "hyperparameters = {\n",
    "    \"hp1\": \"value1\",\n",
    "    \"hp2\": 300,\n",
    "    \"hp3\": 0.001}\n",
    "\n",
    "xgb_estimator = sagemaker.estimator.Estimator(container_image_uri,\n",
    "                                    role,\n",
    "                                    instance_count=1, \n",
    "                                    #instance_type='local', # we use local mode\n",
    "                                    instance_type='ml.m5.xlarge',\n",
    "                                    base_job_name=prefix, # Set based job name to easily identify job under HPO\n",
    "                                    hyperparameters=hyperparameters)\n",
    "\n",
    "# Must align with training script argparser\n",
    "hyperparameter_ranges = {'epochs': IntegerParameter(10, 20),\n",
    "                         #'lr': ContinuousParameter(0.001, 0.01),\n",
    "                        }\n",
    "\n",
    "# Must exist in one of the metric definition\n",
    "objective_metric_name = 'validation-mlogloss'\n",
    "\n",
    "metric_definitions = [{'Name': 'train-mlogloss',\n",
    "                       'Regex': 'validation_0-mlogloss:([0-9\\\\.]+)'},\n",
    "                     {'Name': 'validation-mlogloss',\n",
    "                       'Regex': 'validation_1-mlogloss:([0-9\\\\.]+)'}]\n",
    "\n",
    "task_tags = [{'Key':'ML Task', 'Value':'XGBoost'}]\n",
    "tuner = HyperparameterTuner(xgb_estimator,\n",
    "                            objective_metric_name=objective_metric_name,\n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            tags=task_tags,\n",
    "                            objective_type='Maximize',\n",
    "                            max_jobs=2,\n",
    "                            max_parallel_jobs=2)\n",
    "\n",
    "train_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "tuner.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve metrics for best tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>validation-mlogloss</td>\n",
       "      <td>1.09765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp          metric_name    value\n",
       "0        0.0  validation-mlogloss  1.09765"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "\n",
    "metric_name = 'validation-mlogloss'\n",
    "job_name = tuner.best_training_job()\n",
    "metrics_dataframe = TrainingJobAnalytics(training_job_name=job_name, metric_names=[metric_name]).dataframe()\n",
    "metrics_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>check model artifact</h3>\n",
    "    \n",
    "make sure it is Booster type,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-342474125894/script-mode-containe-200820-1621-002-fa80cf0e/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "artifact_path = est.latest_training_job.describe()['ModelArtifacts']['S3ModelArtifacts']\n",
    "#artifact_path = \"s3://sagemaker-ap-southeast-1-342474125894/script-mode-containe-200820-1621-002-fa80cf0e/output/model.tar.gz\"\n",
    "print(artifact_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-southeast-1-342474125894/script-mode-containe-200820-1621-002-fa80cf0e/output/model.tar.gz to ./model.tar.gz\n",
      "x model.pth\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp $artifact_path .\n",
    "! tar -xvf model.tar.gz\n",
    "! rm model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x128235ac0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('model.pth', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Method 2: Train with Prebuilt container </h1>\n",
    "\n",
    "Prebuilt container has both sagemaker-container/sagemaker-inference install in a single image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-20 07:45:31 Starting - Starting the training job...\n",
      "2020-08-20 07:45:33 Starting - Launching requested ML instances......\n",
      "2020-08-20 07:46:40 Starting - Preparing the instances for training......\n",
      "2020-08-20 07:48:02 Downloading - Downloading input data\n",
      "2020-08-20 07:48:02 Training - Downloading the training image...\n",
      "2020-08-20 07:48:30 Uploading - Uploading generated training model\n",
      "2020-08-20 07:48:30 Completed - Training job completed\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Invoking user training script.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating setup.cfg\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\n",
      "  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=9278 sha256=cbb965065f10544ae9d37dca66968b13c0dc1847ae5ed3cd197bcc16cf1391c8\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-v9vjqy19/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hp1\": \"value1\",\n",
      "        \"hp3\": 0.001,\n",
      "        \"hp2\": 300\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-xgboost-2020-08-20-07-45-37-434\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-1-342474125894/sagemaker-xgboost-2020-08-20-07-45-37-434/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-southeast-1-342474125894/sagemaker-xgboost-2020-08-20-07-45-37-434/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2020-08-20-07-45-37-434\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-1-342474125894/sagemaker-xgboost-2020-08-20-07-45-37-434/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--hp1\",\"value1\",\"--hp2\",\"300\",\"--hp3\",\"0.001\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HP1=value1\u001b[0m\n",
      "\u001b[34mSM_HP_HP3=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_HP2=300\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python3.6/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python36.zip:/miniconda3/lib/python3.6:/miniconda3/lib/python3.6/lib-dynload:/miniconda3/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m train --hp1 value1 --hp2 300 --hp3 0.001\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNamespace(epochs=50, hp1='value1', hp2=300, hp3=0.001, model_dir='/opt/ml/model', train='/opt/ml/input/data/train', validation='/opt/ml/input/data/validation')\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in train channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/train/train.csv\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in validation channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/validation/test.csv\u001b[0m\n",
      "\u001b[34mX_train: (70, 5), y_train:(70,)\u001b[0m\n",
      "\u001b[34mX_test: (30, 5), y_test:(30,)\u001b[0m\n",
      "\u001b[34mXGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.0001, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=50, n_jobs=3, nthread=None, num_parallel_tree=None,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method=None, validate_parameters=False, verbosity=1)\u001b[0m\n",
      "\u001b[34m[0]#011validation_0-mlogloss:1.09853#011validation_1-mlogloss:1.09853\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation_1-mlogloss hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[1]#011validation_0-mlogloss:1.09845#011validation_1-mlogloss:1.09845\u001b[0m\n",
      "\u001b[34m[2]#011validation_0-mlogloss:1.09838#011validation_1-mlogloss:1.09837\u001b[0m\n",
      "\u001b[34m[3]#011validation_0-mlogloss:1.09830#011validation_1-mlogloss:1.09829\u001b[0m\n",
      "\u001b[34m[4]#011validation_0-mlogloss:1.09822#011validation_1-mlogloss:1.09821\u001b[0m\n",
      "\u001b[34m[5]#011validation_0-mlogloss:1.09814#011validation_1-mlogloss:1.09812\u001b[0m\n",
      "\u001b[34m[6]#011validation_0-mlogloss:1.09806#011validation_1-mlogloss:1.09804\u001b[0m\n",
      "\u001b[34m[7]#011validation_0-mlogloss:1.09798#011validation_1-mlogloss:1.09796\u001b[0m\n",
      "\u001b[34m[8]#011validation_0-mlogloss:1.09790#011validation_1-mlogloss:1.09788\u001b[0m\n",
      "\u001b[34m[9]#011validation_0-mlogloss:1.09782#011validation_1-mlogloss:1.09780\u001b[0m\n",
      "\u001b[34m[10]#011validation_0-mlogloss:1.09774#011validation_1-mlogloss:1.09772\u001b[0m\n",
      "\u001b[34m[11]#011validation_0-mlogloss:1.09767#011validation_1-mlogloss:1.09763\u001b[0m\n",
      "\u001b[34m[12]#011validation_0-mlogloss:1.09759#011validation_1-mlogloss:1.09755\u001b[0m\n",
      "\u001b[34m[13]#011validation_0-mlogloss:1.09751#011validation_1-mlogloss:1.09747\u001b[0m\n",
      "\u001b[34m[14]#011validation_0-mlogloss:1.09743#011validation_1-mlogloss:1.09739\u001b[0m\n",
      "\u001b[34m[15]#011validation_0-mlogloss:1.09735#011validation_1-mlogloss:1.09731\u001b[0m\n",
      "\u001b[34m[16]#011validation_0-mlogloss:1.09727#011validation_1-mlogloss:1.09723\u001b[0m\n",
      "\u001b[34m[17]#011validation_0-mlogloss:1.09719#011validation_1-mlogloss:1.09715\u001b[0m\n",
      "\u001b[34m[18]#011validation_0-mlogloss:1.09712#011validation_1-mlogloss:1.09707\u001b[0m\n",
      "\u001b[34m[19]#011validation_0-mlogloss:1.09704#011validation_1-mlogloss:1.09698\u001b[0m\n",
      "\u001b[34m[20]#011validation_0-mlogloss:1.09696#011validation_1-mlogloss:1.09690\u001b[0m\n",
      "\u001b[34m[21]#011validation_0-mlogloss:1.09688#011validation_1-mlogloss:1.09682\u001b[0m\n",
      "\u001b[34m[22]#011validation_0-mlogloss:1.09680#011validation_1-mlogloss:1.09674\u001b[0m\n",
      "\u001b[34m[23]#011validation_0-mlogloss:1.09672#011validation_1-mlogloss:1.09666\u001b[0m\n",
      "\u001b[34m[24]#011validation_0-mlogloss:1.09664#011validation_1-mlogloss:1.09658\u001b[0m\n",
      "\u001b[34m[25]#011validation_0-mlogloss:1.09657#011validation_1-mlogloss:1.09650\u001b[0m\n",
      "\u001b[34m[26]#011validation_0-mlogloss:1.09649#011validation_1-mlogloss:1.09641\u001b[0m\n",
      "\u001b[34m[27]#011validation_0-mlogloss:1.09641#011validation_1-mlogloss:1.09633\u001b[0m\n",
      "\u001b[34m[28]#011validation_0-mlogloss:1.09633#011validation_1-mlogloss:1.09625\u001b[0m\n",
      "\u001b[34m[29]#011validation_0-mlogloss:1.09625#011validation_1-mlogloss:1.09617\u001b[0m\n",
      "\u001b[34m[30]#011validation_0-mlogloss:1.09617#011validation_1-mlogloss:1.09609\u001b[0m\n",
      "\u001b[34m[31]#011validation_0-mlogloss:1.09609#011validation_1-mlogloss:1.09601\u001b[0m\n",
      "\u001b[34m[32]#011validation_0-mlogloss:1.09601#011validation_1-mlogloss:1.09593\u001b[0m\n",
      "\u001b[34m[33]#011validation_0-mlogloss:1.09594#011validation_1-mlogloss:1.09585\u001b[0m\n",
      "\u001b[34m[34]#011validation_0-mlogloss:1.09586#011validation_1-mlogloss:1.09577\u001b[0m\n",
      "\u001b[34m[35]#011validation_0-mlogloss:1.09578#011validation_1-mlogloss:1.09569\u001b[0m\n",
      "\u001b[34m[36]#011validation_0-mlogloss:1.09570#011validation_1-mlogloss:1.09560\u001b[0m\n",
      "\u001b[34m[37]#011validation_0-mlogloss:1.09562#011validation_1-mlogloss:1.09552\u001b[0m\n",
      "\u001b[34m[38]#011validation_0-mlogloss:1.09554#011validation_1-mlogloss:1.09544\u001b[0m\n",
      "\u001b[34m[39]#011validation_0-mlogloss:1.09547#011validation_1-mlogloss:1.09536\u001b[0m\n",
      "\u001b[34m[40]#011validation_0-mlogloss:1.09539#011validation_1-mlogloss:1.09528\u001b[0m\n",
      "\u001b[34m[41]#011validation_0-mlogloss:1.09531#011validation_1-mlogloss:1.09520\u001b[0m\n",
      "\u001b[34m[42]#011validation_0-mlogloss:1.09523#011validation_1-mlogloss:1.09512\u001b[0m\n",
      "\u001b[34m[43]#011validation_0-mlogloss:1.09515#011validation_1-mlogloss:1.09504\u001b[0m\n",
      "\u001b[34m[44]#011validation_0-mlogloss:1.09507#011validation_1-mlogloss:1.09495\u001b[0m\n",
      "\u001b[34m[45]#011validation_0-mlogloss:1.09499#011validation_1-mlogloss:1.09487\u001b[0m\n",
      "\u001b[34m[46]#011validation_0-mlogloss:1.09492#011validation_1-mlogloss:1.09479\u001b[0m\n",
      "\u001b[34m[47]#011validation_0-mlogloss:1.09484#011validation_1-mlogloss:1.09471\u001b[0m\n",
      "\u001b[34m[48]#011validation_0-mlogloss:1.09476#011validation_1-mlogloss:1.09463\u001b[0m\n",
      "\u001b[34m[49]#011validation_0-mlogloss:1.09468#011validation_1-mlogloss:1.09455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.86      1.00      0.92         6\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.95      0.97      0.96        30\u001b[0m\n",
      "\u001b[34mweighted avg       0.97      0.97      0.97        30\n",
      "\u001b[0m\n",
      "\u001b[34m[[11  1  0]\n",
      " [ 0  6  0]\n",
      " [ 0  0 12]]\u001b[0m\n",
      "\u001b[34m0.9714285714285714\u001b[0m\n",
      "\u001b[34msave booster\u001b[0m\n",
      "Training seconds: 35\n",
      "Billable seconds: 35\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "# log group prefix /aws/sagemaker/TrainingJobs\n",
    "\n",
    "hyperparameters = {\n",
    "    \"hp1\": \"value1\",\n",
    "    \"hp2\": 300,\n",
    "    \"hp3\": 0.001}\n",
    "\n",
    "metric_definitions=[\n",
    "   {'Name': 'custom_train:loss', 'Regex': 'validation_0-mlogloss:=(.*?) '},\n",
    "   {'Name': 'custom_validation:loss', 'Regex': 'validation_1-mlogloss=(.*?) '}\n",
    "]\n",
    "    \n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"../docker/code\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    #instance_type=\"local\",\n",
    "    framework_version=\"1.0-1\",\n",
    "    #metric_definitions=metric_definitions # built in algo does not support metric definition\n",
    ")\n",
    "\n",
    "train_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "xgb_estimator.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy from estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "serializer = CSVSerializer()\n",
    "serializer.CONTENT_TYPE = \"text/csv\"\n",
    "\n",
    "predictor = xgb_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.medium\",\n",
    "    serializer=serializer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"file.csv\") as f:\n",
    "    payload = f.read()\n",
    "\n",
    "predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Get Predictor </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0.335604', '0.32953852', '0.3348575'],\n",
       " ['0.3353785', '0.329989', '0.3346325']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.xgboost.model import XGBoostPredictor\n",
    "import numpy as np\n",
    "\n",
    "endpoint_name = \"sagemaker-xgboost-2020-08-11-06-52-30-545\"\n",
    "payload = \"1,2,3,4,5\\n2,3,4,5,6\"\n",
    "\n",
    "xgb_predictor = XGBoostPredictor(endpoint_name)\n",
    "\n",
    "xgb_predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Low level API - inference </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3306555449962616, 0.33722642064094543, 0.33211803436279297]]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "runtime_client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "\n",
    "payload = \"1,2,3,4,5\"\n",
    "endpoint_name = 'sagemaker-xgboost-2020-08-11-06-52-30-545'\n",
    "\n",
    "response = runtime_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType='text/csv',\n",
    "                                   Body=payload)\n",
    "\n",
    "result = response['Body'].read().decode('ascii')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (virtualenv_p38smv2)",
   "language": "python",
   "name": "virtualenv_p38smv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
