{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Method 1: Train with custom XGB Container </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to build and use a custom Docker container for training with Amazon SageMaker that leverages on the <strong>Script Mode</strong> execution that is implemented by the sagemaker-containers library. Reference documentation is available at https://github.com/aws/sagemaker-containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining some variables like the current execution role, the ECR repository that we are going to use for pushing the custom Docker container and a default Amazon S3 bucket to be used by Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342474125894\n",
      "ap-southeast-1\n",
      "arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\n",
      "sagemaker-ap-southeast-1-342474125894\n",
      "sagemaker-training-containers/script-mode-container-xgb\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "ecr_namespace = 'sagemaker-training-containers/'\n",
    "prefix = 'script-mode-container-xgb'\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = \"arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\"\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)\n",
    "print(ecr_repository_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Build and push the container</h3>\n",
    "We are now ready to build this container and push it to Amazon ECR. This task is executed using a shell script stored in the ../script/ folder. Let's take a look at this script and then execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  13.31kB\n",
      "Step 1/16 : FROM ubuntu:16.04\n",
      " ---> 13c9f1285025\n",
      "Step 2/16 : LABEL maintainer=\"Giuseppe A. Porcelli\"\n",
      " ---> Using cache\n",
      " ---> 6bbf3d07c68d\n",
      "Step 3/16 : ARG PYTHON=python3\n",
      " ---> Using cache\n",
      " ---> 8e254b9ef0a0\n",
      "Step 4/16 : ARG PYTHON_PIP=python3-pip\n",
      " ---> Using cache\n",
      " ---> 84c928b11bb3\n",
      "Step 5/16 : ARG PIP=pip3\n",
      " ---> Using cache\n",
      " ---> 65e780b1f9d7\n",
      "Step 6/16 : ARG PYTHON_VERSION=3.6.6\n",
      " ---> Using cache\n",
      " ---> 03bab72f170e\n",
      "Step 7/16 : RUN apt-get update && apt-get install -y --no-install-recommends software-properties-common &&     add-apt-repository ppa:deadsnakes/ppa -y &&     apt-get update && apt-get install -y --no-install-recommends     build-essential     ca-certificates     curl     wget     git     libopencv-dev     openssh-client     openssh-server     vim     zlib1g-dev &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> e29c159657d9\n",
      "Step 8/16 : RUN wget https://www.python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tgz &&     tar -xvf Python-$PYTHON_VERSION.tgz && cd Python-$PYTHON_VERSION &&     ./configure && make && make install &&     apt-get update && apt-get install -y --no-install-recommends libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev &&     make && make install && rm -rf ../Python-$PYTHON_VERSION* &&     ln -s /usr/local/bin/pip3 /usr/bin/pip\n",
      " ---> Using cache\n",
      " ---> 5f344151a182\n",
      "Step 9/16 : RUN ${PIP} --no-cache-dir install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> eda3fb14df62\n",
      "Step 10/16 : RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
      " ---> Using cache\n",
      " ---> 36e695fcdc04\n",
      "Step 11/16 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 47c0eeca0f80\n",
      "Step 12/16 : RUN ${PIP} install --no-cache --upgrade     numpy==1.14.5     pandas==0.24.1     scikit-learn==0.20.3     requests==2.21.0     scipy==1.2.1     xgboost==1.1.1\n",
      " ---> Using cache\n",
      " ---> 8005d64e71ff\n",
      "Step 13/16 : ENV PYTHONDONTWRITEBYTECODE=1     PYTHONUNBUFFERED=1     LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\"     PYTHONIOENCODING=UTF-8     LANG=C.UTF-8     LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> d49a18978498\n",
      "Step 14/16 : RUN ${PIP} install --no-cache --upgrade     sagemaker-containers\n",
      " ---> Using cache\n",
      " ---> 1d33f1130683\n",
      "Step 15/16 : COPY code/* /opt/ml/code/\n",
      " ---> eaadfe4d9813\n",
      "Step 16/16 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in 599db12a4f49\n",
      "Removing intermediate container 599db12a4f49\n",
      " ---> f826e3443b64\n",
      "Successfully built f826e3443b64\n",
      "Successfully tagged sagemaker-training-containers/script-mode-container-xgb:latest\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "Login Succeeded\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryUri\": \"342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/script-mode-container-xgb\", \n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            }, \n",
      "            \"registryId\": \"342474125894\", \n",
      "            \"imageTagMutability\": \"MUTABLE\", \n",
      "            \"repositoryArn\": \"arn:aws:ecr:ap-southeast-1:342474125894:repository/sagemaker-training-containers/script-mode-container-xgb\", \n",
      "            \"repositoryName\": \"sagemaker-training-containers/script-mode-container-xgb\", \n",
      "            \"createdAt\": 1597065421.0\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "The push refers to repository [342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/script-mode-container-xgb]\n",
      "\n",
      "\u001b[1B3b5ead59: Preparing \n",
      "\u001b[1B707974b2: Preparing \n",
      "\u001b[1B2b5574ba: Preparing \n",
      "\u001b[1Bfc276494: Preparing \n",
      "\u001b[1Bb7f4d226: Preparing \n",
      "\u001b[1B136c651b: Preparing \n",
      "\u001b[1Bb57b75a1: Preparing \n",
      "\u001b[1Bf22d44f3: Preparing \n",
      "\u001b[1B6f329a25: Preparing \n",
      "\u001b[1B7de5faec: Preparing \n",
      "\u001b[11Bb5ead59: Pushed lready exists 6kB0A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[11A\u001b[2Klatest: digest: sha256:9b2830f9238b2b32ed5cfd1174713578e15773dcf98941dec48da5c915096350 size: 2626\n"
     ]
    }
   ],
   "source": [
    "! ../scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training with Amazon SageMaker</h3>\n",
    "\n",
    "Once we have correctly pushed our container to Amazon ECR, we are ready to start training with Amazon SageMaker, which requires the ECR path to the Docker container used for training as parameter for starting a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/script-mode-container-xgb:latest\n"
     ]
    }
   ],
   "source": [
    "container_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, ecr_repository_name)\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can realize that the training code has been implemented as a standard Python script, that will be invoked by the sagemaker-containers library passing hyperparameters as arguments. This way of invoking training script is indeed called <strong>Script Mode</strong> for Amazon SageMaker containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare Data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we upload some dummy data to Amazon S3, in order to define our S3-based training channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (100, 5), y:(100,)\n",
      "train_df: (70, 6), test_df:(30, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=100, n_features=5, n_redundant=0, n_informative=2, n_clusters_per_class=1, n_classes=3\n",
    ")\n",
    "print(f\"X: {X.shape}, y:{y.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "train_df = pd.concat([y_train, X_train], axis=1)\n",
    "train_df.columns = range(train_df.shape[1])\n",
    "test_df = pd.concat([y_test, X_test], axis=1)\n",
    "test_df.columns = range(test_df.shape[1])\n",
    "\n",
    "print(f\"train_df: {train_df.shape}, test_df:{test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-342474125894/script-mode-container-xgb/train/train.csv\n",
      "s3://sagemaker-ap-southeast-1-342474125894/script-mode-container-xgb/val/test.csv\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"../test_data/train/train.csv\"\n",
    "test_filename = \"../test_data/val/test.csv\"\n",
    "train_df.to_csv(train_filename, header=True, index=False)\n",
    "test_df.to_csv(test_filename, header=True, index=False)\n",
    "\n",
    "train_uri = sagemaker_session.upload_data(train_filename, bucket, prefix + '/train')\n",
    "test_uri = sagemaker_session.upload_data(test_filename, bucket, prefix + '/val')\n",
    "print(train_uri)\n",
    "print(test_uri)\n",
    "#! rm $train_filename $test_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can execute the training job by calling the fit() method of the generic Estimator object defined in the Amazon SageMaker Python SDK (https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/estimator.py). This corresponds to calling the CreateTrainingJob() API (https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTrainingJob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-11 06:33:49 Starting - Starting the training job...\n",
      "2020-08-11 06:33:52 Starting - Launching requested ML instances......\n",
      "2020-08-11 06:35:01 Starting - Preparing the instances for training...\n",
      "2020-08-11 06:35:42 Downloading - Downloading input data\n",
      "2020-08-11 06:35:42 Training - Downloading the training image.....\u001b[34m2020-08-11 06:36:29,233 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-11 06:36:29,234 sagemaker-containers INFO     Failed to parse hyperparameter hp1 value value1 to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-08-11 06:36:29,252 sagemaker-containers INFO     Failed to parse hyperparameter hp1 value value1 to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-08-11 06:36:29,255 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-11 06:36:29,266 sagemaker-containers INFO     Failed to parse hyperparameter hp1 value value1 to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-08-11 06:36:29,268 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-11 06:36:29,281 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hp1\": \"value1\",\n",
      "        \"hp3\": 0.001,\n",
      "        \"hp2\": 300\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"script-mode-container-xgb-2020-08-11-06-33-54-847\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"script-mode-container-xgb-2020-08-11-06-33-54-847\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--hp1\",\"value1\",\"--hp2\",\"300\",\"--hp3\",\"0.001\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HP1=value1\u001b[0m\n",
      "\u001b[34mSM_HP_HP3=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_HP2=300\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 train.py --hp1 value1 --hp2 300 --hp3 0.001\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNamespace(hp1='value1', hp2=300, hp3=0.001, model_dir='/opt/ml/model', train='/opt/ml/input/data/train', validation='/opt/ml/input/data/validation')\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in train channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/train/train.csv\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in validation channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/validation/test.csv\u001b[0m\n",
      "\u001b[34mX_train: (70, 5), y_train:(70,)\u001b[0m\n",
      "\u001b[34mX_test: (30, 5), y_test:(30,)\u001b[0m\n",
      "\u001b[34mXGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=None,\n",
      "       importance_type='gain', interaction_constraints=None,\n",
      "       learning_rate=0.0001, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=5, missing=None, monotone_constraints=None,\n",
      "       n_estimators=100, n_jobs=3, nthread=None, num_parallel_tree=None,\n",
      "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=None, subsample=1, tree_method=None,\n",
      "       validate_parameters=None, verbosity=1)\u001b[0m\n",
      "\u001b[34m[0]#011validation_0-mlogloss:1.09853#011validation_1-mlogloss:1.09853\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation_1-mlogloss hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[1]#011validation_0-mlogloss:1.09845#011validation_1-mlogloss:1.09845\u001b[0m\n",
      "\u001b[34m[2]#011validation_0-mlogloss:1.09838#011validation_1-mlogloss:1.09837\u001b[0m\n",
      "\u001b[34m[3]#011validation_0-mlogloss:1.09830#011validation_1-mlogloss:1.09829\u001b[0m\n",
      "\u001b[34m[4]#011validation_0-mlogloss:1.09822#011validation_1-mlogloss:1.09821\u001b[0m\n",
      "\u001b[34m[5]#011validation_0-mlogloss:1.09814#011validation_1-mlogloss:1.09812\u001b[0m\n",
      "\u001b[34m[6]#011validation_0-mlogloss:1.09806#011validation_1-mlogloss:1.09804\u001b[0m\n",
      "\u001b[34m[7]#011validation_0-mlogloss:1.09798#011validation_1-mlogloss:1.09796\u001b[0m\n",
      "\u001b[34m[8]#011validation_0-mlogloss:1.09790#011validation_1-mlogloss:1.09788\u001b[0m\n",
      "\u001b[34m[9]#011validation_0-mlogloss:1.09782#011validation_1-mlogloss:1.09780\u001b[0m\n",
      "\u001b[34m[10]#011validation_0-mlogloss:1.09774#011validation_1-mlogloss:1.09772\u001b[0m\n",
      "\u001b[34m[11]#011validation_0-mlogloss:1.09767#011validation_1-mlogloss:1.09763\u001b[0m\n",
      "\u001b[34m[12]#011validation_0-mlogloss:1.09759#011validation_1-mlogloss:1.09755\u001b[0m\n",
      "\u001b[34m[13]#011validation_0-mlogloss:1.09751#011validation_1-mlogloss:1.09747\u001b[0m\n",
      "\u001b[34m[14]#011validation_0-mlogloss:1.09743#011validation_1-mlogloss:1.09739\u001b[0m\n",
      "\u001b[34m[15]#011validation_0-mlogloss:1.09735#011validation_1-mlogloss:1.09731\u001b[0m\n",
      "\u001b[34m[16]#011validation_0-mlogloss:1.09727#011validation_1-mlogloss:1.09723\u001b[0m\n",
      "\u001b[34m[17]#011validation_0-mlogloss:1.09719#011validation_1-mlogloss:1.09715\u001b[0m\n",
      "\u001b[34m[18]#011validation_0-mlogloss:1.09712#011validation_1-mlogloss:1.09707\u001b[0m\n",
      "\u001b[34m[19]#011validation_0-mlogloss:1.09704#011validation_1-mlogloss:1.09698\u001b[0m\n",
      "\u001b[34m[20]#011validation_0-mlogloss:1.09696#011validation_1-mlogloss:1.09690\u001b[0m\n",
      "\u001b[34m[21]#011validation_0-mlogloss:1.09688#011validation_1-mlogloss:1.09682\u001b[0m\n",
      "\u001b[34m[22]#011validation_0-mlogloss:1.09680#011validation_1-mlogloss:1.09674\u001b[0m\n",
      "\u001b[34m[23]#011validation_0-mlogloss:1.09672#011validation_1-mlogloss:1.09666\u001b[0m\n",
      "\u001b[34m[24]#011validation_0-mlogloss:1.09664#011validation_1-mlogloss:1.09658\u001b[0m\n",
      "\u001b[34m[25]#011validation_0-mlogloss:1.09657#011validation_1-mlogloss:1.09650\u001b[0m\n",
      "\u001b[34m[26]#011validation_0-mlogloss:1.09649#011validation_1-mlogloss:1.09641\u001b[0m\n",
      "\u001b[34m[27]#011validation_0-mlogloss:1.09641#011validation_1-mlogloss:1.09633\u001b[0m\n",
      "\u001b[34m[28]#011validation_0-mlogloss:1.09633#011validation_1-mlogloss:1.09625\u001b[0m\n",
      "\u001b[34m[29]#011validation_0-mlogloss:1.09625#011validation_1-mlogloss:1.09617\u001b[0m\n",
      "\u001b[34m[30]#011validation_0-mlogloss:1.09617#011validation_1-mlogloss:1.09609\u001b[0m\n",
      "\u001b[34m[31]#011validation_0-mlogloss:1.09609#011validation_1-mlogloss:1.09601\u001b[0m\n",
      "\u001b[34m[32]#011validation_0-mlogloss:1.09601#011validation_1-mlogloss:1.09593\u001b[0m\n",
      "\u001b[34m[33]#011validation_0-mlogloss:1.09594#011validation_1-mlogloss:1.09585\u001b[0m\n",
      "\u001b[34m[34]#011validation_0-mlogloss:1.09586#011validation_1-mlogloss:1.09577\u001b[0m\n",
      "\u001b[34m[35]#011validation_0-mlogloss:1.09578#011validation_1-mlogloss:1.09569\u001b[0m\n",
      "\u001b[34m[36]#011validation_0-mlogloss:1.09570#011validation_1-mlogloss:1.09560\u001b[0m\n",
      "\u001b[34m[37]#011validation_0-mlogloss:1.09562#011validation_1-mlogloss:1.09552\u001b[0m\n",
      "\u001b[34m[38]#011validation_0-mlogloss:1.09554#011validation_1-mlogloss:1.09544\u001b[0m\n",
      "\u001b[34m[39]#011validation_0-mlogloss:1.09547#011validation_1-mlogloss:1.09536\u001b[0m\n",
      "\u001b[34m[40]#011validation_0-mlogloss:1.09539#011validation_1-mlogloss:1.09528\u001b[0m\n",
      "\u001b[34m[41]#011validation_0-mlogloss:1.09531#011validation_1-mlogloss:1.09520\u001b[0m\n",
      "\u001b[34m[42]#011validation_0-mlogloss:1.09523#011validation_1-mlogloss:1.09512\u001b[0m\n",
      "\u001b[34m[43]#011validation_0-mlogloss:1.09515#011validation_1-mlogloss:1.09504\u001b[0m\n",
      "\u001b[34m[44]#011validation_0-mlogloss:1.09507#011validation_1-mlogloss:1.09495\u001b[0m\n",
      "\u001b[34m[45]#011validation_0-mlogloss:1.09499#011validation_1-mlogloss:1.09487\u001b[0m\n",
      "\u001b[34m[46]#011validation_0-mlogloss:1.09492#011validation_1-mlogloss:1.09479\u001b[0m\n",
      "\u001b[34m[47]#011validation_0-mlogloss:1.09484#011validation_1-mlogloss:1.09471\u001b[0m\n",
      "\u001b[34m[48]#011validation_0-mlogloss:1.09476#011validation_1-mlogloss:1.09463\u001b[0m\n",
      "\u001b[34m[49]#011validation_0-mlogloss:1.09468#011validation_1-mlogloss:1.09455\u001b[0m\n",
      "\u001b[34m[50]#011validation_0-mlogloss:1.09460#011validation_1-mlogloss:1.09447\u001b[0m\n",
      "\u001b[34m[51]#011validation_0-mlogloss:1.09452#011validation_1-mlogloss:1.09439\u001b[0m\n",
      "\u001b[34m[52]#011validation_0-mlogloss:1.09445#011validation_1-mlogloss:1.09431\u001b[0m\n",
      "\u001b[34m[53]#011validation_0-mlogloss:1.09437#011validation_1-mlogloss:1.09423\u001b[0m\n",
      "\u001b[34m[54]#011validation_0-mlogloss:1.09429#011validation_1-mlogloss:1.09414\u001b[0m\n",
      "\u001b[34m[55]#011validation_0-mlogloss:1.09421#011validation_1-mlogloss:1.09406\u001b[0m\n",
      "\u001b[34m[56]#011validation_0-mlogloss:1.09413#011validation_1-mlogloss:1.09398\u001b[0m\n",
      "\u001b[34m[57]#011validation_0-mlogloss:1.09405#011validation_1-mlogloss:1.09390\u001b[0m\n",
      "\u001b[34m[58]#011validation_0-mlogloss:1.09398#011validation_1-mlogloss:1.09382\u001b[0m\n",
      "\u001b[34m[59]#011validation_0-mlogloss:1.09390#011validation_1-mlogloss:1.09374\u001b[0m\n",
      "\u001b[34m[60]#011validation_0-mlogloss:1.09382#011validation_1-mlogloss:1.09366\u001b[0m\n",
      "\u001b[34m[61]#011validation_0-mlogloss:1.09374#011validation_1-mlogloss:1.09358\u001b[0m\n",
      "\u001b[34m[62]#011validation_0-mlogloss:1.09366#011validation_1-mlogloss:1.09350\u001b[0m\n",
      "\u001b[34m[63]#011validation_0-mlogloss:1.09359#011validation_1-mlogloss:1.09342\u001b[0m\n",
      "\u001b[34m[64]#011validation_0-mlogloss:1.09351#011validation_1-mlogloss:1.09334\u001b[0m\n",
      "\u001b[34m[65]#011validation_0-mlogloss:1.09343#011validation_1-mlogloss:1.09326\u001b[0m\n",
      "\u001b[34m[66]#011validation_0-mlogloss:1.09335#011validation_1-mlogloss:1.09318\u001b[0m\n",
      "\u001b[34m[67]#011validation_0-mlogloss:1.09327#011validation_1-mlogloss:1.09309\u001b[0m\n",
      "\u001b[34m[68]#011validation_0-mlogloss:1.09319#011validation_1-mlogloss:1.09301\u001b[0m\n",
      "\u001b[34m[69]#011validation_0-mlogloss:1.09312#011validation_1-mlogloss:1.09293\u001b[0m\n",
      "\u001b[34m[70]#011validation_0-mlogloss:1.09304#011validation_1-mlogloss:1.09285\u001b[0m\n",
      "\u001b[34m[71]#011validation_0-mlogloss:1.09296#011validation_1-mlogloss:1.09277\u001b[0m\n",
      "\u001b[34m[72]#011validation_0-mlogloss:1.09288#011validation_1-mlogloss:1.09269\u001b[0m\n",
      "\u001b[34m[73]#011validation_0-mlogloss:1.09280#011validation_1-mlogloss:1.09261\u001b[0m\n",
      "\u001b[34m[74]#011validation_0-mlogloss:1.09273#011validation_1-mlogloss:1.09253\u001b[0m\n",
      "\u001b[34m[75]#011validation_0-mlogloss:1.09265#011validation_1-mlogloss:1.09245\u001b[0m\n",
      "\u001b[34m[76]#011validation_0-mlogloss:1.09257#011validation_1-mlogloss:1.09237\u001b[0m\n",
      "\u001b[34m[77]#011validation_0-mlogloss:1.09249#011validation_1-mlogloss:1.09229\u001b[0m\n",
      "\u001b[34m[78]#011validation_0-mlogloss:1.09241#011validation_1-mlogloss:1.09221\u001b[0m\n",
      "\u001b[34m[79]#011validation_0-mlogloss:1.09234#011validation_1-mlogloss:1.09213\u001b[0m\n",
      "\u001b[34m[80]#011validation_0-mlogloss:1.09226#011validation_1-mlogloss:1.09205\u001b[0m\n",
      "\u001b[34m[81]#011validation_0-mlogloss:1.09218#011validation_1-mlogloss:1.09197\u001b[0m\n",
      "\u001b[34m[82]#011validation_0-mlogloss:1.09210#011validation_1-mlogloss:1.09188\u001b[0m\n",
      "\u001b[34m[83]#011validation_0-mlogloss:1.09202#011validation_1-mlogloss:1.09180\u001b[0m\n",
      "\u001b[34m[84]#011validation_0-mlogloss:1.09195#011validation_1-mlogloss:1.09172\u001b[0m\n",
      "\u001b[34m[85]#011validation_0-mlogloss:1.09187#011validation_1-mlogloss:1.09164\u001b[0m\n",
      "\u001b[34m[86]#011validation_0-mlogloss:1.09179#011validation_1-mlogloss:1.09156\u001b[0m\n",
      "\u001b[34m[87]#011validation_0-mlogloss:1.09171#011validation_1-mlogloss:1.09148\u001b[0m\n",
      "\u001b[34m[88]#011validation_0-mlogloss:1.09163#011validation_1-mlogloss:1.09140\u001b[0m\n",
      "\u001b[34m[89]#011validation_0-mlogloss:1.09156#011validation_1-mlogloss:1.09132\u001b[0m\n",
      "\u001b[34m[90]#011validation_0-mlogloss:1.09148#011validation_1-mlogloss:1.09124\u001b[0m\n",
      "\u001b[34m[91]#011validation_0-mlogloss:1.09140#011validation_1-mlogloss:1.09116\u001b[0m\n",
      "\u001b[34m[92]#011validation_0-mlogloss:1.09132#011validation_1-mlogloss:1.09108\u001b[0m\n",
      "\u001b[34m[93]#011validation_0-mlogloss:1.09125#011validation_1-mlogloss:1.09100\u001b[0m\n",
      "\u001b[34m[94]#011validation_0-mlogloss:1.09117#011validation_1-mlogloss:1.09092\u001b[0m\n",
      "\u001b[34m[95]#011validation_0-mlogloss:1.09109#011validation_1-mlogloss:1.09084\u001b[0m\n",
      "\u001b[34m[96]#011validation_0-mlogloss:1.09101#011validation_1-mlogloss:1.09076\u001b[0m\n",
      "\u001b[34m[97]#011validation_0-mlogloss:1.09093#011validation_1-mlogloss:1.09068\u001b[0m\n",
      "\u001b[34m[98]#011validation_0-mlogloss:1.09086#011validation_1-mlogloss:1.09060\u001b[0m\n",
      "\u001b[34m[99]#011validation_0-mlogloss:1.09078#011validation_1-mlogloss:1.09052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.86      1.00      0.92         6\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        30\n",
      "   macro avg       0.95      0.97      0.96        30\u001b[0m\n",
      "\u001b[34mweighted avg       0.97      0.97      0.97        30\n",
      "\u001b[0m\n",
      "\u001b[34m[[11  1  0]\n",
      " [ 0  6  0]\n",
      " [ 0  0 12]]\u001b[0m\n",
      "\u001b[34m0.9714285714285714\u001b[0m\n",
      "\u001b[34msave booster\u001b[0m\n",
      "\u001b[34m2020-08-11 06:36:30,527 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-08-11 06:36:40 Uploading - Uploading generated training model\n",
      "2020-08-11 06:36:40 Completed - Training job completed\n",
      "Training seconds: 64\n",
      "Billable seconds: 64\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "\n",
    "# JSON encode hyperparameters to avoid showing some info messages raised by the sagemaker-containers library.\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "# hyperparameters = json_encode_hyperparameters({\n",
    "#     \"hp1\": \"value1\",\n",
    "#     \"hp2\": 300,\n",
    "#     \"hp3\": 0.001})\n",
    "\n",
    "hyperparameters = {\n",
    "    \"hp1\": \"value1\",\n",
    "    \"hp2\": 300,\n",
    "    \"hp3\": 0.001}\n",
    "\n",
    "est = sagemaker.estimator.Estimator(container_image_uri,\n",
    "                                    role,\n",
    "                                    instance_count=1, \n",
    "                                    #instance_type='local', # we use local mode\n",
    "                                    instance_type='ml.m5.xlarge',\n",
    "                                    base_job_name=prefix,\n",
    "                                    hyperparameters=hyperparameters)\n",
    "\n",
    "train_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "est.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>check model artifact</h3>\n",
    "    \n",
    "make sure it is Booster type,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-342474125894/script-mode-container-xgb-2020-08-11-06-33-54-847/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "artifact_path = est.latest_training_job.describe()['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(artifact_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-southeast-1-342474125894/script-mode-container-xgb-2020-08-11-06-33-54-847/output/model.tar.gz to ./model.tar.gz\n",
      "x model.pth\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp $artifact_path .\n",
    "! tar -xvf model.tar.gz\n",
    "! rm model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x124ea6d60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('model.pth', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Method 2: Train with Prebuilt container </h1>\n",
    "\n",
    "Prebuilt container has both sagemaker-container/sagemaker-inference install in a single image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-11 06:48:22 Starting - Starting the training job...\n",
      "2020-08-11 06:48:24 Starting - Launching requested ML instances......\n",
      "2020-08-11 06:49:36 Starting - Preparing the instances for training......\n",
      "2020-08-11 06:50:41 Downloading - Downloading input data\n",
      "2020-08-11 06:50:41 Training - Downloading the training image...\n",
      "2020-08-11 06:51:19 Uploading - Uploading generated training model\n",
      "2020-08-11 06:51:19 Completed - Training job completed\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Invoking user training script.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating setup.cfg\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\n",
      "  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=7239 sha256=fbf492aca781ae933a2660f39f9e600f89710b9c58c33bac3481018ca61194d3\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-dsmd2oin/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hp1\": \"value1\",\n",
      "        \"hp3\": 0.001,\n",
      "        \"hp2\": 300\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-xgboost-2020-08-11-06-48-28-158\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-1-342474125894/sagemaker-xgboost-2020-08-11-06-48-28-158/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-southeast-1-342474125894/sagemaker-xgboost-2020-08-11-06-48-28-158/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2020-08-11-06-48-28-158\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-1-342474125894/sagemaker-xgboost-2020-08-11-06-48-28-158/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--hp1\",\"value1\",\"--hp2\",\"300\",\"--hp3\",\"0.001\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HP1=value1\u001b[0m\n",
      "\u001b[34mSM_HP_HP3=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_HP2=300\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python3.6/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python36.zip:/miniconda3/lib/python3.6:/miniconda3/lib/python3.6/lib-dynload:/miniconda3/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m train --hp1 value1 --hp2 300 --hp3 0.001\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNamespace(hp1='value1', hp2=300, hp3=0.001, model_dir='/opt/ml/model', train='/opt/ml/input/data/train', validation='/opt/ml/input/data/validation')\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in train channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/train/train.csv\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in validation channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/validation/test.csv\u001b[0m\n",
      "\u001b[34mX_train: (70, 5), y_train:(70,)\u001b[0m\n",
      "\u001b[34mX_test: (30, 5), y_test:(30,)\u001b[0m\n",
      "\u001b[34mXGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.0001, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=3, nthread=None, num_parallel_tree=None,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method=None, validate_parameters=False, verbosity=1)\u001b[0m\n",
      "\u001b[34m[0]#011validation_0-mlogloss:1.09853#011validation_1-mlogloss:1.09853\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation_1-mlogloss hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[1]#011validation_0-mlogloss:1.09845#011validation_1-mlogloss:1.09845\u001b[0m\n",
      "\u001b[34m[2]#011validation_0-mlogloss:1.09838#011validation_1-mlogloss:1.09837\u001b[0m\n",
      "\u001b[34m[3]#011validation_0-mlogloss:1.09830#011validation_1-mlogloss:1.09829\u001b[0m\n",
      "\u001b[34m[4]#011validation_0-mlogloss:1.09822#011validation_1-mlogloss:1.09821\u001b[0m\n",
      "\u001b[34m[5]#011validation_0-mlogloss:1.09814#011validation_1-mlogloss:1.09812\u001b[0m\n",
      "\u001b[34m[6]#011validation_0-mlogloss:1.09806#011validation_1-mlogloss:1.09804\u001b[0m\n",
      "\u001b[34m[7]#011validation_0-mlogloss:1.09798#011validation_1-mlogloss:1.09796\u001b[0m\n",
      "\u001b[34m[8]#011validation_0-mlogloss:1.09790#011validation_1-mlogloss:1.09788\u001b[0m\n",
      "\u001b[34m[9]#011validation_0-mlogloss:1.09782#011validation_1-mlogloss:1.09780\u001b[0m\n",
      "\u001b[34m[10]#011validation_0-mlogloss:1.09774#011validation_1-mlogloss:1.09772\u001b[0m\n",
      "\u001b[34m[11]#011validation_0-mlogloss:1.09767#011validation_1-mlogloss:1.09763\u001b[0m\n",
      "\u001b[34m[12]#011validation_0-mlogloss:1.09759#011validation_1-mlogloss:1.09755\u001b[0m\n",
      "\u001b[34m[13]#011validation_0-mlogloss:1.09751#011validation_1-mlogloss:1.09747\u001b[0m\n",
      "\u001b[34m[14]#011validation_0-mlogloss:1.09743#011validation_1-mlogloss:1.09739\u001b[0m\n",
      "\u001b[34m[15]#011validation_0-mlogloss:1.09735#011validation_1-mlogloss:1.09731\u001b[0m\n",
      "\u001b[34m[16]#011validation_0-mlogloss:1.09727#011validation_1-mlogloss:1.09723\u001b[0m\n",
      "\u001b[34m[17]#011validation_0-mlogloss:1.09719#011validation_1-mlogloss:1.09715\u001b[0m\n",
      "\u001b[34m[18]#011validation_0-mlogloss:1.09712#011validation_1-mlogloss:1.09707\u001b[0m\n",
      "\u001b[34m[19]#011validation_0-mlogloss:1.09704#011validation_1-mlogloss:1.09698\u001b[0m\n",
      "\u001b[34m[20]#011validation_0-mlogloss:1.09696#011validation_1-mlogloss:1.09690\u001b[0m\n",
      "\u001b[34m[21]#011validation_0-mlogloss:1.09688#011validation_1-mlogloss:1.09682\u001b[0m\n",
      "\u001b[34m[22]#011validation_0-mlogloss:1.09680#011validation_1-mlogloss:1.09674\u001b[0m\n",
      "\u001b[34m[23]#011validation_0-mlogloss:1.09672#011validation_1-mlogloss:1.09666\u001b[0m\n",
      "\u001b[34m[24]#011validation_0-mlogloss:1.09664#011validation_1-mlogloss:1.09658\u001b[0m\n",
      "\u001b[34m[25]#011validation_0-mlogloss:1.09657#011validation_1-mlogloss:1.09650\u001b[0m\n",
      "\u001b[34m[26]#011validation_0-mlogloss:1.09649#011validation_1-mlogloss:1.09641\u001b[0m\n",
      "\u001b[34m[27]#011validation_0-mlogloss:1.09641#011validation_1-mlogloss:1.09633\u001b[0m\n",
      "\u001b[34m[28]#011validation_0-mlogloss:1.09633#011validation_1-mlogloss:1.09625\u001b[0m\n",
      "\u001b[34m[29]#011validation_0-mlogloss:1.09625#011validation_1-mlogloss:1.09617\u001b[0m\n",
      "\u001b[34m[30]#011validation_0-mlogloss:1.09617#011validation_1-mlogloss:1.09609\u001b[0m\n",
      "\u001b[34m[31]#011validation_0-mlogloss:1.09609#011validation_1-mlogloss:1.09601\u001b[0m\n",
      "\u001b[34m[32]#011validation_0-mlogloss:1.09601#011validation_1-mlogloss:1.09593\u001b[0m\n",
      "\u001b[34m[33]#011validation_0-mlogloss:1.09594#011validation_1-mlogloss:1.09585\u001b[0m\n",
      "\u001b[34m[34]#011validation_0-mlogloss:1.09586#011validation_1-mlogloss:1.09577\u001b[0m\n",
      "\u001b[34m[35]#011validation_0-mlogloss:1.09578#011validation_1-mlogloss:1.09569\u001b[0m\n",
      "\u001b[34m[36]#011validation_0-mlogloss:1.09570#011validation_1-mlogloss:1.09560\u001b[0m\n",
      "\u001b[34m[37]#011validation_0-mlogloss:1.09562#011validation_1-mlogloss:1.09552\u001b[0m\n",
      "\u001b[34m[38]#011validation_0-mlogloss:1.09554#011validation_1-mlogloss:1.09544\u001b[0m\n",
      "\u001b[34m[39]#011validation_0-mlogloss:1.09547#011validation_1-mlogloss:1.09536\u001b[0m\n",
      "\u001b[34m[40]#011validation_0-mlogloss:1.09539#011validation_1-mlogloss:1.09528\u001b[0m\n",
      "\u001b[34m[41]#011validation_0-mlogloss:1.09531#011validation_1-mlogloss:1.09520\u001b[0m\n",
      "\u001b[34m[42]#011validation_0-mlogloss:1.09523#011validation_1-mlogloss:1.09512\u001b[0m\n",
      "\u001b[34m[43]#011validation_0-mlogloss:1.09515#011validation_1-mlogloss:1.09504\u001b[0m\n",
      "\u001b[34m[44]#011validation_0-mlogloss:1.09507#011validation_1-mlogloss:1.09495\u001b[0m\n",
      "\u001b[34m[45]#011validation_0-mlogloss:1.09499#011validation_1-mlogloss:1.09487\u001b[0m\n",
      "\u001b[34m[46]#011validation_0-mlogloss:1.09492#011validation_1-mlogloss:1.09479\u001b[0m\n",
      "\u001b[34m[47]#011validation_0-mlogloss:1.09484#011validation_1-mlogloss:1.09471\u001b[0m\n",
      "\u001b[34m[48]#011validation_0-mlogloss:1.09476#011validation_1-mlogloss:1.09463\u001b[0m\n",
      "\u001b[34m[49]#011validation_0-mlogloss:1.09468#011validation_1-mlogloss:1.09455\u001b[0m\n",
      "\u001b[34m[50]#011validation_0-mlogloss:1.09460#011validation_1-mlogloss:1.09447\u001b[0m\n",
      "\u001b[34m[51]#011validation_0-mlogloss:1.09452#011validation_1-mlogloss:1.09439\u001b[0m\n",
      "\u001b[34m[52]#011validation_0-mlogloss:1.09445#011validation_1-mlogloss:1.09431\u001b[0m\n",
      "\u001b[34m[53]#011validation_0-mlogloss:1.09437#011validation_1-mlogloss:1.09423\u001b[0m\n",
      "\u001b[34m[54]#011validation_0-mlogloss:1.09429#011validation_1-mlogloss:1.09414\u001b[0m\n",
      "\u001b[34m[55]#011validation_0-mlogloss:1.09421#011validation_1-mlogloss:1.09406\u001b[0m\n",
      "\u001b[34m[56]#011validation_0-mlogloss:1.09413#011validation_1-mlogloss:1.09398\u001b[0m\n",
      "\u001b[34m[57]#011validation_0-mlogloss:1.09405#011validation_1-mlogloss:1.09390\u001b[0m\n",
      "\u001b[34m[58]#011validation_0-mlogloss:1.09398#011validation_1-mlogloss:1.09382\u001b[0m\n",
      "\u001b[34m[59]#011validation_0-mlogloss:1.09390#011validation_1-mlogloss:1.09374\u001b[0m\n",
      "\u001b[34m[60]#011validation_0-mlogloss:1.09382#011validation_1-mlogloss:1.09366\u001b[0m\n",
      "\u001b[34m[61]#011validation_0-mlogloss:1.09374#011validation_1-mlogloss:1.09358\u001b[0m\n",
      "\u001b[34m[62]#011validation_0-mlogloss:1.09366#011validation_1-mlogloss:1.09350\u001b[0m\n",
      "\u001b[34m[63]#011validation_0-mlogloss:1.09359#011validation_1-mlogloss:1.09342\u001b[0m\n",
      "\u001b[34m[64]#011validation_0-mlogloss:1.09351#011validation_1-mlogloss:1.09334\u001b[0m\n",
      "\u001b[34m[65]#011validation_0-mlogloss:1.09343#011validation_1-mlogloss:1.09326\u001b[0m\n",
      "\u001b[34m[66]#011validation_0-mlogloss:1.09335#011validation_1-mlogloss:1.09318\u001b[0m\n",
      "\u001b[34m[67]#011validation_0-mlogloss:1.09327#011validation_1-mlogloss:1.09309\u001b[0m\n",
      "\u001b[34m[68]#011validation_0-mlogloss:1.09319#011validation_1-mlogloss:1.09301\u001b[0m\n",
      "\u001b[34m[69]#011validation_0-mlogloss:1.09312#011validation_1-mlogloss:1.09293\u001b[0m\n",
      "\u001b[34m[70]#011validation_0-mlogloss:1.09304#011validation_1-mlogloss:1.09285\u001b[0m\n",
      "\u001b[34m[71]#011validation_0-mlogloss:1.09296#011validation_1-mlogloss:1.09277\u001b[0m\n",
      "\u001b[34m[72]#011validation_0-mlogloss:1.09288#011validation_1-mlogloss:1.09269\u001b[0m\n",
      "\u001b[34m[73]#011validation_0-mlogloss:1.09280#011validation_1-mlogloss:1.09261\u001b[0m\n",
      "\u001b[34m[74]#011validation_0-mlogloss:1.09273#011validation_1-mlogloss:1.09253\u001b[0m\n",
      "\u001b[34m[75]#011validation_0-mlogloss:1.09265#011validation_1-mlogloss:1.09245\u001b[0m\n",
      "\u001b[34m[76]#011validation_0-mlogloss:1.09257#011validation_1-mlogloss:1.09237\u001b[0m\n",
      "\u001b[34m[77]#011validation_0-mlogloss:1.09249#011validation_1-mlogloss:1.09229\u001b[0m\n",
      "\u001b[34m[78]#011validation_0-mlogloss:1.09241#011validation_1-mlogloss:1.09221\u001b[0m\n",
      "\u001b[34m[79]#011validation_0-mlogloss:1.09234#011validation_1-mlogloss:1.09213\u001b[0m\n",
      "\u001b[34m[80]#011validation_0-mlogloss:1.09226#011validation_1-mlogloss:1.09205\u001b[0m\n",
      "\u001b[34m[81]#011validation_0-mlogloss:1.09218#011validation_1-mlogloss:1.09197\u001b[0m\n",
      "\u001b[34m[82]#011validation_0-mlogloss:1.09210#011validation_1-mlogloss:1.09188\u001b[0m\n",
      "\u001b[34m[83]#011validation_0-mlogloss:1.09202#011validation_1-mlogloss:1.09180\u001b[0m\n",
      "\u001b[34m[84]#011validation_0-mlogloss:1.09195#011validation_1-mlogloss:1.09172\u001b[0m\n",
      "\u001b[34m[85]#011validation_0-mlogloss:1.09187#011validation_1-mlogloss:1.09164\u001b[0m\n",
      "\u001b[34m[86]#011validation_0-mlogloss:1.09179#011validation_1-mlogloss:1.09156\u001b[0m\n",
      "\u001b[34m[87]#011validation_0-mlogloss:1.09171#011validation_1-mlogloss:1.09148\u001b[0m\n",
      "\u001b[34m[88]#011validation_0-mlogloss:1.09163#011validation_1-mlogloss:1.09140\u001b[0m\n",
      "\u001b[34m[89]#011validation_0-mlogloss:1.09156#011validation_1-mlogloss:1.09132\u001b[0m\n",
      "\u001b[34m[90]#011validation_0-mlogloss:1.09148#011validation_1-mlogloss:1.09124\u001b[0m\n",
      "\u001b[34m[91]#011validation_0-mlogloss:1.09140#011validation_1-mlogloss:1.09116\u001b[0m\n",
      "\u001b[34m[92]#011validation_0-mlogloss:1.09132#011validation_1-mlogloss:1.09108\u001b[0m\n",
      "\u001b[34m[93]#011validation_0-mlogloss:1.09125#011validation_1-mlogloss:1.09100\u001b[0m\n",
      "\u001b[34m[94]#011validation_0-mlogloss:1.09117#011validation_1-mlogloss:1.09092\u001b[0m\n",
      "\u001b[34m[95]#011validation_0-mlogloss:1.09109#011validation_1-mlogloss:1.09084\u001b[0m\n",
      "\u001b[34m[96]#011validation_0-mlogloss:1.09101#011validation_1-mlogloss:1.09076\u001b[0m\n",
      "\u001b[34m[97]#011validation_0-mlogloss:1.09093#011validation_1-mlogloss:1.09068\u001b[0m\n",
      "\u001b[34m[98]#011validation_0-mlogloss:1.09086#011validation_1-mlogloss:1.09060\u001b[0m\n",
      "\u001b[34m[99]#011validation_0-mlogloss:1.09078#011validation_1-mlogloss:1.09052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.86      1.00      0.92         6\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.95      0.97      0.96        30\u001b[0m\n",
      "\u001b[34mweighted avg       0.97      0.97      0.97        30\n",
      "\u001b[0m\n",
      "\u001b[34m[[11  1  0]\n",
      " [ 0  6  0]\n",
      " [ 0  0 12]]\u001b[0m\n",
      "\u001b[34m0.9714285714285714\u001b[0m\n",
      "\u001b[34msave booster\u001b[0m\n",
      "Training seconds: 51\n",
      "Billable seconds: 51\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "hyperparameters = {\n",
    "    \"hp1\": \"value1\",\n",
    "    \"hp2\": 300,\n",
    "    \"hp3\": 0.001}\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"../docker/code\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    framework_version=\"1.0-1\",\n",
    ")\n",
    "\n",
    "train_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "xgb_estimator.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "serializer = CSVSerializer()\n",
    "serializer.CONTENT_TYPE = \"text/csv\"\n",
    "\n",
    "predictor = xgb_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.medium\",\n",
    "    serializer=serializer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"file.csv\") as f:\n",
    "    payload = f.read()\n",
    "\n",
    "predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Get Predictor </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0.335604', '0.32953852', '0.3348575'],\n",
       " ['0.3353785', '0.329989', '0.3346325']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.xgboost.model import XGBoostPredictor\n",
    "import numpy as np\n",
    "\n",
    "endpoint_name = \"sagemaker-xgboost-2020-08-11-06-52-30-545\"\n",
    "payload = \"1,2,3,4,5\\n2,3,4,5,6\"\n",
    "\n",
    "xgb_predictor = XGBoostPredictor(endpoint_name)\n",
    "\n",
    "xgb_predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Low level API - inference </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3306555449962616, 0.33722642064094543, 0.33211803436279297]]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "runtime_client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "\n",
    "payload = \"1,2,3,4,5\"\n",
    "endpoint_name = 'sagemaker-xgboost-2020-08-11-06-52-30-545'\n",
    "\n",
    "response = runtime_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType='text/csv',\n",
    "                                   Body=payload)\n",
    "\n",
    "result = response['Body'].read().decode('ascii')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smv2",
   "language": "python",
   "name": "smv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
