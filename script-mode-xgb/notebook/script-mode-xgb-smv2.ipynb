{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameter_ranges = {'lr': ContinuousParameter(0.001, 0.01),\n",
    "                         'n-epochs': IntegerParameter(100, 200)}<h1> Method 1: Train with custom XGB Container </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to build and use a custom Docker container for training with Amazon SageMaker that leverages on the <strong>Script Mode</strong> execution that is implemented by the sagemaker-containers library. Reference documentation is available at https://github.com/aws/sagemaker-containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining some variables like the current execution role, the ECR repository that we are going to use for pushing the custom Docker container and a default Amazon S3 bucket to be used by Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "342474125894\nap-southeast-1\narn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\nsagemaker-ap-southeast-1-342474125894\nsagemaker-training-containers/script-mode-container-xgb\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "ecr_namespace = 'sagemaker-training-containers/'\n",
    "prefix = 'script-mode-container-xgb'\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = \"arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\"\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)\n",
    "print(ecr_repository_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Build and push the container</h3>\n",
    "We are now ready to build this container and push it to Amazon ECR. This task is executed using a shell script stored in the ../script/ folder. Let's take a look at this script and then execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "container  147.3s\n",
      "\u001b[0m\u001b[34m => [8/9] COPY code/* /opt/ml/code/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     2.6s\n",
      " => => exporting layers                                                    2.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 219.8s (13/14)                                                     \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.29kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:16.04            3.3s\n",
      "\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 78.18kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => [1/9] FROM docker.io/library/ubuntu:16.04@sha256:3355b6e4ba1b12071ba5  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/9] RUN apt-get update && apt-get install -y --no-install-re  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/9] RUN wget https://www.python.org/ftp/python/3.6.6/Python-  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/9] RUN pip3 --no-cache-dir install --upgrade pip             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/9] RUN ln -s $(which python3) /usr/local/bin/python          0.0s\n",
      "\u001b[0m\u001b[34m => [6/9] RUN pip3 install --no-cache --upgrade     numpy==1.14.5     pa  66.3s\n",
      "\u001b[0m\u001b[34m => [7/9] RUN pip3 install --no-cache --upgrade     sagemaker-container  147.3s\n",
      "\u001b[0m\u001b[34m => [8/9] COPY code/* /opt/ml/code/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     2.7s\n",
      " => => exporting layers                                                    2.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 219.9s (13/14)                                                     \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.29kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:16.04            3.3s\n",
      "\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 78.18kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => [1/9] FROM docker.io/library/ubuntu:16.04@sha256:3355b6e4ba1b12071ba5  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/9] RUN apt-get update && apt-get install -y --no-install-re  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/9] RUN wget https://www.python.org/ftp/python/3.6.6/Python-  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/9] RUN pip3 --no-cache-dir install --upgrade pip             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/9] RUN ln -s $(which python3) /usr/local/bin/python          0.0s\n",
      "\u001b[0m\u001b[34m => [6/9] RUN pip3 install --no-cache --upgrade     numpy==1.14.5     pa  66.3s\n",
      "\u001b[0m\u001b[34m => [7/9] RUN pip3 install --no-cache --upgrade     sagemaker-container  147.3s\n",
      "\u001b[0m\u001b[34m => [8/9] COPY code/* /opt/ml/code/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     2.9s\n",
      " => => exporting layers                                                    2.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 220.1s (13/14)                                                     \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.29kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:16.04            3.3s\n",
      "\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 78.18kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => [1/9] FROM docker.io/library/ubuntu:16.04@sha256:3355b6e4ba1b12071ba5  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/9] RUN apt-get update && apt-get install -y --no-install-re  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/9] RUN wget https://www.python.org/ftp/python/3.6.6/Python-  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/9] RUN pip3 --no-cache-dir install --upgrade pip             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/9] RUN ln -s $(which python3) /usr/local/bin/python          0.0s\n",
      "\u001b[0m\u001b[34m => [6/9] RUN pip3 install --no-cache --upgrade     numpy==1.14.5     pa  66.3s\n",
      "\u001b[0m\u001b[34m => [7/9] RUN pip3 install --no-cache --upgrade     sagemaker-container  147.3s\n",
      "\u001b[0m\u001b[34m => [8/9] COPY code/* /opt/ml/code/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     3.0s\n",
      " => => exporting layers                                                    3.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 220.2s (13/14)                                                     \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.29kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:16.04            3.3s\n",
      "\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 78.18kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => [1/9] FROM docker.io/library/ubuntu:16.04@sha256:3355b6e4ba1b12071ba5  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/9] RUN apt-get update && apt-get install -y --no-install-re  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/9] RUN wget https://www.python.org/ftp/python/3.6.6/Python-  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/9] RUN pip3 --no-cache-dir install --upgrade pip             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/9] RUN ln -s $(which python3) /usr/local/bin/python          0.0s\n",
      "\u001b[0m\u001b[34m => [6/9] RUN pip3 install --no-cache --upgrade     numpy==1.14.5     pa  66.3s\n",
      "\u001b[0m\u001b[34m => [7/9] RUN pip3 install --no-cache --upgrade     sagemaker-container  147.3s\n",
      "\u001b[0m\u001b[34m => [8/9] COPY code/* /opt/ml/code/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     3.2s\n",
      " => => exporting layers                                                    3.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 220.4s (13/14)                                                     \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.29kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:16.04            3.3s\n",
      "\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 78.18kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => [1/9] FROM docker.io/library/ubuntu:16.04@sha256:3355b6e4ba1b12071ba5  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/9] RUN apt-get update && apt-get install -y --no-install-re  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/9] RUN wget https://www.python.org/ftp/python/3.6.6/Python-  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/9] RUN pip3 --no-cache-dir install --upgrade pip             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/9] RUN ln -s $(which python3) /usr/local/bin/python          0.0s\n",
      "\u001b[0m\u001b[34m => [6/9] RUN pip3 install --no-cache --upgrade     numpy==1.14.5     pa  66.3s\n",
      "\u001b[0m\u001b[34m => [7/9] RUN pip3 install --no-cache --upgrade     sagemaker-container  147.3s\n",
      "\u001b[0m\u001b[34m => [8/9] COPY code/* /opt/ml/code/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     3.3s\n",
      " => => exporting layers                                                    3.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 220.5s (13/14)                                                     \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.29kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:16.04            3.3s\n",
      "\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 78.18kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => [1/9] FROM docker.io/library/ubuntu:16.04@sha256:3355b6e4ba1b12071ba5  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/9] RUN apt-get update && apt-get install -y --no-install-re  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/9] RUN wget https://www.python.org/ftp/python/3.6.6/Python-  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/9] RUN pip3 --no-cache-dir install --upgrade pip             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/9] RUN ln -s $(which python3) /usr/local/bin/python          0.0s\n",
      "\u001b[0m\u001b[34m => [6/9] RUN pip3 install --no-cache --upgrade     numpy==1.14.5     pa  66.3s\n",
      "\u001b[0m\u001b[34m => [7/9] RUN pip3 install --no-cache --upgrade     sagemaker-container  147.3s\n",
      "\u001b[0m\u001b[34m => [8/9] COPY code/* /opt/ml/code/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     3.5s\n",
      " => => exporting layers                                                    3.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 220.7s (13/14)                                                     \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.29kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:16.04            3.3s\n",
      "\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 78.18kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => [1/9] FROM docker.io/library/ubuntu:16.04@sha256:3355b6e4ba1b12071ba5  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/9] RUN apt-get update && apt-get install -y --no-install-re  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/9] RUN wget https://www.python.org/ftp/python/3.6.6/Python-  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/9] RUN pip3 --no-cache-dir install --upgrade pip             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/9] RUN ln -s $(which python3) /usr/local/bin/python          0.0s\n",
      "\u001b[0m\u001b[34m => [6/9] RUN pip3 install --no-cache --upgrade     numpy==1.14.5     pa  66.3s\n",
      "\u001b[0m\u001b[34m => [7/9] RUN pip3 install --no-cache --upgrade     sagemaker-container  147.3s\n",
      "\u001b[0m\u001b[34m => [8/9] COPY code/* /opt/ml/code/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     3.7s\n",
      " => => exporting layers                                                    3.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 220.8s (13/14)                                                     \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.29kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:16.04            3.3s\n",
      "\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 78.18kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => [1/9] FROM docker.io/library/ubuntu:16.04@sha256:3355b6e4ba1b12071ba5  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/9] RUN apt-get update && apt-get install -y --no-install-re  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/9] RUN wget https://www.python.org/ftp/python/3.6.6/Python-  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/9] RUN pip3 --no-cache-dir install --upgrade pip             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/9] RUN ln -s $(which python3) /usr/local/bin/python          0.0s\n",
      "\u001b[0m\u001b[34m => [6/9] RUN pip3 install --no-cache --upgrade     numpy==1.14.5     pa  66.3s\n",
      "\u001b[0m\u001b[34m => [7/9] RUN pip3 install --no-cache --upgrade     sagemaker-container  147.3s\n",
      "\u001b[0m\u001b[34m => [8/9] COPY code/* /opt/ml/code/                                        0.1s\n",
      "\u001b[0m => exporting to image                                                     3.8s\n",
      " => => exporting layers                                                    3.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 220.9s (14/14)                                                     \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.29kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:16.04            3.3s\n",
      "\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 78.18kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => [1/9] FROM docker.io/library/ubuntu:16.04@sha256:3355b6e4ba1b12071ba5  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/9] RUN apt-get update && apt-get install -y --no-install-re  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/9] RUN wget https://www.python.org/ftp/python/3.6.6/Python-  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/9] RUN pip3 --no-cache-dir install --upgrade pip             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/9] RUN ln -s $(which python3) /usr/local/bin/python          0.0s\n",
      "\u001b[0m\u001b[34m => [6/9] RUN pip3 install --no-cache --upgrade     numpy==1.14.5     pa  66.3s\n",
      "\u001b[0m\u001b[34m => [7/9] RUN pip3 install --no-cache --upgrade     sagemaker-container  147.3s\n",
      "\u001b[0m\u001b[34m => [8/9] COPY code/* /opt/ml/code/                                        0.1s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     3.9s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    3.9s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:0fb87c8cb6928a77a9ca6785c43d5f5663c02e326496d  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/sagemaker-training-containers/script-mode-cont  0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 220.9s (14/14) FINISHED                                            \n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.29kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:16.04            3.3s\n",
      "\u001b[0m\u001b[34m => [auth] library/ubuntu:pull token for registry-1.docker.io              0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 78.18kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => [1/9] FROM docker.io/library/ubuntu:16.04@sha256:3355b6e4ba1b12071ba5  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/9] RUN apt-get update && apt-get install -y --no-install-re  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/9] RUN wget https://www.python.org/ftp/python/3.6.6/Python-  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/9] RUN pip3 --no-cache-dir install --upgrade pip             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/9] RUN ln -s $(which python3) /usr/local/bin/python          0.0s\n",
      "\u001b[0m\u001b[34m => [6/9] RUN pip3 install --no-cache --upgrade     numpy==1.14.5     pa  66.3s\n",
      "\u001b[0m\u001b[34m => [7/9] RUN pip3 install --no-cache --upgrade     sagemaker-container  147.3s\n",
      "\u001b[0m\u001b[34m => [8/9] COPY code/* /opt/ml/code/                                        0.1s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     3.9s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    3.9s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:0fb87c8cb6928a77a9ca6785c43d5f5663c02e326496d  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/sagemaker-training-containers/script-mode-cont  0.0s\n",
      "\u001b[0m\u001b[?25h+ docker tag sagemaker-training-containers/script-mode-container-xgb 342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/script-mode-container-xgb:latest\n",
      "+ SERVER=342474125894.dkr.ecr.ap-southeast-1.amazonaws.com\n",
      "+ aws ecr get-login-password\n",
      "+ docker login --username AWS --password-stdin 342474125894.dkr.ecr.ap-southeast-1.amazonaws.com\n",
      "Login Succeeded\n",
      "+ echo '***Create Repo***'\n",
      "***Create Repo***\n",
      "+ aws ecr describe-repositories --repository-names sagemaker-training-containers/script-mode-container-xgb\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryArn\": \"arn:aws:ecr:ap-southeast-1:342474125894:repository/sagemaker-training-containers/script-mode-container-xgb\",\n",
      "            \"registryId\": \"342474125894\",\n",
      "            \"repositoryName\": \"sagemaker-training-containers/script-mode-container-xgb\",\n",
      "            \"repositoryUri\": \"342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/script-mode-container-xgb\",\n",
      "            \"createdAt\": \"2020-08-10T21:17:01+08:00\",\n",
      "            \"imageTagMutability\": \"MUTABLE\",\n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            },\n",
      "            \"encryptionConfiguration\": {\n",
      "                \"encryptionType\": \"AES256\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "+ echo '***Push to Repo***'\n",
      "***Push to Repo***\n",
      "+ docker push 342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/script-mode-container-xgb:latest\n",
      "The push refers to repository [342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/script-mode-container-xgb]\n",
      "\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[5Blatest: digest: sha256:9f8ec44feb80fc451189988ddf8abe2edca1d1a863f966e9ba3f8b3ce079aeb7 size: 2627\n"
     ]
    }
   ],
   "source": [
    "! ../scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training with Amazon SageMaker</h3>\n",
    "\n",
    "Once we have correctly pushed our container to Amazon ECR, we are ready to start training with Amazon SageMaker, which requires the ECR path to the Docker container used for training as parameter for starting a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/script-mode-container-xgb:latest\n"
     ]
    }
   ],
   "source": [
    "container_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, ecr_repository_name)\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare Data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we upload some dummy data to Amazon S3, in order to define our S3-based training channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X: (100, 5), y:(100,)\ntrain_df: (70, 6), test_df:(30, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=100, n_features=5, n_redundant=0, n_informative=2, n_clusters_per_class=1, n_classes=3\n",
    ")\n",
    "print(f\"X: {X.shape}, y:{y.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "train_df = pd.concat([y_train, X_train], axis=1)\n",
    "train_df.columns = range(train_df.shape[1])\n",
    "test_df = pd.concat([y_test, X_test], axis=1)\n",
    "test_df.columns = range(test_df.shape[1])\n",
    "\n",
    "print(f\"train_df: {train_df.shape}, test_df:{test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "s3://sagemaker-ap-southeast-1-342474125894/script-mode-container-xgb/train/train.csv\ns3://sagemaker-ap-southeast-1-342474125894/script-mode-container-xgb/val/test.csv\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"../test_data/train/train.csv\"\n",
    "test_filename = \"../test_data/val/test.csv\"\n",
    "train_df.to_csv(train_filename, header=True, index=False)\n",
    "test_df.to_csv(test_filename, header=True, index=False)\n",
    "\n",
    "train_uri = sagemaker_session.upload_data(train_filename, bucket, prefix + '/train')\n",
    "test_uri = sagemaker_session.upload_data(test_filename, bucket, prefix + '/val')\n",
    "print(train_uri)\n",
    "print(test_uri)\n",
    "#! rm $train_filename $test_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can execute the training job by calling the fit() method of the generic Estimator object defined in the Amazon SageMaker Python SDK (https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/estimator.py). This corresponds to calling the CreateTrainingJob() API (https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTrainingJob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating tmp7egnrajv_algo-1-hf9jk_1 ... \n",
      "\u001b[1BAttaching to tmp7egnrajv_algo-1-hf9jk_1\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m 2021-01-04 07:46:37,965 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m 2021-01-04 07:46:37,973 sagemaker-containers INFO     Failed to parse hyperparameter hp1 value value1 to Json.\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m 2021-01-04 07:46:38,004 sagemaker-containers INFO     Failed to parse hyperparameter hp1 value value1 to Json.\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m 2021-01-04 07:46:38,010 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m 2021-01-04 07:46:38,031 sagemaker-containers INFO     Failed to parse hyperparameter hp1 value value1 to Json.\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m 2021-01-04 07:46:38,036 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m 2021-01-04 07:46:38,052 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"current_host\": \"algo-1-hf9jk\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"framework_module\": null,\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m         \"algo-1-hf9jk\"\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m         \"hp1\": \"value1\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m         \"hp2\": 300,\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m         \"hp3\": 0.001\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m             \"ContentType\": \"text/csv\"\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m         \"validation\": {\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m             \"ContentType\": \"text/csv\"\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"job_name\": \"script-mode-container-xgb-2021-01-04-07-46-32-825\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"master_hostname\": \"algo-1-hf9jk\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m         \"current_host\": \"algo-1-hf9jk\",\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m             \"algo-1-hf9jk\"\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_HOSTS=[\"algo-1-hf9jk\"]\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_HPS={\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001}\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-hf9jk\",\"hosts\":[\"algo-1-hf9jk\"]}\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_CHANNELS=[\"train\",\"validation\"]\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_CURRENT_HOST=algo-1-hf9jk\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_FRAMEWORK_MODULE=\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-hf9jk\",\"framework_module\":null,\"hosts\":[\"algo-1-hf9jk\"],\"hyperparameters\":{\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"script-mode-container-xgb-2021-01-04-07-46-32-825\",\"log_level\":20,\"master_hostname\":\"algo-1-hf9jk\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-hf9jk\",\"hosts\":[\"algo-1-hf9jk\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_USER_ARGS=[\"--hp1\",\"value1\",\"--hp2\",\"300\",\"--hp3\",\"0.001\"]\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_HP_HP1=value1\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_HP_HP2=300\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m SM_HP_HP3=0.001\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m /usr/local/bin/python3.6 train.py --hp1 value1 --hp2 300 --hp3 0.001\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m Namespace(epochs=50, hp1='value1', hp2=300, hp3=0.001, model_dir='/opt/ml/model', train='/opt/ml/input/data/train', validation='/opt/ml/input/data/validation')\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m List of files in train channel: \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m /opt/ml/input/data/train/train.csv\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m List of files in validation channel: \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m /opt/ml/input/data/validation/test.csv\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m X_train: (70, 5), y_train:(70,)\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m X_test: (30, 5), y_test:(30,)\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m        colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=None,\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m        importance_type='gain', interaction_constraints=None,\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m        learning_rate=0.0001, max_delta_step=0, max_depth=5,\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m        min_child_weight=5, missing=None, monotone_constraints=None,\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m        n_estimators=50, n_jobs=3, nthread=None, num_parallel_tree=None,\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m        objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m        reg_lambda=1, scale_pos_weight=None, subsample=1, tree_method=None,\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m        validate_parameters=None, verbosity=1)\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [0]\tvalidation_0-mlogloss:1.09851\tvalidation_1-mlogloss:1.09853\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m Will train until validation_1-mlogloss hasn't improved in 10 rounds.\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [1]\tvalidation_0-mlogloss:1.09841\tvalidation_1-mlogloss:1.09844\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [2]\tvalidation_0-mlogloss:1.09830\tvalidation_1-mlogloss:1.09836\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [3]\tvalidation_0-mlogloss:1.09820\tvalidation_1-mlogloss:1.09828\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [4]\tvalidation_0-mlogloss:1.09810\tvalidation_1-mlogloss:1.09820\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [5]\tvalidation_0-mlogloss:1.09799\tvalidation_1-mlogloss:1.09811\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [6]\tvalidation_0-mlogloss:1.09789\tvalidation_1-mlogloss:1.09803\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [7]\tvalidation_0-mlogloss:1.09779\tvalidation_1-mlogloss:1.09795\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [8]\tvalidation_0-mlogloss:1.09769\tvalidation_1-mlogloss:1.09786\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [9]\tvalidation_0-mlogloss:1.09758\tvalidation_1-mlogloss:1.09778\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [10]\tvalidation_0-mlogloss:1.09748\tvalidation_1-mlogloss:1.09770\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [11]\tvalidation_0-mlogloss:1.09738\tvalidation_1-mlogloss:1.09761\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [12]\tvalidation_0-mlogloss:1.09727\tvalidation_1-mlogloss:1.09753\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [13]\tvalidation_0-mlogloss:1.09717\tvalidation_1-mlogloss:1.09745\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [14]\tvalidation_0-mlogloss:1.09707\tvalidation_1-mlogloss:1.09736\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [15]\tvalidation_0-mlogloss:1.09696\tvalidation_1-mlogloss:1.09728\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [16]\tvalidation_0-mlogloss:1.09686\tvalidation_1-mlogloss:1.09720\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [17]\tvalidation_0-mlogloss:1.09676\tvalidation_1-mlogloss:1.09712\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [18]\tvalidation_0-mlogloss:1.09666\tvalidation_1-mlogloss:1.09703\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [19]\tvalidation_0-mlogloss:1.09655\tvalidation_1-mlogloss:1.09695\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [20]\tvalidation_0-mlogloss:1.09645\tvalidation_1-mlogloss:1.09686\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [21]\tvalidation_0-mlogloss:1.09635\tvalidation_1-mlogloss:1.09678\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [22]\tvalidation_0-mlogloss:1.09625\tvalidation_1-mlogloss:1.09670\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [23]\tvalidation_0-mlogloss:1.09614\tvalidation_1-mlogloss:1.09662\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [24]\tvalidation_0-mlogloss:1.09604\tvalidation_1-mlogloss:1.09653\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [25]\tvalidation_0-mlogloss:1.09594\tvalidation_1-mlogloss:1.09645\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [26]\tvalidation_0-mlogloss:1.09583\tvalidation_1-mlogloss:1.09637\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [27]\tvalidation_0-mlogloss:1.09573\tvalidation_1-mlogloss:1.09628\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [28]\tvalidation_0-mlogloss:1.09563\tvalidation_1-mlogloss:1.09620\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [29]\tvalidation_0-mlogloss:1.09553\tvalidation_1-mlogloss:1.09612\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [30]\tvalidation_0-mlogloss:1.09543\tvalidation_1-mlogloss:1.09604\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [31]\tvalidation_0-mlogloss:1.09532\tvalidation_1-mlogloss:1.09595\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [32]\tvalidation_0-mlogloss:1.09522\tvalidation_1-mlogloss:1.09587\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [33]\tvalidation_0-mlogloss:1.09512\tvalidation_1-mlogloss:1.09579\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [34]\tvalidation_0-mlogloss:1.09502\tvalidation_1-mlogloss:1.09570\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [35]\tvalidation_0-mlogloss:1.09491\tvalidation_1-mlogloss:1.09562\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [36]\tvalidation_0-mlogloss:1.09481\tvalidation_1-mlogloss:1.09554\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [37]\tvalidation_0-mlogloss:1.09471\tvalidation_1-mlogloss:1.09546\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [38]\tvalidation_0-mlogloss:1.09461\tvalidation_1-mlogloss:1.09537\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [39]\tvalidation_0-mlogloss:1.09450\tvalidation_1-mlogloss:1.09529\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [40]\tvalidation_0-mlogloss:1.09440\tvalidation_1-mlogloss:1.09521\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [41]\tvalidation_0-mlogloss:1.09430\tvalidation_1-mlogloss:1.09512\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [42]\tvalidation_0-mlogloss:1.09420\tvalidation_1-mlogloss:1.09504\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [43]\tvalidation_0-mlogloss:1.09409\tvalidation_1-mlogloss:1.09496\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [44]\tvalidation_0-mlogloss:1.09399\tvalidation_1-mlogloss:1.09488\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [45]\tvalidation_0-mlogloss:1.09389\tvalidation_1-mlogloss:1.09479\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [46]\tvalidation_0-mlogloss:1.09379\tvalidation_1-mlogloss:1.09471\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [47]\tvalidation_0-mlogloss:1.09368\tvalidation_1-mlogloss:1.09463\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [48]\tvalidation_0-mlogloss:1.09358\tvalidation_1-mlogloss:1.09454\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [49]\tvalidation_0-mlogloss:1.09348\tvalidation_1-mlogloss:1.09446\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m               precision    recall  f1-score   support\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m            0       1.00      0.82      0.90        11\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m            1       0.64      0.78      0.70         9\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m            2       0.80      0.80      0.80        10\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m    micro avg       0.80      0.80      0.80        30\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m    macro avg       0.81      0.80      0.80        30\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m weighted avg       0.82      0.80      0.81        30\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m \n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m [[9 2 0]\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m  [0 7 2]\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m  [0 2 8]]\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m 0.8242424242424242\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m save booster\n",
      "\u001b[36malgo-1-hf9jk_1  |\u001b[0m 2021-01-04 07:46:39,502 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmp7egnrajv_algo-1-hf9jk_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "\n",
    "# Must align with training script argparser\n",
    "hyperparameters = {\n",
    "    \"hp1\": \"value1\",\n",
    "    \"hp2\": 300,\n",
    "    \"hp3\": 0.001}\n",
    "\n",
    "# Custom container can support metric definition\n",
    "est = sagemaker.estimator.Estimator(container_image_uri,\n",
    "                                    role,\n",
    "                                    instance_count=1, \n",
    "                                    instance_type='local', # we use local mode\n",
    "                                    #instance_type='ml.m5.xlarge',\n",
    "                                    base_job_name=prefix,\n",
    "                                    hyperparameters=hyperparameters)\n",
    "\n",
    "train_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "est.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "# Must align with training script argparser\n",
    "hyperparameters = {\n",
    "    \"hp1\": \"value1\",\n",
    "    \"hp2\": 300,\n",
    "    \"hp3\": 0.001}\n",
    "\n",
    "xgb_estimator = sagemaker.estimator.Estimator(container_image_uri,\n",
    "                                    role,\n",
    "                                    instance_count=1, \n",
    "                                    #instance_type='local', # we use local mode\n",
    "                                    instance_type='ml.m5.xlarge',\n",
    "                                    base_job_name=prefix, # Set based job name to easily identify job under HPO\n",
    "                                    hyperparameters=hyperparameters)\n",
    "\n",
    "# Must align with training script argparser\n",
    "hyperparameter_ranges = {'epochs': IntegerParameter(10, 20),\n",
    "                         #'lr': ContinuousParameter(0.001, 0.01),\n",
    "                        }\n",
    "\n",
    "# Must exist in one of the metric definition\n",
    "objective_metric_name = 'validation-mlogloss'\n",
    "\n",
    "metric_definitions = [{'Name': 'train-mlogloss',\n",
    "                       'Regex': 'validation_0-mlogloss:([0-9\\\\.]+)'},\n",
    "                     {'Name': 'validation-mlogloss',\n",
    "                       'Regex': 'validation_1-mlogloss:([0-9\\\\.]+)'}]\n",
    "\n",
    "task_tags = [{'Key':'ML Task', 'Value':'XGBoost'}]\n",
    "tuner = HyperparameterTuner(xgb_estimator,\n",
    "                            objective_metric_name=objective_metric_name,\n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            tags=task_tags,\n",
    "                            objective_type='Maximize',\n",
    "                            max_jobs=2,\n",
    "                            max_parallel_jobs=2)\n",
    "\n",
    "train_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "tuner.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve metrics for best tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>validation-mlogloss</td>\n",
       "      <td>1.09765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp          metric_name    value\n",
       "0        0.0  validation-mlogloss  1.09765"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "\n",
    "metric_name = 'validation-mlogloss'\n",
    "job_name = tuner.best_training_job()\n",
    "metrics_dataframe = TrainingJobAnalytics(training_job_name=job_name, metric_names=[metric_name]).dataframe()\n",
    "metrics_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>check model artifact</h3>\n",
    "    \n",
    "make sure it is Booster type,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-342474125894/script-mode-containe-200820-1621-002-fa80cf0e/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "artifact_path = est.latest_training_job.describe()['ModelArtifacts']['S3ModelArtifacts']\n",
    "#artifact_path = \"s3://sagemaker-ap-southeast-1-342474125894/script-mode-containe-200820-1621-002-fa80cf0e/output/model.tar.gz\"\n",
    "print(artifact_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-southeast-1-342474125894/script-mode-containe-200820-1621-002-fa80cf0e/output/model.tar.gz to ./model.tar.gz\n",
      "x model.pth\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp $artifact_path .\n",
    "! tar -xvf model.tar.gz\n",
    "! rm model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x128235ac0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('model.pth', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Method 2: Train with Prebuilt container </h1>\n",
    "\n",
    "Prebuilt container has both sagemaker-container/sagemaker-inference install in a single image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-20 07:45:31 Starting - Starting the training job...\n",
      "2020-08-20 07:45:33 Starting - Launching requested ML instances......\n",
      "2020-08-20 07:46:40 Starting - Preparing the instances for training......\n",
      "2020-08-20 07:48:02 Downloading - Downloading input data\n",
      "2020-08-20 07:48:02 Training - Downloading the training image...\n",
      "2020-08-20 07:48:30 Uploading - Uploading generated training model\n",
      "2020-08-20 07:48:30 Completed - Training job completed\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Invoking user training script.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating setup.cfg\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\n",
      "  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=9278 sha256=cbb965065f10544ae9d37dca66968b13c0dc1847ae5ed3cd197bcc16cf1391c8\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-v9vjqy19/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hp1\": \"value1\",\n",
      "        \"hp3\": 0.001,\n",
      "        \"hp2\": 300\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-xgboost-2020-08-20-07-45-37-434\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-1-342474125894/sagemaker-xgboost-2020-08-20-07-45-37-434/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-southeast-1-342474125894/sagemaker-xgboost-2020-08-20-07-45-37-434/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2020-08-20-07-45-37-434\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-1-342474125894/sagemaker-xgboost-2020-08-20-07-45-37-434/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--hp1\",\"value1\",\"--hp2\",\"300\",\"--hp3\",\"0.001\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HP1=value1\u001b[0m\n",
      "\u001b[34mSM_HP_HP3=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_HP2=300\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python3.6/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python36.zip:/miniconda3/lib/python3.6:/miniconda3/lib/python3.6/lib-dynload:/miniconda3/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m train --hp1 value1 --hp2 300 --hp3 0.001\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNamespace(epochs=50, hp1='value1', hp2=300, hp3=0.001, model_dir='/opt/ml/model', train='/opt/ml/input/data/train', validation='/opt/ml/input/data/validation')\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in train channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/train/train.csv\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in validation channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/validation/test.csv\u001b[0m\n",
      "\u001b[34mX_train: (70, 5), y_train:(70,)\u001b[0m\n",
      "\u001b[34mX_test: (30, 5), y_test:(30,)\u001b[0m\n",
      "\u001b[34mXGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.0001, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=5, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=50, n_jobs=3, nthread=None, num_parallel_tree=None,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method=None, validate_parameters=False, verbosity=1)\u001b[0m\n",
      "\u001b[34m[0]#011validation_0-mlogloss:1.09853#011validation_1-mlogloss:1.09853\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation_1-mlogloss hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[1]#011validation_0-mlogloss:1.09845#011validation_1-mlogloss:1.09845\u001b[0m\n",
      "\u001b[34m[2]#011validation_0-mlogloss:1.09838#011validation_1-mlogloss:1.09837\u001b[0m\n",
      "\u001b[34m[3]#011validation_0-mlogloss:1.09830#011validation_1-mlogloss:1.09829\u001b[0m\n",
      "\u001b[34m[4]#011validation_0-mlogloss:1.09822#011validation_1-mlogloss:1.09821\u001b[0m\n",
      "\u001b[34m[5]#011validation_0-mlogloss:1.09814#011validation_1-mlogloss:1.09812\u001b[0m\n",
      "\u001b[34m[6]#011validation_0-mlogloss:1.09806#011validation_1-mlogloss:1.09804\u001b[0m\n",
      "\u001b[34m[7]#011validation_0-mlogloss:1.09798#011validation_1-mlogloss:1.09796\u001b[0m\n",
      "\u001b[34m[8]#011validation_0-mlogloss:1.09790#011validation_1-mlogloss:1.09788\u001b[0m\n",
      "\u001b[34m[9]#011validation_0-mlogloss:1.09782#011validation_1-mlogloss:1.09780\u001b[0m\n",
      "\u001b[34m[10]#011validation_0-mlogloss:1.09774#011validation_1-mlogloss:1.09772\u001b[0m\n",
      "\u001b[34m[11]#011validation_0-mlogloss:1.09767#011validation_1-mlogloss:1.09763\u001b[0m\n",
      "\u001b[34m[12]#011validation_0-mlogloss:1.09759#011validation_1-mlogloss:1.09755\u001b[0m\n",
      "\u001b[34m[13]#011validation_0-mlogloss:1.09751#011validation_1-mlogloss:1.09747\u001b[0m\n",
      "\u001b[34m[14]#011validation_0-mlogloss:1.09743#011validation_1-mlogloss:1.09739\u001b[0m\n",
      "\u001b[34m[15]#011validation_0-mlogloss:1.09735#011validation_1-mlogloss:1.09731\u001b[0m\n",
      "\u001b[34m[16]#011validation_0-mlogloss:1.09727#011validation_1-mlogloss:1.09723\u001b[0m\n",
      "\u001b[34m[17]#011validation_0-mlogloss:1.09719#011validation_1-mlogloss:1.09715\u001b[0m\n",
      "\u001b[34m[18]#011validation_0-mlogloss:1.09712#011validation_1-mlogloss:1.09707\u001b[0m\n",
      "\u001b[34m[19]#011validation_0-mlogloss:1.09704#011validation_1-mlogloss:1.09698\u001b[0m\n",
      "\u001b[34m[20]#011validation_0-mlogloss:1.09696#011validation_1-mlogloss:1.09690\u001b[0m\n",
      "\u001b[34m[21]#011validation_0-mlogloss:1.09688#011validation_1-mlogloss:1.09682\u001b[0m\n",
      "\u001b[34m[22]#011validation_0-mlogloss:1.09680#011validation_1-mlogloss:1.09674\u001b[0m\n",
      "\u001b[34m[23]#011validation_0-mlogloss:1.09672#011validation_1-mlogloss:1.09666\u001b[0m\n",
      "\u001b[34m[24]#011validation_0-mlogloss:1.09664#011validation_1-mlogloss:1.09658\u001b[0m\n",
      "\u001b[34m[25]#011validation_0-mlogloss:1.09657#011validation_1-mlogloss:1.09650\u001b[0m\n",
      "\u001b[34m[26]#011validation_0-mlogloss:1.09649#011validation_1-mlogloss:1.09641\u001b[0m\n",
      "\u001b[34m[27]#011validation_0-mlogloss:1.09641#011validation_1-mlogloss:1.09633\u001b[0m\n",
      "\u001b[34m[28]#011validation_0-mlogloss:1.09633#011validation_1-mlogloss:1.09625\u001b[0m\n",
      "\u001b[34m[29]#011validation_0-mlogloss:1.09625#011validation_1-mlogloss:1.09617\u001b[0m\n",
      "\u001b[34m[30]#011validation_0-mlogloss:1.09617#011validation_1-mlogloss:1.09609\u001b[0m\n",
      "\u001b[34m[31]#011validation_0-mlogloss:1.09609#011validation_1-mlogloss:1.09601\u001b[0m\n",
      "\u001b[34m[32]#011validation_0-mlogloss:1.09601#011validation_1-mlogloss:1.09593\u001b[0m\n",
      "\u001b[34m[33]#011validation_0-mlogloss:1.09594#011validation_1-mlogloss:1.09585\u001b[0m\n",
      "\u001b[34m[34]#011validation_0-mlogloss:1.09586#011validation_1-mlogloss:1.09577\u001b[0m\n",
      "\u001b[34m[35]#011validation_0-mlogloss:1.09578#011validation_1-mlogloss:1.09569\u001b[0m\n",
      "\u001b[34m[36]#011validation_0-mlogloss:1.09570#011validation_1-mlogloss:1.09560\u001b[0m\n",
      "\u001b[34m[37]#011validation_0-mlogloss:1.09562#011validation_1-mlogloss:1.09552\u001b[0m\n",
      "\u001b[34m[38]#011validation_0-mlogloss:1.09554#011validation_1-mlogloss:1.09544\u001b[0m\n",
      "\u001b[34m[39]#011validation_0-mlogloss:1.09547#011validation_1-mlogloss:1.09536\u001b[0m\n",
      "\u001b[34m[40]#011validation_0-mlogloss:1.09539#011validation_1-mlogloss:1.09528\u001b[0m\n",
      "\u001b[34m[41]#011validation_0-mlogloss:1.09531#011validation_1-mlogloss:1.09520\u001b[0m\n",
      "\u001b[34m[42]#011validation_0-mlogloss:1.09523#011validation_1-mlogloss:1.09512\u001b[0m\n",
      "\u001b[34m[43]#011validation_0-mlogloss:1.09515#011validation_1-mlogloss:1.09504\u001b[0m\n",
      "\u001b[34m[44]#011validation_0-mlogloss:1.09507#011validation_1-mlogloss:1.09495\u001b[0m\n",
      "\u001b[34m[45]#011validation_0-mlogloss:1.09499#011validation_1-mlogloss:1.09487\u001b[0m\n",
      "\u001b[34m[46]#011validation_0-mlogloss:1.09492#011validation_1-mlogloss:1.09479\u001b[0m\n",
      "\u001b[34m[47]#011validation_0-mlogloss:1.09484#011validation_1-mlogloss:1.09471\u001b[0m\n",
      "\u001b[34m[48]#011validation_0-mlogloss:1.09476#011validation_1-mlogloss:1.09463\u001b[0m\n",
      "\u001b[34m[49]#011validation_0-mlogloss:1.09468#011validation_1-mlogloss:1.09455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.86      1.00      0.92         6\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.95      0.97      0.96        30\u001b[0m\n",
      "\u001b[34mweighted avg       0.97      0.97      0.97        30\n",
      "\u001b[0m\n",
      "\u001b[34m[[11  1  0]\n",
      " [ 0  6  0]\n",
      " [ 0  0 12]]\u001b[0m\n",
      "\u001b[34m0.9714285714285714\u001b[0m\n",
      "\u001b[34msave booster\u001b[0m\n",
      "Training seconds: 35\n",
      "Billable seconds: 35\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "# log group prefix /aws/sagemaker/TrainingJobs\n",
    "\n",
    "hyperparameters = {\n",
    "    \"hp1\": \"value1\",\n",
    "    \"hp2\": 300,\n",
    "    \"hp3\": 0.001}\n",
    "\n",
    "metric_definitions=[\n",
    "   {'Name': 'custom_train:loss', 'Regex': 'validation_0-mlogloss:=(.*?) '},\n",
    "   {'Name': 'custom_validation:loss', 'Regex': 'validation_1-mlogloss=(.*?) '}\n",
    "]\n",
    "    \n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"../docker/code\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    #instance_type=\"local\",\n",
    "    framework_version=\"1.0-1\",\n",
    "    #metric_definitions=metric_definitions # built in algo does not support metric definition\n",
    ")\n",
    "\n",
    "train_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.inputs.TrainingInput('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "xgb_estimator.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy from estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "serializer = CSVSerializer()\n",
    "serializer.CONTENT_TYPE = \"text/csv\"\n",
    "\n",
    "predictor = xgb_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.medium\",\n",
    "    serializer=serializer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"file.csv\") as f:\n",
    "    payload = f.read()\n",
    "\n",
    "predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Get Predictor </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0.335604', '0.32953852', '0.3348575'],\n",
       " ['0.3353785', '0.329989', '0.3346325']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.xgboost.model import XGBoostPredictor\n",
    "import numpy as np\n",
    "\n",
    "endpoint_name = \"sagemaker-xgboost-2020-08-11-06-52-30-545\"\n",
    "payload = \"1,2,3,4,5\\n2,3,4,5,6\"\n",
    "\n",
    "xgb_predictor = XGBoostPredictor(endpoint_name)\n",
    "\n",
    "xgb_predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Low level API - inference </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3306555449962616, 0.33722642064094543, 0.33211803436279297]]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "runtime_client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "\n",
    "payload = \"1,2,3,4,5\"\n",
    "endpoint_name = 'sagemaker-xgboost-2020-08-11-06-52-30-545'\n",
    "\n",
    "response = runtime_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType='text/csv',\n",
    "                                   Body=payload)\n",
    "\n",
    "result = response['Body'].read().decode('ascii')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('3.8.6')",
   "metadata": {
    "interpreter": {
     "hash": "185eabfcdf4df50349e20bee16b2a0b255a9875bb276c77f7747bf074186d73c"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}