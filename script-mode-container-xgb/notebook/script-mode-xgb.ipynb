{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Method 1: Custom XGB Container </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to build and use a custom Docker container for training with Amazon SageMaker that leverages on the <strong>Script Mode</strong> execution that is implemented by the sagemaker-containers library. Reference documentation is available at https://github.com/aws/sagemaker-containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining some variables like the current execution role, the ECR repository that we are going to use for pushing the custom Docker container and a default Amazon S3 bucket to be used by Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342474125894\n",
      "ap-southeast-1\n",
      "arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\n",
      "sagemaker-ap-southeast-1-342474125894\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "ecr_namespace = 'sagemaker-training-containers/'\n",
    "prefix = 'script-mode-container-xgb'\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = \"arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\"\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Build and push the container</h3>\n",
    "We are now ready to build this container and push it to Amazon ECR. This task is executed using a shell script stored in the ../script/ folder. Let's take a look at this script and then execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  13.31kB\n",
      "Step 1/16 : FROM ubuntu:16.04\n",
      " ---> 13c9f1285025\n",
      "Step 2/16 : LABEL maintainer=\"Giuseppe A. Porcelli\"\n",
      " ---> Using cache\n",
      " ---> 6bbf3d07c68d\n",
      "Step 3/16 : ARG PYTHON=python3\n",
      " ---> Using cache\n",
      " ---> 8e254b9ef0a0\n",
      "Step 4/16 : ARG PYTHON_PIP=python3-pip\n",
      " ---> Using cache\n",
      " ---> 84c928b11bb3\n",
      "Step 5/16 : ARG PIP=pip3\n",
      " ---> Using cache\n",
      " ---> 65e780b1f9d7\n",
      "Step 6/16 : ARG PYTHON_VERSION=3.6.6\n",
      " ---> Using cache\n",
      " ---> 03bab72f170e\n",
      "Step 7/16 : RUN apt-get update && apt-get install -y --no-install-recommends software-properties-common &&     add-apt-repository ppa:deadsnakes/ppa -y &&     apt-get update && apt-get install -y --no-install-recommends     build-essential     ca-certificates     curl     wget     git     libopencv-dev     openssh-client     openssh-server     vim     zlib1g-dev &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> e29c159657d9\n",
      "Step 8/16 : RUN wget https://www.python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tgz &&     tar -xvf Python-$PYTHON_VERSION.tgz && cd Python-$PYTHON_VERSION &&     ./configure && make && make install &&     apt-get update && apt-get install -y --no-install-recommends libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev &&     make && make install && rm -rf ../Python-$PYTHON_VERSION* &&     ln -s /usr/local/bin/pip3 /usr/bin/pip\n",
      " ---> Using cache\n",
      " ---> 5f344151a182\n",
      "Step 9/16 : RUN ${PIP} --no-cache-dir install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> eda3fb14df62\n",
      "Step 10/16 : RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
      " ---> Using cache\n",
      " ---> 36e695fcdc04\n",
      "Step 11/16 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 47c0eeca0f80\n",
      "Step 12/16 : RUN ${PIP} install --no-cache --upgrade     numpy==1.14.5     pandas==0.24.1     scikit-learn==0.20.3     requests==2.21.0     scipy==1.2.1     xgboost==1.1.1\n",
      " ---> Using cache\n",
      " ---> 8005d64e71ff\n",
      "Step 13/16 : ENV PYTHONDONTWRITEBYTECODE=1     PYTHONUNBUFFERED=1     LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\"     PYTHONIOENCODING=UTF-8     LANG=C.UTF-8     LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> d49a18978498\n",
      "Step 14/16 : RUN ${PIP} install --no-cache --upgrade     sagemaker-containers\n",
      " ---> Using cache\n",
      " ---> 1d33f1130683\n",
      "Step 15/16 : COPY code/* /opt/ml/code/\n",
      " ---> 3df4af997d3a\n",
      "Step 16/16 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in 5bf41084c428\n",
      "Removing intermediate container 5bf41084c428\n",
      " ---> e00463f1d848\n",
      "Successfully built e00463f1d848\n",
      "Successfully tagged sagemaker-training-containers/script-mode-container-xgb:latest\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "Login Succeeded\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryArn\": \"arn:aws:ecr:ap-southeast-1:342474125894:repository/sagemaker-training-containers/script-mode-container-xgb\",\n",
      "            \"registryId\": \"342474125894\",\n",
      "            \"repositoryName\": \"sagemaker-training-containers/script-mode-container-xgb\",\n",
      "            \"repositoryUri\": \"342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/script-mode-container-xgb\",\n",
      "            \"createdAt\": 1597065421.0,\n",
      "            \"imageTagMutability\": \"MUTABLE\",\n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "The push refers to repository [342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/script-mode-container-xgb]\n",
      "\n",
      "\u001b[1B0728f6bb: Preparing \n",
      "\u001b[1B707974b2: Preparing \n",
      "\u001b[1B2b5574ba: Preparing \n",
      "\u001b[1Bfc276494: Preparing \n",
      "\u001b[1Bb7f4d226: Preparing \n",
      "\u001b[1B136c651b: Preparing \n",
      "\u001b[2B136c651b: Waiting g \n",
      "\u001b[1Bf22d44f3: Preparing \n",
      "\u001b[1B6f329a25: Preparing \n",
      "\u001b[1B7de5faec: Preparing \n",
      "\u001b[11B728f6bb: Pushed lready exists 9kBA\u001b[2K\u001b[11A\u001b[2K\u001b[5A\u001b[2K\u001b[2A\u001b[2K\u001b[11A\u001b[2Klatest: digest: sha256:267c7d9b06f378aa6dfef24a0bdd78b53ba882322487669548edea0a04507638 size: 2626\n"
     ]
    }
   ],
   "source": [
    "! ../scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training with Amazon SageMaker</h3>\n",
    "\n",
    "Once we have correctly pushed our container to Amazon ECR, we are ready to start training with Amazon SageMaker, which requires the ECR path to the Docker container used for training as parameter for starting a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342474125894.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-training-containers/script-mode-container-xgb:latest\n"
     ]
    }
   ],
   "source": [
    "container_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, ecr_repository_name)\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can realize that the training code has been implemented as a standard Python script, that will be invoked by the sagemaker-containers library passing hyperparameters as arguments. This way of invoking training script is indeed called <strong>Script Mode</strong> for Amazon SageMaker containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare Data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we upload some dummy data to Amazon S3, in order to define our S3-based training channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (100, 5), y:(100,)\n",
      "train_df: (70, 6), test_df:(30, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=100, n_features=5, n_redundant=0, n_informative=2, n_clusters_per_class=1, n_classes=3\n",
    ")\n",
    "print(f\"X: {X.shape}, y:{y.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "train_df = pd.concat([y_train, X_train], axis=1)\n",
    "train_df.columns = range(train_df.shape[1])\n",
    "test_df = pd.concat([y_test, X_test], axis=1)\n",
    "test_df.columns = range(test_df.shape[1])\n",
    "\n",
    "print(f\"train_df: {train_df.shape}, test_df:{test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-342474125894/script-mode-container-xgb/train/train.csv\n",
      "s3://sagemaker-ap-southeast-1-342474125894/script-mode-container-xgb/val/test.csv\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"../test_data/train/train.csv\"\n",
    "test_filename = \"../test_data/val/test.csv\"\n",
    "train_df.to_csv(train_filename, header=True, index=False)\n",
    "test_df.to_csv(test_filename, header=True, index=False)\n",
    "\n",
    "train_uri = sagemaker_session.upload_data(train_filename, bucket, prefix + '/train')\n",
    "test_uri = sagemaker_session.upload_data(test_filename, bucket, prefix + '/val')\n",
    "print(train_uri)\n",
    "print(test_uri)\n",
    "#! rm $train_filename $test_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can execute the training job by calling the fit() method of the generic Estimator object defined in the Amazon SageMaker Python SDK (https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/estimator.py). This corresponds to calling the CreateTrainingJob() API (https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTrainingJob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 16:33:05 Starting - Starting the training job...\n",
      "2020-08-10 16:33:07 Starting - Launching requested ML instances......\n",
      "2020-08-10 16:34:16 Starting - Preparing the instances for training...\n",
      "2020-08-10 16:34:54 Downloading - Downloading input data\n",
      "2020-08-10 16:34:54 Training - Downloading the training image.....\u001b[34m2020-08-10 16:35:41,116 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-10 16:35:47,351 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-10 16:35:47,364 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-10 16:35:47,375 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hp1\": \"value1\",\n",
      "        \"hp3\": 0.001,\n",
      "        \"hp2\": 300\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"script-mode-container-xgb-2020-08-10-16-33-10-408\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"hp1\":\"value1\",\"hp2\":300,\"hp3\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"script-mode-container-xgb-2020-08-10-16-33-10-408\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--hp1\",\"value1\",\"--hp2\",\"300\",\"--hp3\",\"0.001\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_HP1=value1\u001b[0m\n",
      "\u001b[34mSM_HP_HP3=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_HP2=300\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 train.py --hp1 value1 --hp2 300 --hp3 0.001\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNamespace(hp1='value1', hp2=300, hp3=0.001, model_dir='/opt/ml/model', train='/opt/ml/input/data/train', validation='/opt/ml/input/data/validation')\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in train channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/train/train.csv\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in validation channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/validation/test.csv\u001b[0m\n",
      "\u001b[34mX_train: (70, 5), y_train:(70,)\u001b[0m\n",
      "\u001b[34mX_test: (30, 5), y_test:(30,)\u001b[0m\n",
      "\u001b[34mXGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=None,\n",
      "       importance_type='gain', interaction_constraints=None,\n",
      "       learning_rate=0.0001, max_delta_step=0, max_depth=5,\n",
      "       min_child_weight=5, missing=None, monotone_constraints=None,\n",
      "       n_estimators=100, n_jobs=3, nthread=None, num_parallel_tree=None,\n",
      "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=None, subsample=1, tree_method=None,\n",
      "       validate_parameters=None, verbosity=1)\u001b[0m\n",
      "\u001b[34m[0]#011validation_0-mlogloss:1.09854#011validation_1-mlogloss:1.09855\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation_1-mlogloss hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[1]#011validation_0-mlogloss:1.09846#011validation_1-mlogloss:1.09849\u001b[0m\n",
      "\u001b[34m[2]#011validation_0-mlogloss:1.09838#011validation_1-mlogloss:1.09844\u001b[0m\n",
      "\u001b[34m[3]#011validation_0-mlogloss:1.09831#011validation_1-mlogloss:1.09838\u001b[0m\n",
      "\u001b[34m[4]#011validation_0-mlogloss:1.09823#011validation_1-mlogloss:1.09832\u001b[0m\n",
      "\u001b[34m[5]#011validation_0-mlogloss:1.09815#011validation_1-mlogloss:1.09826\u001b[0m\n",
      "\u001b[34m[6]#011validation_0-mlogloss:1.09808#011validation_1-mlogloss:1.09820\u001b[0m\n",
      "\u001b[34m[7]#011validation_0-mlogloss:1.09800#011validation_1-mlogloss:1.09815\u001b[0m\n",
      "\u001b[34m[8]#011validation_0-mlogloss:1.09793#011validation_1-mlogloss:1.09809\u001b[0m\n",
      "\u001b[34m[9]#011validation_0-mlogloss:1.09785#011validation_1-mlogloss:1.09803\u001b[0m\n",
      "\u001b[34m[10]#011validation_0-mlogloss:1.09777#011validation_1-mlogloss:1.09797\u001b[0m\n",
      "\u001b[34m[11]#011validation_0-mlogloss:1.09770#011validation_1-mlogloss:1.09791\u001b[0m\n",
      "\u001b[34m[12]#011validation_0-mlogloss:1.09762#011validation_1-mlogloss:1.09786\u001b[0m\n",
      "\u001b[34m[13]#011validation_0-mlogloss:1.09754#011validation_1-mlogloss:1.09780\u001b[0m\n",
      "\u001b[34m[14]#011validation_0-mlogloss:1.09747#011validation_1-mlogloss:1.09774\u001b[0m\n",
      "\u001b[34m[15]#011validation_0-mlogloss:1.09739#011validation_1-mlogloss:1.09768\u001b[0m\n",
      "\u001b[34m[16]#011validation_0-mlogloss:1.09732#011validation_1-mlogloss:1.09762\u001b[0m\n",
      "\u001b[34m[17]#011validation_0-mlogloss:1.09724#011validation_1-mlogloss:1.09756\u001b[0m\n",
      "\u001b[34m[18]#011validation_0-mlogloss:1.09716#011validation_1-mlogloss:1.09751\u001b[0m\n",
      "\u001b[34m[19]#011validation_0-mlogloss:1.09709#011validation_1-mlogloss:1.09745\u001b[0m\n",
      "\u001b[34m[20]#011validation_0-mlogloss:1.09701#011validation_1-mlogloss:1.09739\u001b[0m\n",
      "\u001b[34m[21]#011validation_0-mlogloss:1.09693#011validation_1-mlogloss:1.09733\u001b[0m\n",
      "\u001b[34m[22]#011validation_0-mlogloss:1.09686#011validation_1-mlogloss:1.09728\u001b[0m\n",
      "\u001b[34m[23]#011validation_0-mlogloss:1.09678#011validation_1-mlogloss:1.09722\u001b[0m\n",
      "\u001b[34m[24]#011validation_0-mlogloss:1.09671#011validation_1-mlogloss:1.09716\u001b[0m\n",
      "\u001b[34m[25]#011validation_0-mlogloss:1.09663#011validation_1-mlogloss:1.09710\u001b[0m\n",
      "\u001b[34m[26]#011validation_0-mlogloss:1.09655#011validation_1-mlogloss:1.09704\u001b[0m\n",
      "\u001b[34m[27]#011validation_0-mlogloss:1.09648#011validation_1-mlogloss:1.09699\u001b[0m\n",
      "\u001b[34m[28]#011validation_0-mlogloss:1.09640#011validation_1-mlogloss:1.09693\u001b[0m\n",
      "\u001b[34m[29]#011validation_0-mlogloss:1.09633#011validation_1-mlogloss:1.09687\u001b[0m\n",
      "\u001b[34m[30]#011validation_0-mlogloss:1.09625#011validation_1-mlogloss:1.09681\u001b[0m\n",
      "\u001b[34m[31]#011validation_0-mlogloss:1.09617#011validation_1-mlogloss:1.09675\u001b[0m\n",
      "\u001b[34m[32]#011validation_0-mlogloss:1.09610#011validation_1-mlogloss:1.09669\u001b[0m\n",
      "\u001b[34m[33]#011validation_0-mlogloss:1.09602#011validation_1-mlogloss:1.09664\u001b[0m\n",
      "\u001b[34m[34]#011validation_0-mlogloss:1.09595#011validation_1-mlogloss:1.09658\u001b[0m\n",
      "\u001b[34m[35]#011validation_0-mlogloss:1.09587#011validation_1-mlogloss:1.09652\u001b[0m\n",
      "\u001b[34m[36]#011validation_0-mlogloss:1.09580#011validation_1-mlogloss:1.09647\u001b[0m\n",
      "\u001b[34m[37]#011validation_0-mlogloss:1.09572#011validation_1-mlogloss:1.09641\u001b[0m\n",
      "\u001b[34m[38]#011validation_0-mlogloss:1.09564#011validation_1-mlogloss:1.09635\u001b[0m\n",
      "\u001b[34m[39]#011validation_0-mlogloss:1.09557#011validation_1-mlogloss:1.09629\u001b[0m\n",
      "\u001b[34m[40]#011validation_0-mlogloss:1.09549#011validation_1-mlogloss:1.09623\u001b[0m\n",
      "\u001b[34m[41]#011validation_0-mlogloss:1.09542#011validation_1-mlogloss:1.09617\u001b[0m\n",
      "\u001b[34m[42]#011validation_0-mlogloss:1.09534#011validation_1-mlogloss:1.09612\u001b[0m\n",
      "\u001b[34m[43]#011validation_0-mlogloss:1.09526#011validation_1-mlogloss:1.09606\u001b[0m\n",
      "\u001b[34m[44]#011validation_0-mlogloss:1.09519#011validation_1-mlogloss:1.09600\u001b[0m\n",
      "\u001b[34m[45]#011validation_0-mlogloss:1.09511#011validation_1-mlogloss:1.09594\u001b[0m\n",
      "\u001b[34m[46]#011validation_0-mlogloss:1.09504#011validation_1-mlogloss:1.09588\u001b[0m\n",
      "\u001b[34m[47]#011validation_0-mlogloss:1.09496#011validation_1-mlogloss:1.09583\u001b[0m\n",
      "\u001b[34m[48]#011validation_0-mlogloss:1.09489#011validation_1-mlogloss:1.09577\u001b[0m\n",
      "\u001b[34m[49]#011validation_0-mlogloss:1.09481#011validation_1-mlogloss:1.09571\u001b[0m\n",
      "\u001b[34m[50]#011validation_0-mlogloss:1.09473#011validation_1-mlogloss:1.09566\u001b[0m\n",
      "\u001b[34m[51]#011validation_0-mlogloss:1.09466#011validation_1-mlogloss:1.09560\u001b[0m\n",
      "\u001b[34m[52]#011validation_0-mlogloss:1.09458#011validation_1-mlogloss:1.09554\u001b[0m\n",
      "\u001b[34m[53]#011validation_0-mlogloss:1.09451#011validation_1-mlogloss:1.09548\u001b[0m\n",
      "\u001b[34m[54]#011validation_0-mlogloss:1.09443#011validation_1-mlogloss:1.09542\u001b[0m\n",
      "\u001b[34m[55]#011validation_0-mlogloss:1.09435#011validation_1-mlogloss:1.09537\u001b[0m\n",
      "\u001b[34m[56]#011validation_0-mlogloss:1.09428#011validation_1-mlogloss:1.09531\u001b[0m\n",
      "\u001b[34m[57]#011validation_0-mlogloss:1.09420#011validation_1-mlogloss:1.09525\u001b[0m\n",
      "\u001b[34m[58]#011validation_0-mlogloss:1.09413#011validation_1-mlogloss:1.09519\u001b[0m\n",
      "\u001b[34m[59]#011validation_0-mlogloss:1.09405#011validation_1-mlogloss:1.09513\u001b[0m\n",
      "\u001b[34m[60]#011validation_0-mlogloss:1.09398#011validation_1-mlogloss:1.09508\u001b[0m\n",
      "\u001b[34m[61]#011validation_0-mlogloss:1.09390#011validation_1-mlogloss:1.09502\u001b[0m\n",
      "\u001b[34m[62]#011validation_0-mlogloss:1.09382#011validation_1-mlogloss:1.09496\u001b[0m\n",
      "\u001b[34m[63]#011validation_0-mlogloss:1.09375#011validation_1-mlogloss:1.09490\u001b[0m\n",
      "\u001b[34m[64]#011validation_0-mlogloss:1.09367#011validation_1-mlogloss:1.09485\u001b[0m\n",
      "\u001b[34m[65]#011validation_0-mlogloss:1.09360#011validation_1-mlogloss:1.09479\u001b[0m\n",
      "\u001b[34m[66]#011validation_0-mlogloss:1.09352#011validation_1-mlogloss:1.09473\u001b[0m\n",
      "\u001b[34m[67]#011validation_0-mlogloss:1.09345#011validation_1-mlogloss:1.09467\u001b[0m\n",
      "\u001b[34m[68]#011validation_0-mlogloss:1.09337#011validation_1-mlogloss:1.09461\u001b[0m\n",
      "\u001b[34m[69]#011validation_0-mlogloss:1.09329#011validation_1-mlogloss:1.09456\u001b[0m\n",
      "\u001b[34m[70]#011validation_0-mlogloss:1.09322#011validation_1-mlogloss:1.09450\u001b[0m\n",
      "\u001b[34m[71]#011validation_0-mlogloss:1.09314#011validation_1-mlogloss:1.09444\u001b[0m\n",
      "\u001b[34m[72]#011validation_0-mlogloss:1.09307#011validation_1-mlogloss:1.09439\u001b[0m\n",
      "\u001b[34m[73]#011validation_0-mlogloss:1.09299#011validation_1-mlogloss:1.09433\u001b[0m\n",
      "\u001b[34m[74]#011validation_0-mlogloss:1.09292#011validation_1-mlogloss:1.09427\u001b[0m\n",
      "\u001b[34m[75]#011validation_0-mlogloss:1.09284#011validation_1-mlogloss:1.09421\u001b[0m\n",
      "\u001b[34m[76]#011validation_0-mlogloss:1.09277#011validation_1-mlogloss:1.09415\u001b[0m\n",
      "\u001b[34m[77]#011validation_0-mlogloss:1.09269#011validation_1-mlogloss:1.09410\u001b[0m\n",
      "\u001b[34m[78]#011validation_0-mlogloss:1.09261#011validation_1-mlogloss:1.09404\u001b[0m\n",
      "\u001b[34m[79]#011validation_0-mlogloss:1.09254#011validation_1-mlogloss:1.09398\u001b[0m\n",
      "\u001b[34m[80]#011validation_0-mlogloss:1.09247#011validation_1-mlogloss:1.09393\u001b[0m\n",
      "\u001b[34m[81]#011validation_0-mlogloss:1.09239#011validation_1-mlogloss:1.09387\u001b[0m\n",
      "\u001b[34m[82]#011validation_0-mlogloss:1.09231#011validation_1-mlogloss:1.09381\u001b[0m\n",
      "\u001b[34m[83]#011validation_0-mlogloss:1.09224#011validation_1-mlogloss:1.09375\u001b[0m\n",
      "\u001b[34m[84]#011validation_0-mlogloss:1.09216#011validation_1-mlogloss:1.09369\u001b[0m\n",
      "\u001b[34m[85]#011validation_0-mlogloss:1.09209#011validation_1-mlogloss:1.09364\u001b[0m\n",
      "\u001b[34m[86]#011validation_0-mlogloss:1.09201#011validation_1-mlogloss:1.09358\u001b[0m\n",
      "\u001b[34m[87]#011validation_0-mlogloss:1.09194#011validation_1-mlogloss:1.09352\u001b[0m\n",
      "\u001b[34m[88]#011validation_0-mlogloss:1.09186#011validation_1-mlogloss:1.09346\u001b[0m\n",
      "\u001b[34m[89]#011validation_0-mlogloss:1.09179#011validation_1-mlogloss:1.09341\u001b[0m\n",
      "\u001b[34m[90]#011validation_0-mlogloss:1.09171#011validation_1-mlogloss:1.09335\u001b[0m\n",
      "\u001b[34m[91]#011validation_0-mlogloss:1.09163#011validation_1-mlogloss:1.09329\u001b[0m\n",
      "\u001b[34m[92]#011validation_0-mlogloss:1.09156#011validation_1-mlogloss:1.09324\u001b[0m\n",
      "\u001b[34m[93]#011validation_0-mlogloss:1.09148#011validation_1-mlogloss:1.09318\u001b[0m\n",
      "\u001b[34m[94]#011validation_0-mlogloss:1.09141#011validation_1-mlogloss:1.09312\u001b[0m\n",
      "\u001b[34m[95]#011validation_0-mlogloss:1.09133#011validation_1-mlogloss:1.09306\u001b[0m\n",
      "\u001b[34m[96]#011validation_0-mlogloss:1.09126#011validation_1-mlogloss:1.09301\u001b[0m\n",
      "\u001b[34m[97]#011validation_0-mlogloss:1.09118#011validation_1-mlogloss:1.09295\u001b[0m\n",
      "\u001b[34m[98]#011validation_0-mlogloss:1.09111#011validation_1-mlogloss:1.09289\u001b[0m\n",
      "\u001b[34m[99]#011validation_0-mlogloss:1.09103#011validation_1-mlogloss:1.09283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.81        13\n",
      "           1       0.70      0.88      0.78         8\n",
      "           2       0.67      0.44      0.53         9\n",
      "\n",
      "   micro avg       0.73      0.73      0.73        30\n",
      "   macro avg       0.72      0.72      0.71        30\u001b[0m\n",
      "\u001b[34mweighted avg       0.73      0.73      0.72        30\n",
      "\u001b[0m\n",
      "\u001b[34m[[11  1  1]\n",
      " [ 0  7  1]\n",
      " [ 3  2  4]]\u001b[0m\n",
      "\u001b[34m0.7271428571428571\u001b[0m\n",
      "\u001b[34msave booster\u001b[0m\n",
      "\u001b[34m2020-08-10 16:35:48,582 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-08-10 16:35:56 Uploading - Uploading generated training model\n",
      "2020-08-10 16:35:56 Completed - Training job completed\n",
      "Training seconds: 67\n",
      "Billable seconds: 67\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "\n",
    "# JSON encode hyperparameters to avoid showing some info messages raised by the sagemaker-containers library.\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters({\n",
    "    \"hp1\": \"value1\",\n",
    "    \"hp2\": 300,\n",
    "    \"hp3\": 0.001})\n",
    "\n",
    "est = sagemaker.estimator.Estimator(container_image_uri,\n",
    "                                    role,\n",
    "                                    train_instance_count=1, \n",
    "                                    #train_instance_type='local', # we use local mode\n",
    "                                    train_instance_type='ml.m5.xlarge',\n",
    "                                    base_job_name=prefix,\n",
    "                                    hyperparameters=hyperparameters)\n",
    "\n",
    "train_config = sagemaker.session.s3_input('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.session.s3_input('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "#print(train_config.config, val_config)\n",
    "est.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>check model artifact</h3>\n",
    "    \n",
    "make sure it is Booster type,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-342474125894/script-mode-container-xgb-2020-08-10-16-33-10-408/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "artifact_path = est.latest_training_job.describe()['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(artifact_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-southeast-1-342474125894/script-mode-container-xgb-2020-08-10-16-33-10-408/output/model.tar.gz to ./model.tar.gz\n",
      "x model.pth\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp s3://sagemaker-ap-southeast-1-342474125894/script-mode-container-xgb-2020-08-10-16-33-10-408/output/model.tar.gz .\n",
    "! tar -xvf model.tar.gz\n",
    "! rm model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x11db6d1d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('model.pth', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Method 2: Prebuilt container </h1>\n",
    "\n",
    "Prebuilt container has both sagemaker-container/sagemaker-inference install in a single image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-10 17:40:58 Starting - Starting the training job...\n",
      "2020-08-10 17:41:01 Starting - Launching requested ML instances......\n",
      "2020-08-10 17:42:28 Starting - Preparing the instances for training...\n",
      "2020-08-10 17:42:59 Downloading - Downloading input data...\n",
      "2020-08-10 17:43:17 Training - Downloading the training image..\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Invoking user training script.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating setup.cfg\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\n",
      "  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=8600 sha256=332aa74f90b2cd66aa551c15e162b8319837108cfe6b6984b96a1f283a7087ac\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-xntduyob/wheels/95/c1/85/65aaf48b35aba88c6e896d2fd04a4b69f1cee0d81ea32993ca\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-xgboost-2020-08-10-17-41-03-430\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-1-342474125894/sagemaker-xgboost-2020-08-10-17-41-03-430/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-southeast-1-342474125894/sagemaker-xgboost-2020-08-10-17-41-03-430/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2020-08-10-17-41-03-430\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-1-342474125894/sagemaker-xgboost-2020-08-10-17-41-03-430/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python3.6/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python36.zip:/miniconda3/lib/python3.6:/miniconda3/lib/python3.6/lib-dynload:/miniconda3/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m train\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNamespace(hp1=None, hp2=50, hp3=0.1, model_dir='/opt/ml/model', train='/opt/ml/input/data/train', validation='/opt/ml/input/data/validation')\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in train channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/train/train.csv\n",
      "\u001b[0m\n",
      "\u001b[34mList of files in validation channel: \u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/validation/test.csv\u001b[0m\n",
      "\u001b[34mX_train: (70, 5), y_train:(70,)\u001b[0m\n",
      "\u001b[34mX_test: (30, 5), y_test:(30,)\u001b[0m\n",
      "\u001b[34mXGBClassifier(learning_rate=0.0001, max_depth=5, min_child_weight=5, n_jobs=7,\n",
      "              objective='multi:softprob')\u001b[0m\n",
      "\u001b[34m[0]#011validation_0-mlogloss:1.09854#011validation_1-mlogloss:1.09855\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation_1-mlogloss hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[1]#011validation_0-mlogloss:1.09846#011validation_1-mlogloss:1.09849\u001b[0m\n",
      "\u001b[34m[2]#011validation_0-mlogloss:1.09838#011validation_1-mlogloss:1.09844\u001b[0m\n",
      "\u001b[34m[3]#011validation_0-mlogloss:1.09831#011validation_1-mlogloss:1.09838\u001b[0m\n",
      "\u001b[34m[4]#011validation_0-mlogloss:1.09823#011validation_1-mlogloss:1.09832\u001b[0m\n",
      "\u001b[34m[5]#011validation_0-mlogloss:1.09815#011validation_1-mlogloss:1.09826\u001b[0m\n",
      "\u001b[34m[6]#011validation_0-mlogloss:1.09808#011validation_1-mlogloss:1.0982\u001b[0m\n",
      "\u001b[34m[7]#011validation_0-mlogloss:1.098#011validation_1-mlogloss:1.09815\u001b[0m\n",
      "\u001b[34m[8]#011validation_0-mlogloss:1.09793#011validation_1-mlogloss:1.09809\u001b[0m\n",
      "\u001b[34m[9]#011validation_0-mlogloss:1.09785#011validation_1-mlogloss:1.09803\u001b[0m\n",
      "\u001b[34m[10]#011validation_0-mlogloss:1.09777#011validation_1-mlogloss:1.09797\u001b[0m\n",
      "\u001b[34m[11]#011validation_0-mlogloss:1.0977#011validation_1-mlogloss:1.09791\u001b[0m\n",
      "\u001b[34m[12]#011validation_0-mlogloss:1.09762#011validation_1-mlogloss:1.09786\u001b[0m\n",
      "\u001b[34m[13]#011validation_0-mlogloss:1.09754#011validation_1-mlogloss:1.0978\u001b[0m\n",
      "\u001b[34m[14]#011validation_0-mlogloss:1.09747#011validation_1-mlogloss:1.09774\u001b[0m\n",
      "\u001b[34m[15]#011validation_0-mlogloss:1.09739#011validation_1-mlogloss:1.09768\u001b[0m\n",
      "\u001b[34m[16]#011validation_0-mlogloss:1.09732#011validation_1-mlogloss:1.09762\u001b[0m\n",
      "\u001b[34m[17]#011validation_0-mlogloss:1.09724#011validation_1-mlogloss:1.09756\u001b[0m\n",
      "\u001b[34m[18]#011validation_0-mlogloss:1.09716#011validation_1-mlogloss:1.09751\u001b[0m\n",
      "\u001b[34m[19]#011validation_0-mlogloss:1.09709#011validation_1-mlogloss:1.09745\u001b[0m\n",
      "\u001b[34m[20]#011validation_0-mlogloss:1.09701#011validation_1-mlogloss:1.09739\u001b[0m\n",
      "\u001b[34m[21]#011validation_0-mlogloss:1.09693#011validation_1-mlogloss:1.09733\u001b[0m\n",
      "\u001b[34m[22]#011validation_0-mlogloss:1.09686#011validation_1-mlogloss:1.09728\u001b[0m\n",
      "\u001b[34m[23]#011validation_0-mlogloss:1.09678#011validation_1-mlogloss:1.09722\u001b[0m\n",
      "\u001b[34m[24]#011validation_0-mlogloss:1.09671#011validation_1-mlogloss:1.09716\u001b[0m\n",
      "\u001b[34m[25]#011validation_0-mlogloss:1.09663#011validation_1-mlogloss:1.0971\u001b[0m\n",
      "\u001b[34m[26]#011validation_0-mlogloss:1.09655#011validation_1-mlogloss:1.09704\u001b[0m\n",
      "\u001b[34m[27]#011validation_0-mlogloss:1.09648#011validation_1-mlogloss:1.09699\u001b[0m\n",
      "\u001b[34m[28]#011validation_0-mlogloss:1.0964#011validation_1-mlogloss:1.09693\u001b[0m\n",
      "\u001b[34m[29]#011validation_0-mlogloss:1.09633#011validation_1-mlogloss:1.09687\u001b[0m\n",
      "\u001b[34m[30]#011validation_0-mlogloss:1.09625#011validation_1-mlogloss:1.09681\u001b[0m\n",
      "\u001b[34m[31]#011validation_0-mlogloss:1.09617#011validation_1-mlogloss:1.09675\u001b[0m\n",
      "\u001b[34m[32]#011validation_0-mlogloss:1.0961#011validation_1-mlogloss:1.09669\u001b[0m\n",
      "\u001b[34m[33]#011validation_0-mlogloss:1.09602#011validation_1-mlogloss:1.09664\u001b[0m\n",
      "\u001b[34m[34]#011validation_0-mlogloss:1.09595#011validation_1-mlogloss:1.09658\u001b[0m\n",
      "\u001b[34m[35]#011validation_0-mlogloss:1.09587#011validation_1-mlogloss:1.09652\u001b[0m\n",
      "\u001b[34m[36]#011validation_0-mlogloss:1.0958#011validation_1-mlogloss:1.09646\u001b[0m\n",
      "\u001b[34m[37]#011validation_0-mlogloss:1.09572#011validation_1-mlogloss:1.09641\u001b[0m\n",
      "\u001b[34m[38]#011validation_0-mlogloss:1.09564#011validation_1-mlogloss:1.09635\u001b[0m\n",
      "\u001b[34m[39]#011validation_0-mlogloss:1.09557#011validation_1-mlogloss:1.09629\u001b[0m\n",
      "\u001b[34m[40]#011validation_0-mlogloss:1.09549#011validation_1-mlogloss:1.09623\u001b[0m\n",
      "\u001b[34m[41]#011validation_0-mlogloss:1.09542#011validation_1-mlogloss:1.09617\u001b[0m\n",
      "\u001b[34m[42]#011validation_0-mlogloss:1.09534#011validation_1-mlogloss:1.09612\u001b[0m\n",
      "\u001b[34m[43]#011validation_0-mlogloss:1.09526#011validation_1-mlogloss:1.09606\u001b[0m\n",
      "\u001b[34m[44]#011validation_0-mlogloss:1.09519#011validation_1-mlogloss:1.096\u001b[0m\n",
      "\u001b[34m[45]#011validation_0-mlogloss:1.09511#011validation_1-mlogloss:1.09594\u001b[0m\n",
      "\u001b[34m[46]#011validation_0-mlogloss:1.09504#011validation_1-mlogloss:1.09588\u001b[0m\n",
      "\u001b[34m[47]#011validation_0-mlogloss:1.09496#011validation_1-mlogloss:1.09583\u001b[0m\n",
      "\u001b[34m[48]#011validation_0-mlogloss:1.09489#011validation_1-mlogloss:1.09577\u001b[0m\n",
      "\u001b[34m[49]#011validation_0-mlogloss:1.09481#011validation_1-mlogloss:1.09571\u001b[0m\n",
      "\u001b[34m[50]#011validation_0-mlogloss:1.09473#011validation_1-mlogloss:1.09566\u001b[0m\n",
      "\u001b[34m[51]#011validation_0-mlogloss:1.09466#011validation_1-mlogloss:1.0956\u001b[0m\n",
      "\u001b[34m[52]#011validation_0-mlogloss:1.09458#011validation_1-mlogloss:1.09554\u001b[0m\n",
      "\u001b[34m[53]#011validation_0-mlogloss:1.09451#011validation_1-mlogloss:1.09548\u001b[0m\n",
      "\u001b[34m[54]#011validation_0-mlogloss:1.09443#011validation_1-mlogloss:1.09542\u001b[0m\n",
      "\u001b[34m[55]#011validation_0-mlogloss:1.09435#011validation_1-mlogloss:1.09537\u001b[0m\n",
      "\u001b[34m[56]#011validation_0-mlogloss:1.09428#011validation_1-mlogloss:1.09531\u001b[0m\n",
      "\u001b[34m[57]#011validation_0-mlogloss:1.0942#011validation_1-mlogloss:1.09525\u001b[0m\n",
      "\u001b[34m[58]#011validation_0-mlogloss:1.09413#011validation_1-mlogloss:1.09519\u001b[0m\n",
      "\u001b[34m[59]#011validation_0-mlogloss:1.09405#011validation_1-mlogloss:1.09513\u001b[0m\n",
      "\u001b[34m[60]#011validation_0-mlogloss:1.09398#011validation_1-mlogloss:1.09508\u001b[0m\n",
      "\u001b[34m[61]#011validation_0-mlogloss:1.0939#011validation_1-mlogloss:1.09502\u001b[0m\n",
      "\u001b[34m[62]#011validation_0-mlogloss:1.09382#011validation_1-mlogloss:1.09496\u001b[0m\n",
      "\u001b[34m[63]#011validation_0-mlogloss:1.09375#011validation_1-mlogloss:1.0949\u001b[0m\n",
      "\u001b[34m[64]#011validation_0-mlogloss:1.09367#011validation_1-mlogloss:1.09485\u001b[0m\n",
      "\u001b[34m[65]#011validation_0-mlogloss:1.0936#011validation_1-mlogloss:1.09479\u001b[0m\n",
      "\u001b[34m[66]#011validation_0-mlogloss:1.09352#011validation_1-mlogloss:1.09473\u001b[0m\n",
      "\u001b[34m[67]#011validation_0-mlogloss:1.09345#011validation_1-mlogloss:1.09467\u001b[0m\n",
      "\u001b[34m[68]#011validation_0-mlogloss:1.09337#011validation_1-mlogloss:1.09461\u001b[0m\n",
      "\u001b[34m[69]#011validation_0-mlogloss:1.09329#011validation_1-mlogloss:1.09456\u001b[0m\n",
      "\u001b[34m[70]#011validation_0-mlogloss:1.09322#011validation_1-mlogloss:1.0945\u001b[0m\n",
      "\u001b[34m[71]#011validation_0-mlogloss:1.09314#011validation_1-mlogloss:1.09444\u001b[0m\n",
      "\u001b[34m[72]#011validation_0-mlogloss:1.09307#011validation_1-mlogloss:1.09439\u001b[0m\n",
      "\u001b[34m[73]#011validation_0-mlogloss:1.09299#011validation_1-mlogloss:1.09433\u001b[0m\n",
      "\u001b[34m[74]#011validation_0-mlogloss:1.09292#011validation_1-mlogloss:1.09427\u001b[0m\n",
      "\u001b[34m[75]#011validation_0-mlogloss:1.09284#011validation_1-mlogloss:1.09421\u001b[0m\n",
      "\u001b[34m[76]#011validation_0-mlogloss:1.09277#011validation_1-mlogloss:1.09415\u001b[0m\n",
      "\u001b[34m[77]#011validation_0-mlogloss:1.09269#011validation_1-mlogloss:1.0941\u001b[0m\n",
      "\u001b[34m[78]#011validation_0-mlogloss:1.09261#011validation_1-mlogloss:1.09404\u001b[0m\n",
      "\u001b[34m[79]#011validation_0-mlogloss:1.09254#011validation_1-mlogloss:1.09398\u001b[0m\n",
      "\u001b[34m[80]#011validation_0-mlogloss:1.09246#011validation_1-mlogloss:1.09393\u001b[0m\n",
      "\u001b[34m[81]#011validation_0-mlogloss:1.09239#011validation_1-mlogloss:1.09387\u001b[0m\n",
      "\u001b[34m[82]#011validation_0-mlogloss:1.09231#011validation_1-mlogloss:1.09381\u001b[0m\n",
      "\u001b[34m[83]#011validation_0-mlogloss:1.09224#011validation_1-mlogloss:1.09375\u001b[0m\n",
      "\u001b[34m[84]#011validation_0-mlogloss:1.09216#011validation_1-mlogloss:1.09369\u001b[0m\n",
      "\u001b[34m[85]#011validation_0-mlogloss:1.09209#011validation_1-mlogloss:1.09364\u001b[0m\n",
      "\u001b[34m[86]#011validation_0-mlogloss:1.09201#011validation_1-mlogloss:1.09358\u001b[0m\n",
      "\u001b[34m[87]#011validation_0-mlogloss:1.09194#011validation_1-mlogloss:1.09352\u001b[0m\n",
      "\u001b[34m[88]#011validation_0-mlogloss:1.09186#011validation_1-mlogloss:1.09346\u001b[0m\n",
      "\u001b[34m[89]#011validation_0-mlogloss:1.09179#011validation_1-mlogloss:1.09341\u001b[0m\n",
      "\u001b[34m[90]#011validation_0-mlogloss:1.09171#011validation_1-mlogloss:1.09335\u001b[0m\n",
      "\u001b[34m[91]#011validation_0-mlogloss:1.09163#011validation_1-mlogloss:1.09329\u001b[0m\n",
      "\u001b[34m[92]#011validation_0-mlogloss:1.09156#011validation_1-mlogloss:1.09324\u001b[0m\n",
      "\u001b[34m[93]#011validation_0-mlogloss:1.09149#011validation_1-mlogloss:1.09318\u001b[0m\n",
      "\u001b[34m[94]#011validation_0-mlogloss:1.09141#011validation_1-mlogloss:1.09312\u001b[0m\n",
      "\u001b[34m[95]#011validation_0-mlogloss:1.09133#011validation_1-mlogloss:1.09306\u001b[0m\n",
      "\u001b[34m[96]#011validation_0-mlogloss:1.09126#011validation_1-mlogloss:1.09301\u001b[0m\n",
      "\u001b[34m[97]#011validation_0-mlogloss:1.09118#011validation_1-mlogloss:1.09295\u001b[0m\n",
      "\u001b[34m[98]#011validation_0-mlogloss:1.09111#011validation_1-mlogloss:1.09289\u001b[0m\n",
      "\u001b[34m[99]#011validation_0-mlogloss:1.09103#011validation_1-mlogloss:1.09283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.81        13\n",
      "           1       0.70      0.88      0.78         8\n",
      "           2       0.67      0.44      0.53         9\n",
      "\n",
      "    accuracy                           0.73        30\n",
      "   macro avg       0.72      0.72      0.71        30\u001b[0m\n",
      "\u001b[34mweighted avg       0.73      0.73      0.72        30\n",
      "\u001b[0m\n",
      "\u001b[34m[[11  1  1]\n",
      " [ 0  7  1]\n",
      " [ 3  2  4]]\u001b[0m\n",
      "\u001b[34m0.7271428571428571\u001b[0m\n",
      "\u001b[34msave booster\u001b[0m\n",
      "\n",
      "2020-08-10 17:43:46 Uploading - Uploading generated training model\n",
      "2020-08-10 17:43:46 Completed - Training job completed\n",
      "Training seconds: 47\n",
      "Billable seconds: 47\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"../docker/code\",\n",
    "    #hyperparameters=hyperparameters,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.m5.2xlarge\",\n",
    "    framework_version=\"0.90-2\",\n",
    ")\n",
    "\n",
    "train_config = sagemaker.session.s3_input('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.session.s3_input('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "#print(train_config.config, val_config)\n",
    "xgb_estimator.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.xgboost.model.XGBoostPredictor at 0x11ead2d30>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_estimator.deploy(initial_instance_count=1, instance_type=\"ml.t2.large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33649730682373047, 0.33273303508758545, 0.33076968789100647]]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "runtime_client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "\n",
    "payload = \"1,2,3,4,5\"\n",
    "\n",
    "response = runtime_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType='text/csv',\n",
    "                                   Body=payload)\n",
    "\n",
    "result = response['Body'].read().decode('ascii')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost.model import XGBoostPredictor\n",
    "\n",
    "endpoint_name = 'sagemaker-xgboost-2020-08-10-17-41-03-430'\n",
    "payload = \"1,2,3,4,5\"\n",
    "xgb_predictor = XGBoostPredictor(endpoint_name, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text/csv\n",
      "application/x-npy\n"
     ]
    },
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n<title>500 Internal Server Error</title>\n<h1>Internal Server Error</h1>\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n\". See https://ap-southeast-1.console.aws.amazon.com/cloudwatch/home?region=ap-southeast-1#logEventViewer:group=/aws/sagemaker/Endpoints/sagemaker-xgboost-2020-08-10-17-41-03-430 in account 342474125894 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-a9cf224ef95d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mrequest_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_request_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sandbox36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from model with message \"<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n<title>500 Internal Server Error</title>\n<h1>Internal Server Error</h1>\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n\". See https://ap-southeast-1.console.aws.amazon.com/cloudwatch/home?region=ap-southeast-1#logEventViewer:group=/aws/sagemaker/Endpoints/sagemaker-xgboost-2020-08-10-17-41-03-430 in account 342474125894 for more information."
     ]
    }
   ],
   "source": [
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "xgb_predictor.deserializer = None\n",
    "\n",
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "predictions = predict(test_data.as_matrix()[:, 1:])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('sandbox36': conda)",
   "language": "python",
   "name": "python36864bitsandbox36condab860969a34614bd6b57bc36bf727979c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
